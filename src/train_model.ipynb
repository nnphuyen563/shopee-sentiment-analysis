{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18316,"status":"ok","timestamp":1702037410391,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"Lrp_7uSqWiz3","outputId":"369fcdb2-1d88-4f6e-a545-df00631a42d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3895,"status":"ok","timestamp":1701979552181,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"NKipfUt2c-_c","outputId":"15bcba14-1ddc-46c6-8e21-eb2923e149e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["annotated  preprocessing  raw  review_1.xlsx  val_annotater\n","2700-annotated_annotations.json  val-annotated_annotations.json  val-reannotated_annotations.json\n"]}],"source":["from os import path\n","\n","root_path = '/content/gdrive/Shareddrives/PTDL WEB/Bài tập + Đồ án/Đồ án'\n","dataset_path = path.join(root_path, 'dataset')\n","val_path = path.join(dataset_path, 'val_annotater')\n","preprocessing_path = path.join(dataset_path, \"preprocessing\")\n","\n","!ls \"$dataset_path\"\n","!ls \"$val_path\""]},{"cell_type":"markdown","metadata":{"id":"f6BRZHhrcMKm"},"source":["#1. Kiểm tra độ đồng thuận bằng Fleiss Kappa"]},{"cell_type":"markdown","metadata":{"id":"8Ge8Y7JWcUbd"},"source":["### Lần 1"]},{"cell_type":"markdown","metadata":{"id":"yxElq2NBLWHC"},"source":["Để thực hiện kiểm tra độ đồng thuận cho các dữ liệu gán nhãn, trước tiên nhóm tiến hành import các thư viện liên quan để sử dụng, trong đó bao gồm:\n","*  pandas -  thư viện được sử dụng để xử lý và phân tích dữ liệu\n","*  statsmodels - thư viện để đo độ đồng thuận\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nLvBku2dMeM"},"outputs":[],"source":["import json\n","\n","with open(path.join(val_path, 'val-annotated_annotations.json'), 'r') as f:\n","    datas = json.load(f)['examples']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1701979554677,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"XAGQsuOJdcNf","outputId":"3c1d90b1-7290-4e9b-bfd0-e8ce2ad9d3f5"},"outputs":[{"data":{"text/plain":["{'tuanna21411': 3,\n"," 'uyennnp21411': 1,\n"," 'anhnhn21411': 5,\n"," 'tamta21411': 6,\n"," 'nguyennt21411': 4}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["annotater2id = {}\n","\n","for data in datas:\n","  for classification in data['classifications']:\n","    for annotator in classification['classified_by']:\n","      annotater2id[annotator['annotator'].split(\"@\")[0]] = annotator['annotator_id']\n","\n","annotater2id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dv4PJ6bKcbmR"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570},"executionInfo":{"elapsed":1009,"status":"ok","timestamp":1701979555681,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"PdbdvCDxf08J","outputId":"17c60564-f700-474c-8a17-ea5e9d44dc37"},"outputs":[{"name":"stdout","output_type":"stream","text":["tuanna21411 Counter({'Positive': 112, 'Negative': 99, 'Neutral': 88, 'None': 1})\n","uyennnp21411 Counter({'Negative': 116, 'Positive': 100, 'Neutral': 84})\n","anhnhn21411 Counter({'Negative': 131, 'Positive': 121, 'Neutral': 45, 'None': 3})\n","tamta21411 Counter({'Negative': 132, 'Positive': 98, 'Neutral': 70})\n","nguyennt21411 Counter({'Neutral': 110, 'Positive': 106, 'Negative': 84})\n","text Counter({'đúng với mô_tả kho xấu': 1, '24 không một đôi mẹ ơi': 1, 'đúng với mô_tả đặt áo_khoác mà giao cái qq gì vậy màu_sắc saiii chất_liệu không đúng': 1, 'giao thiếu hàng': 1, 'đúng với mô_tả đúng màu_sắc nâu chất_liệu vải vải không được đẹp lắm nhưng phù_hợp giá_cả hơi rộng nhưng bé nhà mình thích nên vẫn đánh_giá cho shop năm sao': 1, 'chất_liệu mỏng màu sắc đen đúng với mô_tả yét khá là mỏng nhưng với giá này thì cũng ok': 1, 'màu sắc đen chất mỏng': 1, 'màu_sắc đúng đúng với mô_tả không chất_liệu mỏng áo bị lỗi': 1, 'mỏng và bự to rộng không mang được hàng về nhanh hơn dự_kiến a': 1, 'he was also an advocate and supporter in a similar position as his': 1, 'hàng đẹp giao hàng nhanh shipper vui_vẻ thân_thiện sẽ còn quay lại ủng_hộ shop': 1, 'ổn nma mình một m57 46 không thấy hơi rộng phần cánh_tay màu giống ảnh vải dày': 1, 'hàng không đúng với quảng_cáo thật tệ tôi mua sản_phẩm áo nỉ nhưng nhận được hàng không đúng tôi muốn đổi trả yêu_cầu sophie sem xét sử lý cho tôi': 1, 'mình đặt bảy đôi mang năm đôi thì năm đôi đều bị lủng không biết hai đôi kia như_thế_nào đúng là mua với giá rẻ thì ít_nhất cũng phải lành chứ sao mà lủng từ đôi này tới đôi khác': 1, 'chất_liệu oke màu sắc đen đúng với mô_tả sai kích_cỡ đặt 70 không mà 49 không không mặc vừa tay con bung chỉ': 1, 'áo kiểu gì mà tay dài tay ngắn không hiểu shop làm kiểu gì luôn': 1, 'tặng vớ đã đi rồi': 1, 'đúng với mô_tả yes chất_liệu không bic vv màu sắc đen một m5 mặc vào là qua okela luon ak áo cũm xink lămz nha': 1, 'áo xinh mặc lên form đẹp chất vải cũng ưng màu giống với hình giá_cả phù_hợp rất ưng ạ': 1, 'sản_phẩm đẹp rẻ mua lần thứ n tại shop zui chắc tại ng m cũng nho_nhỏ nên hợp với đồ của shop <emoji> face with tears of joy </emoji> chất cũng khá ok sẽ ủng_hộ dài': 1, 'giao hàng nhanh đóng_gói hàng cẩn_thận đẹp mèo nhà mình rất thích': 1, 'chất_liệu vải cotton co_giãn màu sắc đen và trắng đúng với mô_tả sản_phẩm giống mô_tả rất vô_tri ngố': 1, 'quần đẹp quá_trời săn được giá rẻ nữa chất_liệu màu_sắc đều ưng': 1, 'màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ bông áo vải không dày không mỏng mình thích mặc rộng nên chọn size lớn sợ rộng nhma vừa in m6 40 không qua mông nhé': 1, 'chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ngoài đời còn đẹp hơn trên hình': 1, 'chất_liệu mỏng như lá lúa mặc có phần khó_chịu đúng với mô_tả giao_diện đúng khoảng 80 màu_sắc đặt màu be mà nó về màu vàng vỏ chuối <emoji> happy face or smiley </emoji> khuyến_cáo mọi người nên cân_nhắc <emoji> thumbs up </emoji>': 1, 'màu sắc đen chất_liệu vải xấu vậy tưởng cái dẻ lau nhà thôi_thì giá rẻ không đòi_hỏi <emoji> smiling face with hearts </emoji>': 1, 'đúng với mô_tả đúng mô_tả màu sắc đen chất_liệu thun gân tăm shop giao thiếu hàng mua hai tính tiền hai nhận được một': 1, 'mua áo_khoác mà giao quần trẻ_con là sao vậy shop': 1, 'quá tệ đặt cái áo giao cái quần trẻ_con cho ai mặc không biết làm_ăn vớ_vẩn lừa_đảo không nên mua nhé mọi người': 1, 'chất_liệu rẻ màu_sắc den trắng đúng với mô_tả hơi hơi': 1, 'quần quá xấu mình một m50 42 không mua size sao mông mình thuộc dạng mông lép nhưng phần hông quần quá chật kéo không qua đc mông phần eo thì quá rộng eo 63 nhưng thừa hẳn sáu tám cm <emoji> loudly crying face </emoji> … quần thiết_kế quá tệ hông thì chật eo thì rộng xoè ra mang đi sửa mà thợ sửa quần cũng lắc_đầu vì chưa thấy cái quần nào tệ đến vậy chỉ thừa tua_tủa mang về đi sửa hết 50 không nhưng cuối_cùng cũng chỉ để làm dẻ lau thôi không nên mua nhé mọi người': 1, 'mỏng xấu không lên được from … thất_vọng về shop không chịu được': 1, 'tất bị rách nên cho shop một sao': 1, 'đúng với mô_tả không đúng mô_tả chất_liệu mềm màu_sắc xám đen không đúng hàng đã đặt quá rộng màu xấu shop làm_việc không có_tâm': 1, 'hàng nhanh rách mọi người không lên mua': 1, 'màu_sắc nâu chất_liệu vải đúng với mô_tả không đúng to rất to như chi người 60 70 ng mặc í': 1, 'quá xấu quần không_thể mặc màu cũ hơn rất nhiều so với trên hình dơ': 1, 'đúng với mô_tả không biết màu_sắc không biết chất_liệu không biết đặt_hàng hiện chín quà tặng nhưng lúc nhận hàng không có nên chả biết đánh_giá như nào không tặng thì đừng làm thế khách_hàng tưởng có thật <emoji> very happy face or smiley </emoji>': 1, 'chất_liệu xấuu màu_sắc mua màu trắng về màu nâu đúng với mô_tả xấu chê xấu jxheudncbkandvhdbyv': 1, 'chất_liệu không giống ảnh con_em tao cứ đòi mua xong nó trẻ_con nó mới thấy đẹp chứ tao thấy xấu vl chất_liệu xấu kinh <emoji> very very happy face or smiley </emoji>': 1, 'đúng với mô_tả không đúng tí nào màu_sắc đem chất_liệu mỏng vãi thất_vọng tràn_trề không còn gì để nói_xấu mỏng không xứng_đáng với giá tiền tí naog chê nha đừng mua nha mọi người khuyên chân_thật đã thế còn rách nữa chứ <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji>': 1, 'áo thì xù lông xù lá hàng lỏ sản_phẩm không đúng với hình_ảnh dell nên muaa dell có sz riêng như cái bì xấu ik chang cái bì lun': 1, 'mọi người không nên mua ở shop này nha sản_phẩm rất tệ luôn áo như cái rẻ lau vải không ra gì rất bực_mình vì mình bỏ tiền ra mua mà nhận lại được như_vậy chưa mặc lần nào đã bị xù rồi mỏng <emoji> pouting face </emoji> <emoji> pouting face </emoji> rất thất_vọng về shop luôn không ngờ là sản_phẩm tệ như_vậy khuyên mọi người là không nên mua những sản_phẩm như thế_này': 1, 'màu_sắc không đúng đúng với mô_tả không chất_liệu tốt chất_liệu thì đc nma không có túi để tay tệ vll': 1, 'đúng với mô_tả không chất_liệu vải màu_sắc xám áo_khoác vải mỏng không phải logo thêu như trên live vải xấu nhìn như nùi dẻ vậy': 1, 'dải dù chứ không phải lụa xướt': 1, 'đúng với mô_tả không nó mỏng màu sắc đen chất_liệu vải thường nó rất mỏng không giống hình_ảnh': 1, 'chất_liệu mỏng màu_sắc không giống trên ảnh đúng với mô_tả áo không giống trên ảnh mầu xấu và mỏng còn bị lộ đường chỉ chê ạ': 1, 'chất_liệu rách phần cánh_tay đúng với mô_tả không đúng': 1, 'shipper không giao hàng làm tao hóng mãi shop bảo hối bên vận_chuyển rồi mà vẫn không thấy gì': 1, 'chất_liệu len tăm mỏng màu_sắc be áo đẹp phù_hợp với giá tiền chất len tăm mỏng nhẹ thích_hợp những ngày đông chớm lạnh mình xin sửa lại đánh giá_thành một sao vì shop gửi áo tay ngắn tay dài cho mình ai mua chú_ý nhé cảm_ơn': 1, 'đúng với mô_tả không màu_sắc den chất_liệu nỉ vải xấu cực_kì không gặp nước vài bữa là bong viền vải xù': 1, 'áo nhận về đã bị rách một đường dài dưới nách nhắn_tin cho shop thì không trả_lời': 1, 'quần rách shop không giải_quyết mua chục cái rách một cái hoàn là hoàn_tất đang cần gấp báo shop hoàn một quần thôi được không shop chả nói gì xong nhiều việc quá mình cũng quên_béng đi <emoji> unamused face </emoji> <emoji> unamused face </emoji>': 1, 'chất_liệu mỏng đúng với mô_tả không đúng_sai hoàn_toàn màu_sắc trắng nhận về mà chán mua tận 10 đôi không nghĩ như này': 1, 'làm_ăn như này không ổn đâu nhé đặt áo đi gửi cho cái quần trẻ_em làm gì vậy': 1, 'nói_chung là xấu vải áo xấu lắm': 1, 'màu_sắc trắng chất_liệu mỏng áo quá mỏng không vừa người nhỏ': 1, 'màu_sắc den đúng với mô_tả không áo mỏng có mùi hình in rất xấu': 1, 'đúng với mô_tả sa i mình săn trên live của shop đc giá hời cũng hi_vọng nhiều lắm ship nhanh nhưng_mà giao lộn hàng cho mình rồi nha mong shop đổi áo cho mình huhuuuuuuu': 1, 'màu sắc đen chất_liệu loại vải mềm không phải loại mịn đúng với mô_tả sai hoàn_toàn ae không nên mua khuyên ae luôn shop lừa_đảo đó hàng không đúng với ảnh': 1, 'chất_liệu vải dù màu sắc đen mặc nóng chất vải thô': 1, 'chất_liệu lừa_đảo màu_sắc xấu đúng với mô_tả đồ lừa_đảo': 1, 'shop giao hàng không đúng màu đặt màu nâu lại giao màu đen lần đầu như lần cuối sẽ không mua lại': 1, 'giao nhầm cho mình áo khác đòi hoàn hàng thì không rep áo giao nhầm thì xấu bé nhìn như dân tổ': 1, 'đúng với mô_tả shop làm_ăn gì kì vậy trên ảnh là áo_khoác mà giao quần_đùi mọi người đừng nên mua nha': 1, 'chất_liệu không màu_sắc không đúng với giờ ảnh đúng với mô_tả không lúc mua hàng đêm thì mình thấy được áo này với giá giảm sốc cứ nghĩ do săn được lúc tối nên không lo lắm ngờ_đâu lúc hàng về thì lại là cái quần này đây mình không ktra lúc ship tới cty nên về ms bóc hàng mình nhận một phần lỗi cug do mình cả_tin nhưng đến như này mình không_thể không tức': 1, 'đặt một màu giao hàng một màu không_thể chấp_nhận được nhắn_tin thì không thèm phản_hồi': 1, 'bán hàng đ có tâm gì biết là rẻ nhưng không_thể đưa cho tôi cái mà đường chỉ bung hết ở mấy chỗ khâu ống thu vào': 1, 'chất_liệu chất_liệu mỏng màu_sắc không đúng mẫu như ảnh shop chụp đúng với mô_tả chất nỉ mỏng giá ổn mọi người nên cần nhắc trước khi mua chất nỉ mỏng_mảnh hơi thật vong': 1, 'vãi không đẹp chỉ thừa nhiều': 1, 'tao đặt màu xanh nma ship màu hồng': 1, 'màu_sắc đúng màu đúng với mô_tả không ấm mà_còn mỏng nữa không nên mua chất_liệu mỏng': 1, 'áo chất vải được mà shop làm_ăn như cc gửi hàng lỗi cho giờ mình khiếu_nại mà không rep săn sal được giá rẻ nma cubgx đ đáng không mặc được <emoji> very very happy face or smiley </emoji>': 1, 'màu_sắc be chất_liệu nhung tâm đúng với mô_tả dell nha tr quần xấu er mấy bây đừng có mua quần này hai nói thiệt quần này xấu lắm vải thì mỏng nhìn xuyên thấu bên trong luôn á bây với_lại nó không có đứng fom như mẫu mặc đâu thật đấy hai là người đi trước hai biết <emoji> smiling face with halo </emoji> <emoji> broken heart </emoji>': 1, 'màu_sắc màu be đúng với mô_tả không đúng chất_liệu vải hàng chất_lượng kém mài sắc không giống trong hình cực_kì xấu <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji>': 1, 'đúng với mô_tả không chất_liệu vải màu_sắc trắng không nên mua không đáng tiền mỏng te xấu nữa chán shop': 1, 'chất_liệu vair vải xấu một m6 50 không mang ngắn vãi': 1, 'mình không_thể tưởng đc hàng lại xấu như_vậy mô_tả áo thể_thao nỉ bông dầy_dặn mà mỏng_tang đường may kiểu_dáng tóm_lại là không_thể mặc và không dám cho ai': 1, 'màu_sắc đẹp đúng với mô_tả không giống chất_liệu xấu không đẹp như hình': 1, 'màu_sắc đẹp như không đúng trong lòng chất_liệu không ₫ đúng với mô_tả không giống trong hình áo_khoác xanh ở hai cái vòng_tay màu khác cuối cái áo rất thất_vọng': 1, 'màu_sắc không chất_liệu không đúng với mô_tả không không nên mua nhé mọi người nó giao về không pk áo mà là cái rẻ á mọi người <emoji> pouting face </emoji> <emoji> pouting face </emoji>': 1, 'giao bé quá thất_vọng': 1, 'đúng với mô_tả rất tệ màu_sắc ổn chất_liệu mỏng rất rộng không biết sz như nào nhưng mang rất rộng và nhiều chỉ thừa': 1, 'màu_sắc đẹp chất_liệu vãi hơi cứng hàng đẹp tốt hàng hơi chậm': 1, 'màu_sắc đung mau chất_liệu không đung chất khi quang cao': 1, 'chất_liệu nỉ đúng với mô_tả xấu màu_sắc xấu áo xấu vl mỏng thật vọng tràn_trề lần cuối_cùng mua ở shop mà bán đắt vl thề chê': 1, 'shop gửi nhầm màu áo mong shop xem_lại ạ': 1, 'đúng với mô_tả không hề mua áo_khoác giao khẩu_trang <emoji> thumbs down </emoji> <emoji> angry face </emoji>': 1, 'chất_liệu in cũng xấu đúng với mô_tả chất xấu màu_sắc không đẹp không nên mua có size dưới55 mà mik có 36 không đã chật': 1, 'gửi nhầm màu quần kêu đổi ừ à đợi mấy ngày hôm_nay không thấy đâu yêu_cầu shop đổi lại đúng màu quần đặt đặt màu xám giao màu xanh không gquyet được thì hoàn hàng và giả tiền <emoji> slightly smiling face </emoji> làm_ăn kiểu gì kbiet': 1, 'quần lộ rõ quần chíp đánh_giá một sao': 1, 'chưa bao_giờ đánh_giá khi mua hàng shoppe mà nay nhận đc cái áo quá thất_vọng gặp thêm cái màu nâu nữa nhìn chán vãi đúng là tiền_nào_của_nấy': 1, 'sản_phẩm không giống ảnh': 1, 'đúng với mô_tả đúng mình thấy áo cũng đẹp mình m57 mặc size m hơi rộng quá qua mông chút nhưng_mà chắc shop kiểm hàng không kĩ lúc mình nhận thì cái ống tay nó bị bung chỉ một lỗ xong mình khâu lại cũng ok rồi mong shop lần sau rút kinh_nghiệm': 1, 'màu_sắc đúng chất_liệu tệ đúng với mô_tả xấu không nên mua': 1, 'chất_liệu bình_thường màu_sắc cũ đúng với mô_tả không quần cũ lắm luôn ý màu quần ngã vàng ố không chịu được luôn vàng như để tồn_kho lâu lắm luôn rồi á trên hình màu sáng hơn ngoài mình mua đồ hai hand cũng không cũ như này luôn tưởng hàng cho không ạ': 1, 'đặt hai cái áo mà shop giao một quần trẻ_con không liên_quan gọi sdt thì không đúng nhắn_tin thì không trả_lời bán hàng thiếu uy_tín quá': 1, 'màu_sắc hdhsi ts síib iwkah ịn sjkao ssyysg sókcb vavva xhxhh sbshxhka jzjzbb haihx kskzkxb sijs kzjbzbaj zjzkjxv kskzbbxk diixjxhxbk': 1, 'chất_liệu mỏng màu_sắc tạm tay_áo không đúng với trên ảnh rộng nói_chung là cheeeee': 1, 'giao hàng thiếu số_lượng câu trả_lời của shop không hài_lòng và được thích_đáng nên đánh_giá một': 1, 'đúng với mô_tả xấu vãi ò chất_liệu vải màu_sắc xám hàng đểu không nên mua ạ': 1, 'giá rẻ nhưng áo xấu bạn nào lùn với gầy thì không nên mua nha': 1, 'màu_sắc trắng chất_liệu len tăm áo mỏng mặc thấy hết đồ bên trong xong đã thế mới mặc lần đầu đã bung hết chỉ ở tay_áo với vai cơ': 1, 'áo ngắn không_thể hoàn hàng': 1, 'shop ghi là 15 quà tặng mà kiếm quài không thấy một món quà tặng nào không hiểu sao ạ': 1, 'đúng với mô_tả sai mới mô_tả shop bán hàng kì_lạ đặt_hàng áo khoát giao hàng cái quần trẻ_em là sao ai đặt_hàng nhớ để_ý đánh_giá tệ nhen hông phải ganh_ghét gì mà là sự_thật <emoji> thumbs down </emoji> <emoji> thumbs down </emoji>': 1, 'màu_sắc không đúng như hình tệ hàng giao không đúng như video mua áo lại giao cho quần trẻ_em nói_chung là tệ chê': 1, 'màu sắc đen đúng với mô_tả không đúng chất_liệu vải quần rất là mỏng quần gì mà không có túi gì hết ấy': 1, 'đăng quần kiểu này giao kiểu kia chịu_thua luôn á ghét nhất hoàn hàng lâu_lắc đóng_gói thì kiểm_tra kĩ giùm cái <emoji> folded hands </emoji>': 1, 'chất_liệu vải màu_sắc xám đúng với mô_tả không áo mất cúc rồi hoàn_trả áo về shop xonh hoàn xomg shop không đồng í hoàn lại tiền rồi giờ mất luôn áo mất luôn tiền <emoji> grinning face </emoji>': 1, 'giao thiếu một cái nhắn tị rep chậm shop hỏi stk để bank r tớ nói giá thì nói mặc hai xl nhé là sao vậy': 1, 'chất_liệu đểu mỏng mặc chán đời đúng với mô_tả không làm rẻ lau nhà ổn': 1, 'cắt chỉ phát rách luôn ảo thật': 1, 'quần vải thì xấu chất_liệu không như hình chất_liệu trông như quần bà_già không lên mua lại lần hai': 1, 'đúng với mô_tả quá tệ ship nguyên một vết bẩn và rách vai chất_liệu mỏng màu_sắc đúng': 1, 'chất_liệu bth màu_sắc bth đúng với mô_tả không': 1, 'chất_liệu vải màu sắc đen đúng với mô_tả đúng quần khá đẹp giao hàng thì chậm ngồi đợi cả ngày không thấy shipper gọi cuộc nào mà đã ghi là không liên_hệ đc phải mất đến hai ngày thì mới nhận được hàng đáng_lẽ là có_thể nhận sớm hơn mà đã giao muộn rồi đi đây còn phải đứng đợi 30 p nữa chưa giao hàng mà đã gọi ra nhận hàng trời thì nắng chứ có mát_mẻ gì mà bắt đứng đợi 30 p phải nói là dịch_vụ giao hàng quá tệ': 1, 'đúng với mô_tả ok chất_liệu ok màu_sắc xam quá rộng đối_với mình dáng váy cũng ok nma rộng quad không mặc được': 1, 'đúng với mô_tả không đúng lắm màu sắc đen chất_liệu vải mỏng quần chất vải hơi mỏng với hơi nhiều chỉ thừa': 1, 'màu_sắc được chất_liệu mỏng đúng với mô_tả không cực_kì ngắn': 1, 'màu_sắc khác với hình_ảnh đúng với mô_tả đúng màu ở ngoài nhìn hơi cũ ống loe hơi to hình_ảnh mang tính_chất nhận xu': 1, 'không to như mình nghĩ chất vải hơi xù lông màu cũng không đẹp như trên ảnh': 1, 'màu_sắc nâu chất_liệu nỉ áo dáng khá ổn nhưng cổ bị thô do đg may': 1, 'chất_liệu dung đúng với mô_tả dung màu_sắc dung mềm như lụa mịn như nhung luôn công_nghệ penlips hiệu_ứng_son lỳ đẹp như đánh_son ạ <emoji> smiling face with heart eyes </emoji> <emoji> smiling face with heart eyes </emoji> <emoji> smiling face with heart eyes </emoji> sản_phẩm mới ra_lò nhà thắm thỏ thắm thỏ beu spa 푻풉ẩ풎_풎ỹ_풌풉ô풏품_풙â풎 풍ấ풏_푳ô풏품_풎à풚_풑풉풐풏품 푻풉풖ỷ <emoji> telephone receiver </emoji> 푩풐풐풌풊풏품 0982323267 <emoji> department store </emoji> 푨풅풅풓풆풔풔 một 0210 c1 vinhomes new center tp hà_tĩnh cs2 sn 47 nguyễn huệ thị_trấn hương_khê hà_tĩnh filler botox uy_tín longmayphongthuy thammykhongxamlan dieukhacchanmay sexybrows xoasualongmayloihong xoalaser phunmoibabylips phunmoibongdamlipstick phunmi daotaohocvienchuyennghiep': 1, 'đúng với mô_tả tay hơi ngắn síu': 1, 'mẹ ơi cái quần màu xấu ỉa luôn màu cũ bẩn bẩn như kiểu mặc nghìn lần r đem bán á màu trên ảnh còn đẹp chán màu bên ngoài ố vàng à mà sao size làm chả rộng tí nào mặc vẫn còn bó đùi đùi tôi 52 ạ': 1, 'chất_liệu vải hơi lạ đúng với mô_tả đúng màu_sắc đúng vải không dống hình nha shopp': 1, 'có một thùng đây <emoji> yawning face </emoji> <emoji> middle finger </emoji> có một_số đúng đường 凉 có một_số đúng là có phải là gì': 1, 'đúng với mô_tả không chắc chất_liệu vải thô màu_sắc be nói nnao nhỉ theo cản nhận bản_thân mik thì cái quần này nó cứ sao sao ý vải rất cứng và ngứa mặc không ưng tẹo nào nma khâu đóng hàng và giao hnagf thì rất ok mong shop cải_thiện về quần mặc dỳ giá có 59 không thì chẳng đòi chất tốt đc': 1, 'đúng với mô_tả đúng chất_liệu hik màu_sắc nâu lúc nhận hàg hơi thất_vọng áo không đc gấp gọn vô túi kiểu như gấp qua_loa rồi cho vào túi cho có vậy áo có nhiều chỉ thừa vd và ha chỉ mag tính_chất nhận xu': 1, 'chất_liệu khbt đúng với mô_tả cũng tạm vải mỏng không đẹp như ảnh chụp từ trên xuống dưới nè ru4 đi choi đi phúc của mình thì của mình thì của mình thì của mình thì của mình thì của mình thì của mình thì của bạn mình ạ em hứa là sẽ quen thôi mà ckj có_thể làm được điều đó không phải là ql m gửi tin nhắn qua yahoo tới giờ chưa bao_giờ hết': 1, 'giá_thành khá rẻ nhưng tiền nào của đấy cổ áo khi mặc lên thì lệch một bên cao một bên thấp phần bên trong lót một lớp bông mỏng không ấm là mấy không': 1, 'màu_sắc trắng đúng với mô_tả đúng chất_liệu bình_thường tất bé và mắt với tay đều được dán bằng keo <emoji> very happy face or smiley </emoji>': 1, 'chất_liệu nỉ mỏng màu sắc đen áo quá rộng và quá dài mik m58 nặng 45 không mà mặc dài gần tới đầu_gối': 1, 'giao hàng nhanh chất vải khá mềm phù_hợp với giá tiền': 1, 'sợi len ở cổ sau áo đen bị bung và áo đen nhỏ hơn áo trắng khá nhiều <emoji> slightly smiling face </emoji> <emoji> slightly smiling face </emoji> đóng_gói sản_phẩm rất đẹp và chắc_chắn': 1, 'mình đặt hai áo mà shop chỉ gửi một': 1, 'huhu chật lắm luôn í ạ mình đi sz 39 không nhích nổi em mình đi sz 34 còn hơi chật í bh đơn có 50 không mà hoàn lại thì cũng hơi lâu a': 1, 'áo không giống mong_đợi fom ôm phải không đẹp khô và cứng': 1, 'đẹp nhưng áo nhỏ không from rộng': 1, 'đúng với mô_tả đúng màu_sắc be chất_liệu vải khá mềm áo mỏng lắm còn ấm hay không thì khbt giao hàng ok haks du due dieb đo ẹ u ks du rư id d sín rne iéhy eisbbd diệnuwbd đi đi đi djnsx': 1, 'đúng với mô_tả đúng chất_liệu không giống trong ảnh màu_sắc đẹp': 1, 'kiểu thì là vậy chứ áo vải mỏng lắm tay_áo ngắn mặc vào nó ngố ngố kì lắm mọi người': 1, 'chất_liệu vải màu_sắc oke đúng với mô_tả không áo mỏng nhint thấy cả bên trong lộ cả áo ngực và quá rộng nên mặc cứ tụt xuống': 1, 'chất_liệu kb màu sắc đen đúng với mô_tả dung voi mô_tả tiền nào của đấy với số tiền đấy mua bộ_đồ thì không có gì để nói': 1, 'đúng với mô_tả giống hình màu_sắc nâu chất_liệu vải áo hơi mỏng so với mk nghĩ nhìu vải thừa chất vải tuy mềm nhưng bên trong bị xù với giá tìn này thì cx ok': 1, 'huhu buần quá mới mua sz m mà rộng xong pass cho bạn mua size sao mà mua sao thì chật <emoji> rolling on the floor laughing </emoji> màu quần thì size m tao mua giống ghi xám còn sz sao giống xám đen hơn nha chất vải oki ê noi chung la tiền nào của đó nha mua cái quần sale mà cái gấu quần nó giựt lên tới cổ <emoji> very very happy face or smiley </emoji> đường may không đều hơi buần': 1, 'chật mỏng dcd ngieu tao đi ngắn chút_xíu luon cái mắt dễ rơi lắm chí_ít có quà đi kèm ba sao châm_chước': 1, 'đúng với mô_tả không đúng như mô_tả vãi bông loại vãi hay làm quần_áo hoá_trang ông_già noel ấy nó dày hơn một_tí': 1, 'size áo không đúng như mô_tả bạn nào hơi to nên cân_nhắc trước khi mua xin đổi hàng thì shop bảo qua vừa thì đổi chứ không nhận là size áo của mình có vấn_đề nhưng chất vải thì oke giao khá nhanh nên bạn mình đưa lại áo cho em mặc': 1, 'chất_liệu nóng màu_sắc nâu đúng với mô_tả đúng dáng mặc rất ok phải nói là đẹp luôn nhưng màu nâu này nó lạ lắm như màu của mấy bà_già hay mặc í nếu mua thì mình nên chọn màu khác còn với giá tiền như này là ok rồi': 1, 'màu_sắc nâu chất mặc phù_hợp trời lạnh mặc bao nóng <emoji> very very happy face or smiley </emoji> chữ in sơn nham_nhở dễ tróc chú_ý giặt': 1, 'thất_vọng với giá tiền áo mỏng thì không nói làm gì nhưng áo rách thế_thì không chấp_nhận được không biết shop sơ_suất hay cố_tình <emoji> very happy face or smiley </emoji>': 1, 'áo oki lắm nhưng mk đặt cỡ 55 không thì nhận đc áo chỉ mặc vừa khít cơ_thể trong khi mk mới có 40 không <emoji> woozy face </emoji> <emoji> woozy face </emoji>': 1, 'màu_sắc bóng bóng <emoji> happy face or smiley </emoji> chất_liệu hơi mỏng đúng với mô_tả binhf thuowngf mình tưởng chất vải cát cơ nhưng không bóng bóng mặc khá vừa_vặn nói_chung tiền_nào_của_nấy mua được nha hâhhahahahahhahaahhaahahhahahahahahahahaahhahaahahahahahahahahhshshshshshsshhsshshshshhshs': 1, 'vải như ức vậy': 1, 'màu_sắc trắng_đen đúng với mô_tả đúng nam_châm nhỏ không dính lắm một chiếc tất bị mất một cục nam_châm đường chỉ khâu ở hai tay lỏng_lẻo được cái giao hàng lâu <emoji> happy face or smiley </emoji>': 1, 'đúng với mô_tả khong giống lắm chất_liệu xấu màu_sắc be mình thấy chất_liệu giởm form cx xấu nhma 50 không thì cx không_thể đòi_hỏi nhiều': 1, 'màu_sắc trắng giao đủ số_lượng mình đã đặt nhưng bị dơ một đôi giao hàng nhanh ok': 1, 'đúng với mô_tả không đúng lắm chất_liệu nỉ bông pha nilong màu sắc đen và trắng áo không đẹp lắm vải khá xấu lên form khá xấu tay_áo to vãi mà thân áo có chút éc còn dài nên mặc lên hơi xấu cổ áo hơi lỗi in hình dễ tróc nên không khuyến_khích giặt máy live còn 37 không nên mặc vài lần cũng được': 1, 'áo chất vải xấu kiểu dán khác hình shop đăng nhiều đường may ẩu vạt áo hai cái không đều nhau nói_chung tiền nào của đấy áp mã gg còn 34 không nên không đòi_hỏi gì nhiều mua khoác tạm_thời tiết mua thu thôi': 1, 'màu_sắc màu hồng không có túi chất_liệu cũng được đúng với mô_tả đúng tốt nhưng không có túi': 1, 'vải bị xù nhẹ bên ngoài rất nhiều chỉ thừa nguyên một chục chỉ màu xanh không biết để làm gì này mà đem đi giặt thì xù như bông_gòn luôn nhìn tông quan thấy màu đẹp mà làm ẩu quá không thik lắm không hài_lòng với sản_phẩm': 1, 'vãi cứng màu như hình mọi người nên căn nhắc trước khi mua mặc nóng mình 42 cân mặc vừa': 1, 'màu_sắc xanh đúng với mô_tả ngắn hơn trong ảnh mẫu rất nhiều áo đẹp vãi ok dóng mẫu nhưng áo rất ngắnnn': 1, 'đúng với mô_tả hơi rộng chất_liệu vải nỉ màu_sắc xanh áo hơi rộng vải có chỉ thừa nhiều phải cắt bớt vải không mỏng cũng không dày': 1, 'vải oke nhưng_mà quần bị duột chỉ from chỗ lưng quần chưa oke cho lắm đi bóp thì oke hơn nha': 1, 'chất_liệu vải mỏng màu sắc đen đúng với mô_tả không mọi người nên cân_nhắc kỹ trước khi mua bởi mua r thì đừng hối_hận': 1, 'chất_liệu mỏng quá màu_sắc trắng đúng với mô_tả không mấy': 1, 'tất mỏng': 1, 'chất_liệu vải màu_sắc đỏ pha hồng vải khá mỏng và thô mặc lâu ngày sẽ bị sù vải': 1, 'ship thân_thiện đóng_gói cẩn_thận đc tặng thêm lắc xinh nhưng hơit hất vọng về tất tay với thân tất không cùng màu': 1, 'mỏng quá': 1, 'thì cũng đẹp hơi mỏng nhưng dùng mùa hè thì rất ô ke': 1, 'tất chỉ có một size khá chật vải mỏng nhưng_mà phù_hợp với giá tiền ổn': 1, 'màu sắc đen chất_liệu nhung tăm đúng với mô_tả đúng áo có hơi mỏng nhưng màu đen sẽ không lộ rõ chỉ thừa nhiều còn có thêm vết rách nói_chung với giá_như vậy cũng ổn': 1, 'màu_sắc xanh hàng cũng đc mà hơn mỏng mua nên cân_nhắc lại <emoji> loudly crying face </emoji>': 1, 'màu_sắc đúng mô_tả chất_liệu thô xấu của nào tiền nấy': 1, 'màu_sắc vậy chất_liệu giờ đúng với mô_tả vậy nâng mũi sẽ thay_đổi như_thế_nào hành_trình nâng mũi của bạn hằng tại tmv tấm như thế_này có_thể coi là thành_công chưa ạ <emoji> backhand index pointing right </emoji> liên_hệ hotline <emoji> telephone </emoji> 0966605600 hoặc inbox fanpage để đặt lịch tư_vấn cùng bác_sĩ ngay': 1, 'màu_sắc nâu đúng với mô_tả không chất_liệu nỉ bông mặc ấm lắm nhưng không ưng cái cổ tí nào nó như kiểu sắp rụng ra ý biết là tiền_nào_của_nấy nma vẫn thất_vọng vì cũng mua của shop vài lần r': 1, 'giao hàng nhanh đầy_đủ đúng mẫu áo hơi mỏng mặc bên trong cũng ấm áo đen mới mặc đã bị rách cổ': 1, 'không nhận đc hàng': 1, 'đúng với mô_tả khác màu vải mỏng nhăn màu_sắc vàng nhạt chất_liệu vải mỏng tạm': 1, 'giao hàng nhanh quần rất dài so với ng m55 nha chất quần ổn nhưng đường may không chắc mới mặc thử đã bục chỉ ở cạp_quần nha thêm tiền đi cắt gấu cũng phải rẻ nữa': 1, 'chất_liệu toits màu_sắc ghi shop thời_trang trí nội_thất_nghiệp và phát_triển của các chế_độ ăn_uống nước': 1, 'màu_sắc biết chất_liệu ok đúng với mô_tả không áo_khoác cardigan viền xanh nâu frmlk form rộng form freesize 65 75 không đổ lại mặc oke kích_thước dài 65 cm xem trên ảnh thứ hai của sản_phẩm phân_loại be viền xanh be viền nâu chất_liệu nỉ bông cardigan cardigannamnu cardiganformrong aocardigan aokhoac nasumay': 1, 'màu_sắc trang tất không có bọc nilon shop bọc thẳng vào nilon màu làm phai hết màu ra tất': 1, 'màu_sắc ébzsbz đúng với mô_tả vzbwhzuzw chất_liệu hxsjxsjnxe giống nhaaaaaaaaaaaaaaaaaaawwwwwaaa': 1, 'chất_liệu mỏng áo bé xíu à <emoji> smiling face with tear </emoji>': 1, 'mang hơi bị ngứa chân nha shop': 1, 'chéo liền_tay nhận ngay quà bự đi bà_con ơiiii https shp ee 8tsdt6ias3a đã được <emoji> check mark button </emoji> miêu_tả khoa_học <emoji> test tube </emoji> là sao <emoji> star </emoji> ️ lại có <emoji> thumbs up </emoji> thôi em không có <emoji> thumbs up </emoji>': 1, 'đúng với mô_tả hơi rộng chất_liệu vải nỉ màu_sắc nâu đặt áo không mũ mà gửi áo có mũ shop đóng_gói sơ_sài': 1, 'rộng lắm phải đi sửa lại': 1, 'màu_sắc trắng chất_liệu đẹp hơn vải màu đen đúng với mô_tả 70 ship hơi chậm vải đẹp hơn áo đen': 1, 'chất_liệu vải đúng với mô_tả vải không jiong hình lắm màu_sắc đúng mô_tả chất vải không giống mô_tả lắm m không rành nên không biết có phải vải đũi không quần rất dài phù_hợp với ng có chiều cao lý_tưởng giá rẻ vậy thì chất_lượng tương_ứng với tiền mọi người cứ cân_nhắc trước khi mua': 1, 'hàng một size mà kích_thước không bằng nhau shop giải_thích do gia_công shop cũng đồng_ý hoàn hàng tặng shop hai sao còn sản_phẩm thì chỉ một sao so với m 56 không m60 mặc bị cộc bạn nào nhẹ_kí mặc một mùa chắc oki m đưa vào đánh_giá để mọi người biết nha': 1, 'vải đẹp nhưng nhận được hàg có một cái bị rách ngag vai <emoji> very very happy face or smiley </emoji> trừ sao ảnh mag tínb chất minh_hoạ': 1, 'đúng với mô_tả không giống lắm màu_sắc xấu chất_liệu biết màu xấu': 1, 'đặt màu hồng giao màu be': 1, 'mình đã nhận được hàng giao hàng nhanh_chóng đóng_gói cẩn_thận nhưng vải mỗi lần đều khác nhau về chất và màu': 1, 'màu_sắc hồng phấn màu đẹp lăm nhma chất thì mỏng quá cứ sợ lộ sao ấy ạ': 1, 'màu trông hơi bẩn andvhskawgzgsiwvshdhjehedv': 1, 'tất hơi mỏng tạm được': 1, 'chất_liệu mỏng màu_sắc đúng màu chất len mỏng hơn so với mh mua lần đầu': 1, 'mỏng vcl': 1, 'ok nhưng chỉ thừa hơi nhiều': 1, 'đúng với mô_tả đúng chất_liệu mỏng không có túi màu_sắc xanh áo đc nhưng không có túi': 1, 'đúng với mô_tả tạm cùng mã nhưng sản_phẩm có màu chênh_lệch chút len bị xù cảm_thấy không hài_lòng': 1, 'đúng với mô_tả <emoji> thumbs up </emoji> màu_sắc đẹp chất_liệu tốt nhưng hơn mỏng': 1, 'shop giao hàng nhanh đóng_gói sản_phẩm tốt sẽ ủng_hộ shop thêm': 1, 'đúng với mô_tả đúng chất_liệu đẹp màu_sắc giống hình sản_phẩm rất đẹp chất_liệu tốt đóng_gói cẩn_thận shipper thân_thiện nói_chung là 10 đ': 1, 'áo chất dày_dặn săn sale được giá hời quá ạ shop đóng_gói kĩ_càng': 1, 'm63 45 không mặc sz làm vừa chiều dài nha hàng đẹp dày_dặn cầm nặng_tay với giá này quá ok nha cả nha': 1, 'áo đẹp dày rất thích giao hàng nhanh hình_ảnh và video mang tính_chất nhận xu': 1, 'đúng với mô_tả giống mẫu màu_sắc màu đen chất_liệu hơi mỏng vải khá là mỏng nhưng với giá tiền như này thì không_thể đòi_hỏi được thêm nói_chung là phù_hợp với giá tiền mọi người nên nhé giao hàng cũng khá là nhanh video chỉ mang tính_chất nhận xu': 1, 'màu_sắc trắng chất_liệu len tăm đúng với mô_tả đúng mô_tả áo về đúng hôm chỗ mk trở lạnh thấy cũng dày so với tầm giá mặc lên cũng rất đẹp sẽ ủng_hộ shop tiếp': 1, 'chất_liệu chất_liệu vải màu_sắc màu đen đúng với mô_tả đúng mô_tả ạ mình săn rẻ lém ý ship hàng nhanh cực luôn đẹp quá là ok luôn nên mua nhé mọi người': 1, 'đúng với mô_tả tốt chất_liệu tốt màu_sắc tốt lịch live tháng này của em tháng này duy_nhất chỉ có một ngày là 24 11 black friday mega live em xin_lỗi nếu để mọi người chờ ạ hơn 80 nhãn hàng lớn sẽ góp_mặt mỹ_phẩm thời_trang đồ gia_dụng tất_nhiên vẫn freeship và voucher 30 không giới_hạn giá_trị cho tất_cả đơn hàng không có chuyện voucher 30 giới_hạn bao_nhiêu không đâu ạ ngoài live của em thì không bao_giờ có zá này đâu ạ': 1, 'chất dày có lót bông cầm nặng_tay sờ mịn chín năm 10 form khá ổn mũ vừa đầu thôi chứ không rộng nhưng có hai lớp nên bù_trừ tám năm 10 giá_thành phù_hợp với chất_lượng trả_giá shop cũng đồng_ý nên rất hài_lòng về thái_độ phục_vụ 1000 10 anh shipper chúa hề lắm vậy nên mua nhé': 1, 'màu_sắc nâu đúng với mô_tả đúng chất_liệu tốt quần đẹp dày_dặn không có chỉ thừa phù_hợp với mọi người form quần xinh shop giao hàng nhanh tư_vấn nhiệt_tình đóng_gói cẩn_thận': 1, 'màu_sắc màu xám lông chuột đúng với mô_tả được chất_liệu vải nỉ mặc mùa thu hợp_lý hàng đẹp rộng_rãi tui m6 48 không mặc đang còn rộng dài qua mông mặc đi học cx rất là oke rẻ phù_hợp giá tiền quá là ưng r': 1, 'chất_liệu thun màu sắc đen phối xám áo xinh nha vải đúng êm lun cầm_chắc tay vơid giá_như vậy thì ổn chữ thiêu nên không sợ tróc': 1, 'để chuẩn_bị cho buổi báo_cáo sản_phẩm giáo_dục địa_phương thứ hai tới khuyến_khích các nhóm mang lap để hoàn_thiện trong một tiết còn lại một tiết sau sẽ báo_cáo sản_phẩm lấy điểm': 1, 'đúng với mô_tả dung chất_liệu kaki màu_sắc xanh reu mặc vô from dth chất mềm nênn mua nha mua giá rẻ vậy cx hợp_lí phối được chục bộ_đồ': 1, 'áo đẹp hơn mình nghĩ chất rất dày mình chọn màu trắng nhưng_mà dày đẹp không hề bị lộ vải siêu siêu mềm đường may tạm ổn chỉ thừa không đáng_kể lắm nói_chung xứng_đáng với số tiền đã bỏ ra': 1, 'quần đẹp lên dáng xinh lắm cảm_ơn shop': 1, 'áo ok chất được giao hơi lâu xí đúng đủ sản_phẩm sau sẽ ủng_hộ thêm nhaaa': 1, 'đúng với mô_tả vậy màu_sắc giờ chất_liệu giờ đã nhận được hàng giao hàng khá nhanh nhưng vải mỏng quá nhẹ_tênh': 1, 'áo đẹp vải cũng uki lắm lại còn rẻ nữa nhưng_mà shipper giao hàng mà như bà nội tao á <emoji> slightly smiling face </emoji>': 1, 'chất_liệu không bik đúng với mô_tả áo đẹp lên form đẹp lắm nha mọi người màu_sắc be shipper dù trời mưa vẫn đi giao lần sau sẽ ủng_hộ shop tiếp nè': 1, 'đúng với mô_tả màu_sắc không giống trong hình_ảnh chất_liệu đẹp màu_sắc không giống trong hình_ảnh': 1, 'áo đẹp áo may hai túi trong dày thấy shop này giá rẻ nhất rồi cskh nhanh nhiệt_tình cute gửi hàng nhanh': 1, 'đúng với mô_tả đẹp chất_liệu mỏng màu_sắc trắng áo lên form hơi kì và chất mỏng như giá rẻ như này cũng không đòi_hỏi gì <emoji> smiling face with tear </emoji>': 1, 'đúng với mô_tả ty chất_liệu hh màu_sắc ty 19188 không biết có ai cũng đang cảm_giác như em không mấy hôm_nay mẹ đi vay_mượn tiền cho đóng học em không dám nói là học_phí thật mà chỉ dám nói với mẹ là 10 triệu số tiền còn lại em bù là tiền em đi làm thêm vào nhịn ăn_tiêu và tiết_kiệm lại nhưng em biết rõ có xin tiền mẹ học mẹ không bao_giờ mắng đâu nhưng nỗi lo của mẹ ngày_một dày thêm khi hơn 20 ngày mẹ phải lo cho cả hai anh_em học đại_học anh mình học bk mặc_dù chương_trình thường nhưng cũng khá nặng nên khi đăng_ký nguyện_vọng đại_học dù đủ điểm đỗ neu nhưng vì biết khả_năng kinh_tế mình đã chọn nguyện_vọng sau phù_hợp với cả kinh_tế và mong_muốn của bản_thân những_tưởng học_phí này sẽ đỡ được bố_mẹ và phụ_giúp cho gia_đình nhưng thì ra không phải vậy trường khác được nợ học_phí và trả trong suốt cả một kỳ học nhưng tại_sao trường gia_hạn ngắn thông_báo chậm như_vậy <emoji> pensive face </emoji> đã sắp cận_kề ngày gia_hạn nộp học_phí nhưng em vẫn chưa gom đủ tiền nộp em cảm_giác rất sợ nếu mình đóng muộn đây chỉ là tâm_sự của em_em không có ý_kiến gì về chất_lượng đào_tạo của thầy_cô đem so_sánh với trường khác đâu vì thứ khiến em lưu_luyến với trường mình là sự nhiệt_tình của giảng_viên trường thui siu': 1, 'chất xịn nha mặc siêu đã còn rẻ nữa được tặng thêm chun buộc tóc <emoji> strawberry </emoji>': 1, 'đúng với mô_tả đúng màu_sắc xăng chất_liệu coton đẹp quá sau_này sẽ ủng_hộ tiếp ạ ok đẹp lắm nha ok so đẹp đúng rồi': 1, 'đúng với mô_tả như hình màu_sắc hồng_quần chất đẹp nhưng chỗ cạp mặt trước dạng giả khoá thì đẹp hơn với hơi bị lệch chỗ day rút chun giao hàng nhanh oki nhé': 1, 'áo đẹp form rộng thoải_mái màu lên không bị kém da giá lại rẻ nữa rất đáng để mua nha': 1, 'màu_sắc trắng áo đẹp chất dày_dặn nên mua heng ảnh và video mang tính đột_phá minh_hoạ ạ sản_phẩm thân_thiện': 1, 'shop tư_vấn rất tận_tình nhé giao hàng gói hàng chu_đáo cẩn_thận nữa nè mình rất ưng_ý nhé': 1, 'chất_liệu ok đúng với mô_tả được màu_sắc đẹp tb có 10 gb data tốc_độ cao tháng thêm thoại thả ga soạn cf120n gửi 999 mobifone gửi đến bạn 10 gb data tốc_độ cao tháng nhận thêm hai 000 phút thoại và hai 000 sms nội mạng 20 phút thoại ngoại mạng xem phim hót trên truyền_hình cliptv tại https cliptv vn phim ưu_đãi chỉ 120 000 đ tháng liên_hệ 9090 từ_chối tư_vấn cskh của mobifone soạn tc gửi 9241': 1, 'đẹp nhaaa bà_con ôi dày_dặn xinh lắm': 1, 'nhận đủ hai cái cái xám thì mang thoải_mái cái đen thì bé hơn một_tí mặc_dù cùng size <emoji> rolling on the floor laughing </emoji>': 1, 'màu_sắc nâu ui áo xinh lắm nè vừa_vặn không quá mỏng đâu sốp giao hàng cũng nhanh gọn nữa ạ nói_chung là siêu ưng recommend mọi người nên mua nhaaaa': 1, 'nhận được hàng giao nhanh canh sale để được giá tốt mình mua 60 không': 1, 'màu_sắc be đậm chất_liệu vải bông đúng với mô_tả đúng áo đẹp nha chất vải dày tôi săn được có năm không mà vải dày như này thì quá là ưng rồi lần sau sẽ ủng_hộ shop': 1, 'chất_liệu nỉ đúng với mô_tả chín 10 màu_sắc be tròi oi ta ns ưng hi chi lun form 10 đ không có nhưng ò nhưng cái màu tui hong ưng lắm với shop làm cái mũ hơi nhỏ á lần sau làm to xíu là đc ns chung 24 cá mà ntn là đc ròi mà chị shipper dth lắm lun á còn kiên_nhẫn nữa tóm_lại là khỏi bàn lun ủng_hộ mua nha mọi người hình_ảnh mang tính nhận xu': 1, 'chất_liệu len mịn màu sắc đen_trắng đúng với mô_tả đúng đẹp lắm ạ rất hài_lòng về sản_phẩm sẽ quay lại ủng_hộ <emoji> star struck </emoji>': 1, 'không ngờ áo 55 không mà đc như_vậy luôn áo đẹp lắm ạ ở trong là lớp bông cầm khá nặng_tay nói_chung là ok nhoa 凉_凉 <emoji> smiling face with smiling eyes </emoji> màu ở ngoài sẽ đậm hơn trg ảnh và video ạ': 1, 'áo xinh lắm nha phù_hợp mặc sống ảo thôi vì khi di_chuyển cái vai nó hơi bị xô lệch nhiều dươới 50 không vừa vì hơi nhỏ': 1, 'màu_sắc dbdj đúng với mô_tả nsjsj chất_liệu mỏng áo mỏng dễ rách lắm nhe mọi người cân_nhắc trước khi mua tiền_nào_của_nấy thôi': 1, 'màu_sắc xanh trắng chất_liệu len đúng với mô_tả hàng đúng mô_tả chất_lượng tốt giao hàng nhanh mặc ấm giá_cả hợp_lí đáng tiền mua': 1, 'chất_liệu vải gì đó không biết màu sắc đen đúng với mô_tả đẹp đúng với hình_mẫu đúng như đánh_giá sản_phẩm là quần mỏng nhưng_mà đẹp với màu đen cx ít lộ giá_thành rẻ nên chất_lượng như_vậy là quá ok r': 1, 'áo đẹp lắm luôn ạ áo nỉ form thoải_mái màu ghi xinh và tôn da đặt chiều t7 mà chủ_nhật nhận hàng luôn shop tư_vấn rất nhiệt_tình mua ba cái rồi chất hịn không chê vào đâu được cảm_thấy rất đáng tiền mà giá quá rẻ luôn shop giao đủ hangg có lót trong chất hịn không chê vào đâu được cảm_thấy rất đáng tiền mà giá quá rẻ luôn shop giao đủ hangg nhận hàng rất ưng cho shop 100 saolun': 1, 'giao hàng nhanh đóng_gói sản_phẩm cẩn thân shop tư_vấn nhiệt_tình thân_thiện chất_lượng sản_phẩm tốt vải khá dày_dặn nhưng không bị quá nóng lên form rất đẹp nchung là siêu ưng': 1, 'màu_sắc màu hồng chất_liệu tuyệt_vời đúng với mô_tả đúng mùa lần đâu thấy cũng ok giá rẻ đẹp <emoji> smiling face with heart eyes </emoji>': 1, 'đồ đẹp vải ok không mỏng không dày không thấy lộ bên kia mình một m6 quần bận trên mắt_cá chân với giá_như này thì nên mua nha mọi người': 1, 'đúng với mô_tả đẹp cũng tạm đc quần mỏng nhìn xuyên đc một m54 mặc oke la lắm nha mọi người nên mua ba_ba': 1, 'màu đẹp lắm nhé nhưng đt đểu nên không chụp đúng màu đc ạ <emoji> smiling face </emoji> chỉ may một lượt hơi lỏng_lẻo nhưng với giá 70 không thì đã là quá xuất_sắc <emoji> thumbs up </emoji> chất vải dày_dặn lót lưới bên trong form hơi nhỏ và ngắn nên ai cao thì mặc sẽ hơi cộc tay_áo hơi rộng': 1, 'đúng với mô_tả đúng nha chất_liệu nỉ dày đẹp màu_sắc xanh than mua lần thứ hai rồi phải nói là shop gói hàng siêuuu kỹ ngồi gỡ ra cũng mệt <emoji> smiling face with halo </emoji> sẽ ủng_hộ shop nè 10 điểm dành cho shop <emoji> kissing face with closed eyes </emoji> chúc shop mua may bán đắt nhé': 1, 'thấy đánh_giá bảo sz nhỏ chật nên bảo shop huỷ đơn nma shop vẫn giao hai ngày là nhận được rồi mọi người chê nhiều quá nhưng mình thấy đẹp nhaa mình 46 không m58 59 mặc vừa in mặc rất thoải_mái mà giặt phai ghê lắm': 1, 'quần chất ka khi rất đẹp mầu ưng_ý dáng phon rất đứng quần giá lại bình_dân sẽ mua sóp này dài_dài': 1, 'đúng với mô_tả giống như trong hình màu_sắc đẹp chất_liệu tốt hàng giao nhanh màu xanh rất đẹp mua trên live nên được miễn_phí sip gia cũng được giảm xuống rất nhiều hàng đẹp nên mua dung màu o ngoài trong rất đẹp': 1, 'chất_liệu kaki mong đúng với mô_tả ok màu_sắc black shop tư_vấn chuẩn sz quay lại lần hai ủng_hộ shop mua hộ mọi người rất ưng lại được giá đẹp \\ufaf6 <emoji> medium light skin tone </emoji>': 1, 'chất_liệu ok đúng với mô_tả đời màu_sắc đẹp mua được giá tốt áo đẹp giao hàng nhanh_chóng sẽ ủng_hộ thêm lần tới': 1, 'chất_liệu vải nỉ bông đúng với mô_tả đúng màu_sắc thắng áo đẹp giá lại giá rẻ phù_hợp với giá tiền': 1, 'màu_sắc xanh chất_liệu len mềm chất khá ok 56 không vẫn vừa nha cổ thì không xinh hơi chật quá ý vai rộng là lộ cả luôn phần bụng bị thụng trông hơi bcuoi tí săn với giá 42 không nên ok': 1, 'chất_liệu nỉ bông đúng với mô_tả đúmm màu_sắc hồng đậm có xíu ánh tím tui mua có 137 thôi mà đẹp quá_chừng luôn nma màu không giống ảnh shop đăng lắm ảnh tui chụp tui chỉnh cho màu giống ở bngoai roii màu ảnh tui chụp y_chang bên ngoài í chỉ có màu là không đúng thôi còn lại thì quas ổn luôn ạ tui cũng kbiet diễn_tả sao nên là mấy bà coi ảnh đi nha áo này mà 200 không tui thấy còn rẻ í vải siêu dày luônnn form áo không dài lắm nên là dưới m5 mặc chỉ vừa chùm mông thôii': 1, 'chất_liệu bò đúng với mô_tả 80 màu_sắc hơi khác với trên ảnh mình cao một m55 42 không mặc sao vừa nha nhưng màu_sắc bên ngoài sẽ hơi khác hình chút nên mọi người cân_nhắc trước khi mua đc mỗi cái shop giao hàng nhanh giá_cả phù_hợp': 1, 'sản_phẩm chất_lượng tốt giá_cả phù_hợp shop đi đơn nhanh tư_vấn nhiệt_tình nữa 10 đ': 1, 'đúng với mô_tả đúng màu_sắc xanh trắng chất_liệu len áo đẹp lắm nha mọi người ơi hàng đẹp cực luôn ya ưng_ý lắm nha nên mua á': 1, 'chất_liệu đũi đúng với mô_tả rất ok ạ màu_sắc be hơi mỏng tí nma so với giá này thì không phải bàn rồi chất_lượng nha mà_còn hơi chỉ thừa ạ': 1, 'đúng với mô_tả đúng màu_sắc đẹp chất_liệu cotton mình 50 không mặc size làm vừa in đẹp luôn giá này thì không_thể chê gì được rất hài_lòng': 1, 'chất_liệu lên đúng với mô_tả có màu sắc đen áo săn sale 45 không mà đẹp thế nhỉ không bị mỏng cũng không quá dày chất mịn đẹp cảm_ơn shop nhiều lắm ạ': 1, 'đúng với mô_tả ddungs màu_sắc hồng chất_liệu kaki quần đẹp quá_trời luôn ạ vừa như in không chật tí gì giá lại còn rẻ nhữa có_điều là tự_dưng bị lộ dây chỗ cạp_quần nên nhìn không ưng lắm': 1, 'chất_liệu thun lạnh màu sắc đen đúng với mô_tả đúng với mô_tả áo rẻ nhưng_mà mặc lên form xịn lắm nha mọi người ơi': 1, 'chất_liệu len siêu xinh nha ae uy_tín chất_lượng ae xem là biết shop siêu uy_tín': 1, 'sản_phẩm đẹp giao nhanh áo đẹp lắm nha mọi ngừoi nên mua với giá tiền này ạ': 1, 'áo form rộng mặc thoải_mái áo giống hình nhận được hàng mà ưng lắm mọi người ơi <emoji> face with hand over mouth </emoji> <emoji> face with hand over mouth </emoji> nên mua nha': 1, 'giao nhanh nhưng đặt size làm lại giao thành size xl mặc vào vẫn ngắn tay <emoji> very very happy face or smiley </emoji> tiền nào của đấy mặc chống cháy hoặc ở nhà thì ok chứ đi đường phải mặc thêm áo_phao mới chắn gió': 1, 'màu_sắc trắng sản_phẩm đúng với mô_tả áo chất vải mềm mịn mặc vào trời se lạnh thì ấm_áp còn không thì sẽ hơi nóng đường may đẹp tinh_tế mình một m43 40 không thì mặc vào hơi rộng bạn nào cao hơn mặc vào sẽ đẹp hơn': 1, 'chất_liệu vải kaki đúng với mô_tả ok màu sắc đen shop đóng_gói kỹ_càng giao hàng đúng sản_phẩm đã chọn chúc shop bán đắt <emoji> red heart </emoji> ️': 1, 'màu sắc đen đúng với mô_tả suất sắc luôn ạ chất_liệu lụa ưng lắm nha mọi người ơi nhưng_mà muốn chắc_chắn hơn thì đem ra tiệm may thêm đường nữa cho chắc_ăn nên mua nha anh shipper nói_chuyện dịu_dàng quá ưng lắm nha <emoji> red heart </emoji>': 1, 'chất_liệu nỉ màu sắc đen áo đẹp ấm mũ to tay bồng m m52 mặc chùm mông chủ shop cte săn live được áo giá rẻ nên mua nha mọi người': 1, 'đúng với mô_tả như trên chất_liệu vải thunn màu_sắc trắng giao hàng nhanhhhh áo đẹp lắm luôn lên from đẹp': 1, 'chất_liệu khoác nỉ đúng với mô_tả đúng với mô_tả màu_sắc nâu áo chất_liệu nỉ áo đẹp khỏi bàn nam_nữ đều mặc đc vải không quá dày cũng không quá mỏng nói_chung đẹp giá vừa rẻ lại đc áo đẹp nv xuất_sắc lun shipper thân_thiện': 1, 'vải đẹp chuẩn form giao hàng nhanh': 1, 'chất_liệu vải nỉ màu_sắc nâu đúng với mô_tả đúng nha áo mang đẹp nha chất vải mềm rất_chi_là ok luôn á m50 mang qua mông luôn nha chất áo màu siêu đẹp giá quá chi là rẻ 10 điểm nên mua nhaaaa': 1, 'đúng với mô_tả đúng màu sắc đen chất_liệu vải hàng đẹp lắm nha đúng miêu_tả giao rất nhanh hàng rẻ mà đẹp': 1, 'đúng với mô_tả yes màu_sắc vàng <emoji> happy face or smiley </emoji> chất_liệu len len mỏng lắm nha tr màu hơi vàng không phải be mặc ổn cổ cao ấm dec mỗi cái cổ áo <emoji> very happy face or smiley </emoji> giá này hợp_lí r có chỉ thừa': 1, 'màu_sắc tyuio chất_liệu tyui đúng với mô_tả rewas tyuioplkjhgf': 1, 'rẻ nên mua hai cái lunn giao hàng hơi lâu may_mà về kịp để mặc đi chơi <emoji> rolling on the floor laughing </emoji> chất đẹp không quá mỏng cũng không quá dày mỗi_tội cái cổ hơi khó thở ạ 凉_凉_凉 form thì ôm sát người đẹp lắm': 1, 'đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc giao hàng nhanh nhẹ nói_chung là ổn': 1, 'mình nhận hàng rồi nha cho shop năm sao luôn không nghĩ giá rẻ mà sản_phẩm chất_lượng vậy': 1, 'màu_sắc xanh than đúng với mô_tả đúng chất_liệu nỉ pha poly giao hàng nhanh sản_phẩm y hình chữ jump nhỏ hơn trong ảnh shop xíu thuii so với giá là quá ok nhenn sẽ mua thêmm tay_áo hơi ngắn hợp với ng thấp như mình': 1, 'vải tăm nha mặc được đẹp lắm luôn mặc đi chơi trung_thu là ok nè chốt nhé': 1, 'chất vải xấu như áo cũ mua về không mặc dk ln': 1, 'tè vải đến kiểu_dáng đẹp hú_hồn mh không nghĩ vài chục mà mua đc chiếc quần cưng như này chiều dài 104 cm mh rất ưng': 1})\n","cmtid Counter({13281399038: 1, 12198892833: 1, 13288012286: 1, 11695680345: 1, 13032398614: 1, 10773911801: 1, 10353479733: 1, 10361190868: 1, 12916112142: 1, 13171558530: 1, 13279627917: 1, 13174531792: 1, 10824538850: 1, 12411669577: 1, 13043330656: 1, 13230909507: 1, 13293975188: 1, 13239770552: 1, 13203451536: 1, 13026349329: 1, 13168540098: 1, 12590934663: 1, 12878774770: 1, 13284156815: 1, 11671891913: 1, 12507022926: 1, 12736590979: 1, 13080275378: 1, 13274015829: 1, 13253813454: 1, 12863431964: 1, 12479328586: 1, 13270280667: 1, 12268799974: 1, 13181950170: 1, 10878161909: 1, 12546778742: 1, 12886221522: 1, 13301745337: 1, 10375194497: 1, 12882096049: 1, 13135736549: 1, 13253931275: 1, 13008380679: 1, 13007857981: 1, 12642082708: 1, 12770070378: 1, 13011841077: 1, 10749423027: 1, 13257833589: 1, 13141909654: 1, 10537769807: 1, 13108396567: 1, 13026017547: 1, 12488721752: 1, 13249543961: 1, 13273787350: 1, 12163393239: 1, 12990853401: 1, 12968555355: 1, 13111062328: 1, 12760032692: 1, 12870257730: 1, 13274291503: 1, 12996799785: 1, 13340973152: 1, 13262883099: 1, 13289265334: 1, 1025695049: 1, 13164019419: 1, 10833583297: 1, 12874523003: 1, 13314054538: 1, 13026403206: 1, 12944591420: 1, 11833577193: 1, 12970412506: 1, 13054370142: 1, 13008275877: 1, 13200167512: 1, 10571370401: 1, 13132516099: 1, 13198955424: 1, 12860404226: 1, 12025830907: 1, 12871690924: 1, 13191367976: 1, 12267016546: 1, 12930057041: 1, 12615634251: 1, 13022509924: 1, 12067423361: 1, 12962298180: 1, 12886215811: 1, 13183726245: 1, 13217708181: 1, 13285720669: 1, 12899246613: 1, 13296240686: 1, 12897181932: 1, 10814177612: 1, 12971792037: 1, 13044000850: 1, 11638744163: 1, 13228162541: 1, 12119184392: 1, 12135749311: 1, 13306086209: 1, 13256010031: 1, 13010399907: 1, 12469793056: 1, 13302058413: 1, 12394801704: 1, 13244672161: 1, 12137185774: 1, 9716866702: 1, 12620055551: 1, 10680537778: 1, 12306569710: 1, 13323868125: 1, 11225710853: 1, 13230086706: 1, 12417356857: 1, 12891280057: 1, 13178941628: 1, 11964848499: 1, 13090801587: 1, 12848561060: 1, 13237555354: 1, 13341445417: 1, 13104103685: 1, 13149792153: 1, 10893683350: 1, 7102215502: 1, 13159756239: 1, 13170759722: 1, 13269348251: 1, 6283455819: 1, 13318626611: 1, 12358154680: 1, 12933879441: 1, 12782597752: 1, 13095165330: 1, 12906120442: 1, 11605138755: 1, 12727077974: 1, 13180852081: 1, 12948560132: 1, 12160661378: 1, 12973791656: 1, 13076559778: 1, 12371008994: 1, 12992989098: 1, 13186224830: 1, 9958349748: 1, 13245580005: 1, 12561707427: 1, 13084057284: 1, 12807959000: 1, 13330330747: 1, 13255454365: 1, 12628639646: 1, 12855636815: 1, 12938597655: 1, 13115386435: 1, 11750537326: 1, 12437601649: 1, 13038460768: 1, 12797650862: 1, 10832847638: 1, 12990872891: 1, 12830988753: 1, 12760781935: 1, 12280051239: 1, 12998265303: 1, 12256521034: 1, 13247722289: 1, 13121528771: 1, 12612223119: 1, 12234011659: 1, 12544095878: 1, 13159835416: 1, 12065864665: 1, 12585150675: 1, 12871131979: 1, 12352726771: 1, 12982780896: 1, 13140042300: 1, 11498702022: 1, 13252959603: 1, 13328609265: 1, 11829631903: 1, 13260744607: 1, 13038429754: 1, 13235658301: 1, 13029163284: 1, 13244382781: 1, 6417322638: 1, 7328230113: 1, 13134894419: 1, 11948322115: 1, 13078298941: 1, 12846462987: 1, 12921012603: 1, 11480068808: 1, 10668256656: 1, 13211099713: 1, 12383838505: 1, 13245703493: 1, 11608333477: 1, 11529783187: 1, 12989692394: 1, 13079504151: 1, 13097166185: 1, 13239621971: 1, 13182588775: 1, 12637499158: 1, 13186975439: 1, 13192437937: 1, 13175509542: 1, 13144472412: 1, 11320379440: 1, 12610447526: 1, 12563988690: 1, 12665590202: 1, 13070322729: 1, 12883633090: 1, 13116906729: 1, 13285823909: 1, 13232751351: 1, 12729259062: 1, 12867059435: 1, 13164969838: 1, 12795992490: 1, 13091661626: 1, 13332857221: 1, 13038307677: 1, 13171745789: 1, 12720299937: 1, 13123673714: 1, 13106235215: 1, 12622247169: 1, 13003587990: 1, 13208562772: 1, 13273575442: 1, 10674243414: 1, 13170384872: 1, 13079623867: 1, 13258244727: 1, 13277848720: 1, 10751788635: 1, 12528901917: 1, 13255835599: 1, 13260211429: 1, 10213951970: 1, 12989213961: 1, 12214022680: 1, 12645453502: 1, 12441900524: 1, 11835042567: 1, 12407390858: 1, 12805850880: 1, 12910144521: 1, 12693290903: 1, 13280071513: 1, 12853541774: 1, 13053692374: 1, 13297890522: 1, 13227307206: 1, 13200510273: 1, 12842734854: 1, 12591570701: 1, 13044032948: 1, 13160439400: 1, 12861455806: 1, 13278764661: 1, 12563669864: 1, 12537900642: 1, 12371890908: 1, 11196019962: 1, 6277181889: 1, 13188196835: 1, 13038747660: 1, 13125315357: 1, 12371215920: 1, 12662840091: 1, 13323083413: 1, 12961779171: 1, 12218145292: 1, 13307717257: 1, 11278839235: 1, 13274120293: 1, 13345744134: 1, 13154206315: 1, 12564152237: 1, 12626247367: 1, 12967427776: 1, 12502489602: 1, 13345935353: 1, 12639849781: 1})\n"]},{"data":{"text/html":["\n","  <div id=\"df-030a8d74-4401-4ea1-999a-9fa189747362\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tuanna21411</th>\n","      <th>uyennnp21411</th>\n","      <th>anhnhn21411</th>\n","      <th>tamta21411</th>\n","      <th>nguyennt21411</th>\n","      <th>text</th>\n","      <th>cmtid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Neutral</td>\n","      <td>đúng với mô_tả kho xấu</td>\n","      <td>13281399038</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Neutral</td>\n","      <td>24 không một đôi mẹ ơi</td>\n","      <td>12198892833</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>đúng với mô_tả đặt áo_khoác mà giao cái qq gì ...</td>\n","      <td>13288012286</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Neutral</td>\n","      <td>giao thiếu hàng</td>\n","      <td>11695680345</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Positive</td>\n","      <td>Neutral</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả đúng màu_sắc nâu chất_liệu vải ...</td>\n","      <td>13032398614</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>mình nhận hàng rồi nha cho shop năm sao luôn k...</td>\n","      <td>12626247367</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>màu_sắc xanh than đúng với mô_tả đúng chất_liệ...</td>\n","      <td>12967427776</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>vải tăm nha mặc được đẹp lắm luôn mặc đi chơi ...</td>\n","      <td>12502489602</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>chất vải xấu như áo cũ mua về không mặc dk ln</td>\n","      <td>13345935353</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>tè vải đến kiểu_dáng đẹp hú_hồn mh không nghĩ ...</td>\n","      <td>12639849781</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-030a8d74-4401-4ea1-999a-9fa189747362')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-030a8d74-4401-4ea1-999a-9fa189747362 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-030a8d74-4401-4ea1-999a-9fa189747362');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8db8b9f5-ea3a-48a3-bb8a-db48f6604a6a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8db8b9f5-ea3a-48a3-bb8a-db48f6604a6a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8db8b9f5-ea3a-48a3-bb8a-db48f6604a6a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["    tuanna21411 uyennnp21411 anhnhn21411 tamta21411 nguyennt21411  \\\n","0      Negative     Negative    Negative   Negative       Neutral   \n","1       Neutral      Neutral    Negative   Negative       Neutral   \n","2      Negative     Negative    Negative   Negative      Negative   \n","3       Neutral      Neutral    Negative   Negative       Neutral   \n","4      Positive      Neutral    Positive   Positive      Positive   \n","..          ...          ...         ...        ...           ...   \n","295    Positive     Positive    Positive   Positive      Positive   \n","296    Positive     Positive    Positive   Positive      Positive   \n","297    Positive     Positive    Positive   Positive      Positive   \n","298    Negative     Negative    Negative   Negative      Negative   \n","299    Positive     Positive    Positive   Positive      Positive   \n","\n","                                                  text        cmtid  \n","0                               đúng với mô_tả kho xấu  13281399038  \n","1                               24 không một đôi mẹ ơi  12198892833  \n","2    đúng với mô_tả đặt áo_khoác mà giao cái qq gì ...  13288012286  \n","3                                      giao thiếu hàng  11695680345  \n","4    đúng với mô_tả đúng màu_sắc nâu chất_liệu vải ...  13032398614  \n","..                                                 ...          ...  \n","295  mình nhận hàng rồi nha cho shop năm sao luôn k...  12626247367  \n","296  màu_sắc xanh than đúng với mô_tả đúng chất_liệ...  12967427776  \n","297  vải tăm nha mặc được đẹp lắm luôn mặc đi chơi ...  12502489602  \n","298      chất vải xấu như áo cũ mua về không mặc dk ln  13345935353  \n","299  tè vải đến kiểu_dáng đẹp hú_hồn mh không nghĩ ...  12639849781  \n","\n","[300 rows x 7 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["annotater_data = {k: [] for k in annotater2id.keys()}\n","annotater_data.update({\n","    'text': [],\n","    'cmtid': []\n","})\n","\n","for data in datas:\n","\n","  temp_dict = {i: 'None' for i in annotater_data.keys()}\n","  temp_dict['text'] = data['content']\n","  temp_dict['cmtid'] = data['metadata']['cmtid']\n","\n","  for classification in data['classifications']:\n","    label = classification['classname']\n","\n","    for annotator in classification['classified_by']:\n","      name = annotator['annotator'].split(\"@\")[0]\n","\n","      temp_dict[name] = label\n","\n","  for k, v in temp_dict.items():\n","    annotater_data[k].append(v)\n","\n","drop_columns = []\n","for k, v in annotater_data.items():\n","  if Counter(v).get('None', 0) >= len(datas) * 0.1:\n","    drop_columns.append(k)\n","    continue\n","\n","  print(k, Counter(v))\n","\n","annotater_df = pd.DataFrame.from_dict(annotater_data)\n","annotater_df = annotater_df.drop(drop_columns, axis = 1)\n","annotater_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":849,"status":"ok","timestamp":1701979556525,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"Y_tIVflDjVQ1","outputId":"fddedb21-0412-4168-b7cc-362785951755"},"outputs":[{"data":{"text/plain":["0.6819902671886527"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from statsmodels.stats.inter_rater import aggregate_raters, fleiss_kappa\n","\n","fleiss_matrix, categories = aggregate_raters(annotater_df.drop(['text', 'cmtid'], axis = 1))\n","kappa = fleiss_kappa(fleiss_matrix)\n","kappa"]},{"cell_type":"markdown","metadata":{"id":"4xQkgZdRcqBc"},"source":["Sau khi đặt ra các quy tắc, nhóm tiến hành cùng nhau gắn thẻ 300 bình luận đầu tiên. Độ đồng thuận ban đầu chỉ đạt 68%, ở mức độ tốt. Tuy nhiên, để mô hình huấn luyện tốt nhất, nhóm tiến hành thảo luận và gán lại nhãn của dữ liệu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1701979556525,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"pQPpm5qpB8Et","outputId":"3573a7a9-c802-4401-be64-30272a2be0fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["125\n"]},{"data":{"text/html":["\n","  <div id=\"df-a2b33d56-11e2-4f2b-b637-a56149bb0fec\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>annotated</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13281399038</td>\n","      <td>[Negative, Negative, Negative, Negative, Neutral]</td>\n","      <td>đúng với mô_tả kho xấu</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12198892833</td>\n","      <td>[Neutral, Neutral, Negative, Negative, Neutral]</td>\n","      <td>24 không một đôi mẹ ơi</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11695680345</td>\n","      <td>[Neutral, Neutral, Negative, Negative, Neutral]</td>\n","      <td>giao thiếu hàng</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13032398614</td>\n","      <td>[Positive, Neutral, Positive, Positive, Positive]</td>\n","      <td>đúng với mô_tả đúng màu_sắc nâu chất_liệu vải ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10353479733</td>\n","      <td>[Neutral, Negative, Negative, Negative, Neutral]</td>\n","      <td>màu sắc đen chất mỏng</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>13003587990</td>\n","      <td>[Positive, Neutral, Positive, Neutral, Neutral]</td>\n","      <td>chất_liệu ok đúng với mô_tả được màu_sắc đẹp t...</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>13255835599</td>\n","      <td>[Neutral, Negative, Negative, Negative, Neutral]</td>\n","      <td>màu_sắc dbdj đúng với mô_tả nsjsj chất_liệu mỏ...</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>13227307206</td>\n","      <td>[Negative, Negative, Positive, Positive, Posit...</td>\n","      <td>màu_sắc xanh chất_liệu len mềm chất khá ok 56 ...</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>12842734854</td>\n","      <td>[Positive, Positive, Neutral, Neutral, Positive]</td>\n","      <td>chất_liệu bò đúng với mô_tả 80 màu_sắc hơi khá...</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>13274120293</td>\n","      <td>[Positive, Neutral, Neutral, Positive, Positive]</td>\n","      <td>đúng với mô_tả yes màu_sắc vàng &lt;emoji&gt; happy ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b33d56-11e2-4f2b-b637-a56149bb0fec')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a2b33d56-11e2-4f2b-b637-a56149bb0fec button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a2b33d56-11e2-4f2b-b637-a56149bb0fec');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b383dc56-5945-4b66-b3b3-e436756e0416\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b383dc56-5945-4b66-b3b3-e436756e0416')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b383dc56-5945-4b66-b3b3-e436756e0416 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["           cmtid                                          annotated  \\\n","0    13281399038  [Negative, Negative, Negative, Negative, Neutral]   \n","1    12198892833    [Neutral, Neutral, Negative, Negative, Neutral]   \n","2    11695680345    [Neutral, Neutral, Negative, Negative, Neutral]   \n","3    13032398614  [Positive, Neutral, Positive, Positive, Positive]   \n","4    10353479733   [Neutral, Negative, Negative, Negative, Neutral]   \n","..           ...                                                ...   \n","120  13003587990    [Positive, Neutral, Positive, Neutral, Neutral]   \n","121  13255835599   [Neutral, Negative, Negative, Negative, Neutral]   \n","122  13227307206  [Negative, Negative, Positive, Positive, Posit...   \n","123  12842734854   [Positive, Positive, Neutral, Neutral, Positive]   \n","124  13274120293   [Positive, Neutral, Neutral, Positive, Positive]   \n","\n","                                                  text  \n","0                               đúng với mô_tả kho xấu  \n","1                               24 không một đôi mẹ ơi  \n","2                                      giao thiếu hàng  \n","3    đúng với mô_tả đúng màu_sắc nâu chất_liệu vải ...  \n","4                                màu sắc đen chất mỏng  \n","..                                                 ...  \n","120  chất_liệu ok đúng với mô_tả được màu_sắc đẹp t...  \n","121  màu_sắc dbdj đúng với mô_tả nsjsj chất_liệu mỏ...  \n","122  màu_sắc xanh chất_liệu len mềm chất khá ok 56 ...  \n","123  chất_liệu bò đúng với mô_tả 80 màu_sắc hơi khá...  \n","124  đúng với mô_tả yes màu_sắc vàng <emoji> happy ...  \n","\n","[125 rows x 3 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["error_sentences = []\n","for index, row in annotater_df.iterrows():\n","  values = list(row.to_dict().values())[:len(annotater2id)]\n","  if len(set(values)) > 1:\n","    error_sentences.append(\n","          {'cmtid': row['cmtid'],\n","          'annotated': values,\n","           'text': row['text']}\n","        )\n","\n","print(len(error_sentences))\n","\n","error_df = {i: [] for i in error_sentences[0].keys()}\n","for i in error_sentences:\n","  for k, v in i.items():\n","    error_df[k].append(v)\n","\n","error_df = pd.DataFrame.from_dict(error_df)\n","error_df"]},{"cell_type":"markdown","metadata":{"id":"zCJ6lg2OdkBU"},"source":["Nhóm xác định các bình luận có nhãn chênh lệch nhiều để tiến hành cùng nhau đánh giá lại."]},{"cell_type":"markdown","metadata":{"id":"kR23-2SYdKDP"},"source":["### Lần 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yI_c7X2va_gK"},"outputs":[],"source":["import json\n","\n","with open(path.join(val_path, 'val-reannotated_annotations.json'), 'r') as f:\n","    datas_2 = json.load(f)['examples']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1701979560616,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"3-zRphSqbYZc","outputId":"0dca7a44-10e9-4d93-a418-ed61969e4fc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["uyennnp21411 Counter({'Positive': 114, 'Negative': 106, 'Neutral': 80})\n","anhnhn21411 Counter({'Positive': 117, 'Negative': 116, 'Neutral': 67})\n","tamta21411 Counter({'Negative': 113, 'Positive': 110, 'Neutral': 77})\n","nguyennt21411 Counter({'Positive': 114, 'Negative': 107, 'Neutral': 79})\n","tuanna21411 Counter({'Positive': 116, 'Negative': 111, 'Neutral': 72, 'None': 1})\n","text Counter({'nói_chung là xấu vải áo xấu lắm': 1, 'giao bé quá thất_vọng': 1, 'màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ bông áo vải không dày không mỏng mình thích mặc rộng nên chọn size lớn sợ rộng nhma vừa in m6 40 không qua mông nhé': 1, 'chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ngoài đời còn đẹp hơn trên hình': 1, 'màu sắc đen chất mỏng': 1, 'áo kiểu gì mà tay dài tay ngắn không hiểu shop làm kiểu gì luôn': 1, 'tặng vớ đã đi rồi': 1, 'màu_sắc tyuio chất_liệu tyui đúng với mô_tả rewas tyuioplkjhgf': 1, 'chất_liệu mỏng như lá lúa mặc có phần khó_chịu đúng với mô_tả giao_diện đúng khoảng 80 màu_sắc đặt màu be mà nó về màu vàng vỏ chuối <emoji> happy face or smiley </emoji> khuyến_cáo mọi người nên cân_nhắc <emoji> thumbs up </emoji>': 1, 'màu sắc đen chất_liệu vải xấu vậy tưởng cái dẻ lau nhà thôi_thì giá rẻ không đòi_hỏi <emoji> smiling face with hearts </emoji>': 1, 'đúng với mô_tả đúng mô_tả màu sắc đen chất_liệu thun gân tăm shop giao thiếu hàng mua hai tính tiền hai nhận được một': 1, 'mua áo_khoác mà giao quần trẻ_con là sao vậy shop': 1, 'quá tệ đặt cái áo giao cái quần trẻ_con cho ai mặc không biết làm_ăn vớ_vẩn lừa_đảo không nên mua nhé mọi người': 1, 'chất_liệu rẻ màu_sắc den trắng đúng với mô_tả hơi hơi': 1, 'quần quá xấu mình một m50 42 không mua size sao mông mình thuộc dạng mông lép nhưng phần hông quần quá chật kéo không qua đc mông phần eo thì quá rộng eo 63 nhưng thừa hẳn sáu tám cm <emoji> loudly crying face </emoji> … quần thiết_kế quá tệ hông thì chật eo thì rộng xoè ra mang đi sửa mà thợ sửa quần cũng lắc_đầu vì chưa thấy cái quần nào tệ đến vậy chỉ thừa tua_tủa mang về đi sửa hết 50 không nhưng cuối_cùng cũng chỉ để làm dẻ lau thôi không nên mua nhé mọi người': 1, 'mỏng xấu không lên được from … thất_vọng về shop không chịu được': 1, 'tất bị rách nên cho shop một sao': 1, 'đúng với mô_tả không đúng mô_tả chất_liệu mềm màu_sắc xám đen không đúng hàng đã đặt quá rộng màu xấu shop làm_việc không có_tâm': 1, 'hàng nhanh rách mọi người không lên mua': 1, 'màu_sắc nâu chất_liệu vải đúng với mô_tả không đúng to rất to như chi người 60 70 ng mặc í': 1, 'quá xấu quần không_thể mặc màu cũ hơn rất nhiều so với trên hình dơ': 1, 'đúng với mô_tả không biết màu_sắc không biết chất_liệu không biết đặt_hàng hiện chín quà tặng nhưng lúc nhận hàng không có nên chả biết đánh_giá như nào không tặng thì đừng làm thế khách_hàng tưởng có thật <emoji> very happy face or smiley </emoji>': 1, 'chất_liệu xấuu màu_sắc mua màu trắng về màu nâu đúng với mô_tả xấu chê xấu jxheudncbkandvhdbyv': 1, 'chất_liệu không giống ảnh con_em tao cứ đòi mua xong nó trẻ_con nó mới thấy đẹp chứ tao thấy xấu vl chất_liệu xấu kinh <emoji> very very happy face or smiley </emoji>': 1, 'đúng với mô_tả không đúng tí nào màu_sắc đem chất_liệu mỏng vãi thất_vọng tràn_trề không còn gì để nói_xấu mỏng không xứng_đáng với giá tiền tí naog chê nha đừng mua nha mọi người khuyên chân_thật đã thế còn rách nữa chứ <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji> <emoji> pouting face </emoji>': 1, 'áo thì xù lông xù lá hàng lỏ sản_phẩm không đúng với hình_ảnh dell nên muaa dell có sz riêng như cái bì xấu ik chang cái bì lun': 1, 'mọi người không nên mua ở shop này nha sản_phẩm rất tệ luôn áo như cái rẻ lau vải không ra gì rất bực_mình vì mình bỏ tiền ra mua mà nhận lại được như_vậy chưa mặc lần nào đã bị xù rồi mỏng <emoji> pouting face </emoji> <emoji> pouting face </emoji> rất thất_vọng về shop luôn không ngờ là sản_phẩm tệ như_vậy khuyên mọi người là không nên mua những sản_phẩm như thế_này': 1, 'màu_sắc không đúng đúng với mô_tả không chất_liệu tốt chất_liệu thì đc nma không có túi để tay tệ vll': 1, 'đúng với mô_tả không chất_liệu vải màu_sắc xám áo_khoác vải mỏng không phải logo thêu như trên live vải xấu nhìn như nùi dẻ vậy': 1, 'dải dù chứ không phải lụa xướt': 1, 'đúng với mô_tả không nó mỏng màu sắc đen chất_liệu vải thường nó rất mỏng không giống hình_ảnh': 1, 'chất_liệu mỏng màu_sắc không giống trên ảnh đúng với mô_tả áo không giống trên ảnh mầu xấu và mỏng còn bị lộ đường chỉ chê ạ': 1, 'chất_liệu rách phần cánh_tay đúng với mô_tả không đúng': 1, 'shipper không giao hàng làm tao hóng mãi shop bảo hối bên vận_chuyển rồi mà vẫn không thấy gì': 1, 'chất_liệu len tăm mỏng màu_sắc be áo đẹp phù_hợp với giá tiền chất len tăm mỏng nhẹ thích_hợp những ngày đông chớm lạnh mình xin sửa lại đánh giá_thành một sao vì shop gửi áo tay ngắn tay dài cho mình ai mua chú_ý nhé cảm_ơn': 1, 'đúng với mô_tả không màu_sắc den chất_liệu nỉ vải xấu cực_kì không gặp nước vài bữa là bong viền vải xù': 1, 'áo nhận về đã bị rách một đường dài dưới nách nhắn_tin cho shop thì không trả_lời': 1, 'quần rách shop không giải_quyết mua chục cái rách một cái hoàn là hoàn_tất đang cần gấp báo shop hoàn một quần thôi được không shop chả nói gì xong nhiều việc quá mình cũng quên_béng đi <emoji> unamused face </emoji> <emoji> unamused face </emoji>': 1, 'chất_liệu mỏng đúng với mô_tả không đúng_sai hoàn_toàn màu_sắc trắng nhận về mà chán mua tận 10 đôi không nghĩ như này': 1, 'làm_ăn như này không ổn đâu nhé đặt áo đi gửi cho cái quần trẻ_em làm gì vậy': 1, 'màu_sắc trắng chất_liệu mỏng áo quá mỏng không vừa người nhỏ': 1, 'đúng với mô_tả sa i mình săn trên live của shop đc giá hời cũng hi_vọng nhiều lắm ship nhanh nhưng_mà giao lộn hàng cho mình rồi nha mong shop đổi áo cho mình huhuuuuuuu': 1, 'màu sắc đen chất_liệu loại vải mềm không phải loại mịn đúng với mô_tả sai hoàn_toàn ae không nên mua khuyên ae luôn shop lừa_đảo đó hàng không đúng với ảnh': 1, 'chất_liệu vải dù màu sắc đen mặc nóng chất vải thô': 1, 'chất_liệu lừa_đảo màu_sắc xấu đúng với mô_tả đồ lừa_đảo': 1, 'shop giao hàng không đúng màu đặt màu nâu lại giao màu đen lần đầu như lần cuối sẽ không mua lại': 1, 'giao nhầm cho mình áo khác đòi hoàn hàng thì không rep áo giao nhầm thì xấu bé nhìn như dân tổ': 1, 'đúng với mô_tả shop làm_ăn gì kì vậy trên ảnh là áo_khoác mà giao quần_đùi mọi người đừng nên mua nha': 1, 'chất_liệu không màu_sắc không đúng với giờ ảnh đúng với mô_tả không lúc mua hàng đêm thì mình thấy được áo này với giá giảm sốc cứ nghĩ do săn được lúc tối nên không lo lắm ngờ_đâu lúc hàng về thì lại là cái quần này đây mình không ktra lúc ship tới cty nên về ms bóc hàng mình nhận một phần lỗi cug do mình cả_tin nhưng đến như này mình không_thể không tức': 1, 'đặt một màu giao hàng một màu không_thể chấp_nhận được nhắn_tin thì không thèm phản_hồi': 1, 'bán hàng đ có tâm gì biết là rẻ nhưng không_thể đưa cho tôi cái mà đường chỉ bung hết ở mấy chỗ khâu ống thu vào': 1, 'chất_liệu chất_liệu mỏng màu_sắc không đúng mẫu như ảnh shop chụp đúng với mô_tả chất nỉ mỏng giá ổn mọi người nên cần nhắc trước khi mua chất nỉ mỏng_mảnh hơi thật vong': 1, 'vãi không đẹp chỉ thừa nhiều': 1, 'tao đặt màu xanh nma ship màu hồng': 1, 'màu_sắc đúng màu đúng với mô_tả không ấm mà_còn mỏng nữa không nên mua chất_liệu mỏng': 1, 'áo chất vải được mà shop làm_ăn như cc gửi hàng lỗi cho giờ mình khiếu_nại mà không rep săn sal được giá rẻ nma cubgx đ đáng không mặc được <emoji> very very happy face or smiley </emoji>': 1, 'màu_sắc be chất_liệu nhung tâm đúng với mô_tả dell nha tr quần xấu er mấy bây đừng có mua quần này hai nói thiệt quần này xấu lắm vải thì mỏng nhìn xuyên thấu bên trong luôn á bây với_lại nó không có đứng fom như mẫu mặc đâu thật đấy hai là người đi trước hai biết <emoji> smiling face with halo </emoji> <emoji> broken heart </emoji>': 1, 'màu_sắc màu be đúng với mô_tả không đúng chất_liệu vải hàng chất_lượng kém mài sắc không giống trong hình cực_kì xấu <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji> <emoji> thumbs down </emoji> <emoji> light skin tone </emoji>': 1, 'đúng với mô_tả không chất_liệu vải màu_sắc trắng không nên mua không đáng tiền mỏng te xấu nữa chán shop': 1, 'chất_liệu vair vải xấu một m6 50 không mang ngắn vãi': 1, 'mình không_thể tưởng đc hàng lại xấu như_vậy mô_tả áo thể_thao nỉ bông dầy_dặn mà mỏng_tang đường may kiểu_dáng tóm_lại là không_thể mặc và không dám cho ai': 1, 'màu_sắc đẹp đúng với mô_tả không giống chất_liệu xấu không đẹp như hình': 1, 'màu_sắc đẹp như không đúng trong lòng chất_liệu không ₫ đúng với mô_tả không giống trong hình áo_khoác xanh ở hai cái vòng_tay màu khác cuối cái áo rất thất_vọng': 1, 'màu_sắc không chất_liệu không đúng với mô_tả không không nên mua nhé mọi người nó giao về không pk áo mà là cái rẻ á mọi người <emoji> pouting face </emoji> <emoji> pouting face </emoji>': 1, 'đúng với mô_tả rất tệ màu_sắc ổn chất_liệu mỏng rất rộng không biết sz như nào nhưng mang rất rộng và nhiều chỉ thừa': 1, 'màu_sắc đẹp chất_liệu vãi hơi cứng hàng đẹp tốt hàng hơi chậm': 1, 'màu_sắc đung mau chất_liệu không đung chất khi quang cao': 1, 'chất_liệu nỉ đúng với mô_tả xấu màu_sắc xấu áo xấu vl mỏng thật vọng tràn_trề lần cuối_cùng mua ở shop mà bán đắt vl thề chê': 1, 'shop gửi nhầm màu áo mong shop xem_lại ạ': 1, 'đúng với mô_tả không hề mua áo_khoác giao khẩu_trang <emoji> thumbs down </emoji> <emoji> angry face </emoji>': 1, 'chất_liệu in cũng xấu đúng với mô_tả chất xấu màu_sắc không đẹp không nên mua có size dưới55 mà mik có 36 không đã chật': 1, 'gửi nhầm màu quần kêu đổi ừ à đợi mấy ngày hôm_nay không thấy đâu yêu_cầu shop đổi lại đúng màu quần đặt đặt màu xám giao màu xanh không gquyet được thì hoàn hàng và giả tiền <emoji> slightly smiling face </emoji> làm_ăn kiểu gì kbiet': 1, 'quần lộ rõ quần chíp đánh_giá một sao': 1, 'chưa bao_giờ đánh_giá khi mua hàng shoppe mà nay nhận đc cái áo quá thất_vọng gặp thêm cái màu nâu nữa nhìn chán vãi đúng là tiền_nào_của_nấy': 1, 'sản_phẩm không giống ảnh': 1, 'đúng với mô_tả đúng mình thấy áo cũng đẹp mình m57 mặc size m hơi rộng quá qua mông chút nhưng_mà chắc shop kiểm hàng không kĩ lúc mình nhận thì cái ống tay nó bị bung chỉ một lỗ xong mình khâu lại cũng ok rồi mong shop lần sau rút kinh_nghiệm': 1, 'màu_sắc đúng chất_liệu tệ đúng với mô_tả xấu không nên mua': 1, 'chất_liệu bình_thường màu_sắc cũ đúng với mô_tả không quần cũ lắm luôn ý màu quần ngã vàng ố không chịu được luôn vàng như để tồn_kho lâu lắm luôn rồi á trên hình màu sáng hơn ngoài mình mua đồ hai hand cũng không cũ như này luôn tưởng hàng cho không ạ': 1, 'đặt hai cái áo mà shop giao một quần trẻ_con không liên_quan gọi sdt thì không đúng nhắn_tin thì không trả_lời bán hàng thiếu uy_tín quá': 1, 'màu_sắc hdhsi ts síib iwkah ịn sjkao ssyysg sókcb vavva xhxhh sbshxhka jzjzbb haihx kskzkxb sijs kzjbzbaj zjzkjxv kskzbbxk diixjxhxbk': 1, 'chất_liệu mỏng màu_sắc tạm tay_áo không đúng với trên ảnh rộng nói_chung là cheeeee': 1, 'giao hàng thiếu số_lượng câu trả_lời của shop không hài_lòng và được thích_đáng nên đánh_giá một': 1, 'đúng với mô_tả xấu vãi ò chất_liệu vải màu_sắc xám hàng đểu không nên mua ạ': 1, 'giá rẻ nhưng áo xấu bạn nào lùn với gầy thì không nên mua nha': 1, 'màu_sắc trắng chất_liệu len tăm áo mỏng mặc thấy hết đồ bên trong xong đã thế mới mặc lần đầu đã bung hết chỉ ở tay_áo với vai cơ': 1, 'áo ngắn không_thể hoàn hàng': 1, 'shop ghi là 15 quà tặng mà kiếm quài không thấy một món quà tặng nào không hiểu sao ạ': 1, 'màu_sắc không đúng như hình tệ hàng giao không đúng như video mua áo lại giao cho quần trẻ_em nói_chung là tệ chê': 1, 'màu sắc đen đúng với mô_tả không đúng chất_liệu vải quần rất là mỏng quần gì mà không có túi gì hết ấy': 1, 'đăng quần kiểu này giao kiểu kia chịu_thua luôn á ghét nhất hoàn hàng lâu_lắc đóng_gói thì kiểm_tra kĩ giùm cái <emoji> folded hands </emoji>': 1, 'chất_liệu vải màu_sắc xám đúng với mô_tả không áo mất cúc rồi hoàn_trả áo về shop xonh hoàn xomg shop không đồng í hoàn lại tiền rồi giờ mất luôn áo mất luôn tiền <emoji> grinning face </emoji>': 1, 'giao thiếu một cái nhắn tị rep chậm shop hỏi stk để bank r tớ nói giá thì nói mặc hai xl nhé là sao vậy': 1, 'chất_liệu đểu mỏng mặc chán đời đúng với mô_tả không làm rẻ lau nhà ổn': 1, 'cắt chỉ phát rách luôn ảo thật': 1, 'quần vải thì xấu chất_liệu không như hình chất_liệu trông như quần bà_già không lên mua lại lần hai': 1, 'đúng với mô_tả quá tệ ship nguyên một vết bẩn và rách vai chất_liệu mỏng màu_sắc đúng': 1, 'chất_liệu bth màu_sắc bth đúng với mô_tả không': 1, 'chất_liệu vải màu sắc đen đúng với mô_tả đúng quần khá đẹp giao hàng thì chậm ngồi đợi cả ngày không thấy shipper gọi cuộc nào mà đã ghi là không liên_hệ đc phải mất đến hai ngày thì mới nhận được hàng đáng_lẽ là có_thể nhận sớm hơn mà đã giao muộn rồi đi đây còn phải đứng đợi 30 p nữa chưa giao hàng mà đã gọi ra nhận hàng trời thì nắng chứ có mát_mẻ gì mà bắt đứng đợi 30 p phải nói là dịch_vụ giao hàng quá tệ': 1, 'đúng với mô_tả ok chất_liệu ok màu_sắc xam quá rộng đối_với mình dáng váy cũng ok nma rộng quad không mặc được': 1, 'đúng với mô_tả không đúng lắm màu sắc đen chất_liệu vải mỏng quần chất vải hơi mỏng với hơi nhiều chỉ thừa': 1, 'màu_sắc được chất_liệu mỏng đúng với mô_tả không cực_kì ngắn': 1, 'màu_sắc khác với hình_ảnh đúng với mô_tả đúng màu ở ngoài nhìn hơi cũ ống loe hơi to hình_ảnh mang tính_chất nhận xu': 1, 'không to như mình nghĩ chất vải hơi xù lông màu cũng không đẹp như trên ảnh': 1, 'màu_sắc nâu chất_liệu nỉ áo dáng khá ổn nhưng cổ bị thô do đg may': 1, 'chất_liệu dung đúng với mô_tả dung màu_sắc dung mềm như lụa mịn như nhung luôn công_nghệ penlips hiệu_ứng_son lỳ đẹp như đánh_son ạ <emoji> smiling face with heart eyes </emoji> <emoji> smiling face with heart eyes </emoji> <emoji> smiling face with heart eyes </emoji> sản_phẩm mới ra_lò nhà thắm thỏ thắm thỏ beu spa 푻풉ẩ풎_풎ỹ_풌풉ô풏품_풙â풎 풍ấ풏_푳ô풏품_풎à풚_풑풉풐풏품 푻풉풖ỷ <emoji> telephone receiver </emoji> 푩풐풐풌풊풏품 0982323267 <emoji> department store </emoji> 푨풅풅풓풆풔풔 một 0210 c1 vinhomes new center tp hà_tĩnh cs2 sn 47 nguyễn huệ thị_trấn hương_khê hà_tĩnh filler botox uy_tín longmayphongthuy thammykhongxamlan dieukhacchanmay sexybrows xoasualongmayloihong xoalaser phunmoibabylips phunmoibongdamlipstick phunmi daotaohocvienchuyennghiep': 1, 'đúng với mô_tả tay hơi ngắn síu': 1, 'mẹ ơi cái quần màu xấu ỉa luôn màu cũ bẩn bẩn như kiểu mặc nghìn lần r đem bán á màu trên ảnh còn đẹp chán màu bên ngoài ố vàng à mà sao size làm chả rộng tí nào mặc vẫn còn bó đùi đùi tôi 52 ạ': 1, 'chất_liệu vải hơi lạ đúng với mô_tả đúng màu_sắc đúng vải không dống hình nha shopp': 1, 'có một thùng đây <emoji> yawning face </emoji> <emoji> middle finger </emoji> có một_số đúng đường 凉 có một_số đúng là có phải là gì': 1, 'đúng với mô_tả không chắc chất_liệu vải thô màu_sắc be nói nnao nhỉ theo cản nhận bản_thân mik thì cái quần này nó cứ sao sao ý vải rất cứng và ngứa mặc không ưng tẹo nào nma khâu đóng hàng và giao hnagf thì rất ok mong shop cải_thiện về quần mặc dỳ giá có 59 không thì chẳng đòi chất tốt đc': 1, 'đúng với mô_tả đúng chất_liệu hik màu_sắc nâu lúc nhận hàg hơi thất_vọng áo không đc gấp gọn vô túi kiểu như gấp qua_loa rồi cho vào túi cho có vậy áo có nhiều chỉ thừa vd và ha chỉ mag tính_chất nhận xu': 1, 'chất_liệu khbt đúng với mô_tả cũng tạm vải mỏng không đẹp như ảnh chụp từ trên xuống dưới nè ru4 đi choi đi phúc của mình thì của mình thì của mình thì của mình thì của mình thì của mình thì của mình thì của bạn mình ạ em hứa là sẽ quen thôi mà ckj có_thể làm được điều đó không phải là ql m gửi tin nhắn qua yahoo tới giờ chưa bao_giờ hết': 1, 'giá_thành khá rẻ nhưng tiền nào của đấy cổ áo khi mặc lên thì lệch một bên cao một bên thấp phần bên trong lót một lớp bông mỏng không ấm là mấy không': 1, 'màu_sắc trắng đúng với mô_tả đúng chất_liệu bình_thường tất bé và mắt với tay đều được dán bằng keo <emoji> very happy face or smiley </emoji>': 1, 'chất_liệu nỉ mỏng màu sắc đen áo quá rộng và quá dài mik m58 nặng 45 không mà mặc dài gần tới đầu_gối': 1, 'giao hàng nhanh chất vải khá mềm phù_hợp với giá tiền': 1, 'sợi len ở cổ sau áo đen bị bung và áo đen nhỏ hơn áo trắng khá nhiều <emoji> slightly smiling face </emoji> <emoji> slightly smiling face </emoji> đóng_gói sản_phẩm rất đẹp và chắc_chắn': 1, 'mình đặt hai áo mà shop chỉ gửi một': 1, 'huhu chật lắm luôn í ạ mình đi sz 39 không nhích nổi em mình đi sz 34 còn hơi chật í bh đơn có 50 không mà hoàn lại thì cũng hơi lâu a': 1, 'đúng với mô_tả đúng màu_sắc be chất_liệu vải khá mềm áo mỏng lắm còn ấm hay không thì khbt giao hàng ok haks du due dieb đo ẹ u ks du rư id d sín rne iéhy eisbbd diệnuwbd đi đi đi djnsx': 1, 'đúng với mô_tả đúng chất_liệu không giống trong ảnh màu_sắc đẹp': 1, 'kiểu thì là vậy chứ áo vải mỏng lắm tay_áo ngắn mặc vào nó ngố ngố kì lắm mọi người': 1, 'chất_liệu vải màu_sắc oke đúng với mô_tả không áo mỏng nhint thấy cả bên trong lộ cả áo ngực và quá rộng nên mặc cứ tụt xuống': 1, 'chất_liệu kb màu sắc đen đúng với mô_tả dung voi mô_tả tiền nào của đấy với số tiền đấy mua bộ_đồ thì không có gì để nói': 1, 'đúng với mô_tả giống hình màu_sắc nâu chất_liệu vải áo hơi mỏng so với mk nghĩ nhìu vải thừa chất vải tuy mềm nhưng bên trong bị xù với giá tìn này thì cx ok': 1, 'huhu buần quá mới mua sz m mà rộng xong pass cho bạn mua size sao mà mua sao thì chật <emoji> rolling on the floor laughing </emoji> màu quần thì size m tao mua giống ghi xám còn sz sao giống xám đen hơn nha chất vải oki ê noi chung la tiền nào của đó nha mua cái quần sale mà cái gấu quần nó giựt lên tới cổ <emoji> very very happy face or smiley </emoji> đường may không đều hơi buần': 1, 'chật mỏng dcd ngieu tao đi ngắn chút_xíu luon cái mắt dễ rơi lắm chí_ít có quà đi kèm ba sao châm_chước': 1, 'đúng với mô_tả không đúng như mô_tả vãi bông loại vãi hay làm quần_áo hoá_trang ông_già noel ấy nó dày hơn một_tí': 1, 'size áo không đúng như mô_tả bạn nào hơi to nên cân_nhắc trước khi mua xin đổi hàng thì shop bảo qua vừa thì đổi chứ không nhận là size áo của mình có vấn_đề nhưng chất vải thì oke giao khá nhanh nên bạn mình đưa lại áo cho em mặc': 1, 'chất_liệu nóng màu_sắc nâu đúng với mô_tả đúng dáng mặc rất ok phải nói là đẹp luôn nhưng màu nâu này nó lạ lắm như màu của mấy bà_già hay mặc í nếu mua thì mình nên chọn màu khác còn với giá tiền như này là ok rồi': 1, 'thất_vọng với giá tiền áo mỏng thì không nói làm gì nhưng áo rách thế_thì không chấp_nhận được không biết shop sơ_suất hay cố_tình <emoji> very happy face or smiley </emoji>': 1, 'áo oki lắm nhưng mk đặt cỡ 55 không thì nhận đc áo chỉ mặc vừa khít cơ_thể trong khi mk mới có 40 không <emoji> woozy face </emoji> <emoji> woozy face </emoji>': 1, 'màu_sắc bóng bóng <emoji> happy face or smiley </emoji> chất_liệu hơi mỏng đúng với mô_tả binhf thuowngf mình tưởng chất vải cát cơ nhưng không bóng bóng mặc khá vừa_vặn nói_chung tiền_nào_của_nấy mua được nha hâhhahahahahhahaahhaahahhahahahahahahahaahhahaahahahahahahahahhshshshshshsshhsshshshshhshs': 1, 'vải như ức vậy': 1, 'màu_sắc trắng_đen đúng với mô_tả đúng nam_châm nhỏ không dính lắm một chiếc tất bị mất một cục nam_châm đường chỉ khâu ở hai tay lỏng_lẻo được cái giao hàng lâu <emoji> happy face or smiley </emoji>': 1, 'đúng với mô_tả khong giống lắm chất_liệu xấu màu_sắc be mình thấy chất_liệu giởm form cx xấu nhma 50 không thì cx không_thể đòi_hỏi nhiều': 1, 'màu_sắc trắng giao đủ số_lượng mình đã đặt nhưng bị dơ một đôi giao hàng nhanh ok': 1, 'đúng với mô_tả không đúng lắm chất_liệu nỉ bông pha nilong màu sắc đen và trắng áo không đẹp lắm vải khá xấu lên form khá xấu tay_áo to vãi mà thân áo có chút éc còn dài nên mặc lên hơi xấu cổ áo hơi lỗi in hình dễ tróc nên không khuyến_khích giặt máy live còn 37 không nên mặc vài lần cũng được': 1, 'áo chất vải xấu kiểu dán khác hình shop đăng nhiều đường may ẩu vạt áo hai cái không đều nhau nói_chung tiền nào của đấy áp mã gg còn 34 không nên không đòi_hỏi gì nhiều mua khoác tạm_thời tiết mua thu thôi': 1, 'màu_sắc màu hồng không có túi chất_liệu cũng được đúng với mô_tả đúng tốt nhưng không có túi': 1, 'vải bị xù nhẹ bên ngoài rất nhiều chỉ thừa nguyên một chục chỉ màu xanh không biết để làm gì này mà đem đi giặt thì xù như bông_gòn luôn nhìn tông quan thấy màu đẹp mà làm ẩu quá không thik lắm không hài_lòng với sản_phẩm': 1, 'vãi cứng màu như hình mọi người nên căn nhắc trước khi mua mặc nóng mình 42 cân mặc vừa': 1, 'màu_sắc xanh đúng với mô_tả ngắn hơn trong ảnh mẫu rất nhiều áo đẹp vãi ok dóng mẫu nhưng áo rất ngắnnn': 1, 'đúng với mô_tả hơi rộng chất_liệu vải nỉ màu_sắc xanh áo hơi rộng vải có chỉ thừa nhiều phải cắt bớt vải không mỏng cũng không dày': 1, 'vải oke nhưng_mà quần bị duột chỉ from chỗ lưng quần chưa oke cho lắm đi bóp thì oke hơn nha': 1, 'chất_liệu vải mỏng màu sắc đen đúng với mô_tả không mọi người nên cân_nhắc kỹ trước khi mua bởi mua r thì đừng hối_hận': 1, 'chất_liệu mỏng quá màu_sắc trắng đúng với mô_tả không mấy': 1, 'tất mỏng': 1, 'chất_liệu vải màu_sắc đỏ pha hồng vải khá mỏng và thô mặc lâu ngày sẽ bị sù vải': 1, 'mỏng quá': 1, 'thì cũng đẹp hơi mỏng nhưng dùng mùa hè thì rất ô ke': 1, 'tất chỉ có một size khá chật vải mỏng nhưng_mà phù_hợp với giá tiền ổn': 1, 'màu sắc đen chất_liệu nhung tăm đúng với mô_tả đúng áo có hơi mỏng nhưng màu đen sẽ không lộ rõ chỉ thừa nhiều còn có thêm vết rách nói_chung với giá_như vậy cũng ổn': 1, 'màu_sắc xanh hàng cũng đc mà hơn mỏng mua nên cân_nhắc lại <emoji> loudly crying face </emoji>': 1, 'màu_sắc đúng mô_tả chất_liệu thô xấu của nào tiền nấy': 1, 'màu_sắc vậy chất_liệu giờ đúng với mô_tả vậy nâng mũi sẽ thay_đổi như_thế_nào hành_trình nâng mũi của bạn hằng tại tmv tấm như thế_này có_thể coi là thành_công chưa ạ <emoji> backhand index pointing right </emoji> liên_hệ hotline <emoji> telephone </emoji> 0966605600 hoặc inbox fanpage để đặt lịch tư_vấn cùng bác_sĩ ngay': 1, 'màu_sắc nâu đúng với mô_tả không chất_liệu nỉ bông mặc ấm lắm nhưng không ưng cái cổ tí nào nó như kiểu sắp rụng ra ý biết là tiền_nào_của_nấy nma vẫn thất_vọng vì cũng mua của shop vài lần r': 1, 'giao hàng nhanh đầy_đủ đúng mẫu áo hơi mỏng mặc bên trong cũng ấm áo đen mới mặc đã bị rách cổ': 1, 'không nhận đc hàng': 1, 'đúng với mô_tả khác màu vải mỏng nhăn màu_sắc vàng nhạt chất_liệu vải mỏng tạm': 1, 'chất_liệu toits màu_sắc ghi shop thời_trang trí nội_thất_nghiệp và phát_triển của các chế_độ ăn_uống nước': 1, 'màu_sắc biết chất_liệu ok đúng với mô_tả không áo_khoác cardigan viền xanh nâu frmlk form rộng form freesize 65 75 không đổ lại mặc oke kích_thước dài 65 cm xem trên ảnh thứ hai của sản_phẩm phân_loại be viền xanh be viền nâu chất_liệu nỉ bông cardigan cardigannamnu cardiganformrong aocardigan aokhoac nasumay': 1, 'màu_sắc trang tất không có bọc nilon shop bọc thẳng vào nilon màu làm phai hết màu ra tất': 1, 'màu_sắc ébzsbz đúng với mô_tả vzbwhzuzw chất_liệu hxsjxsjnxe giống nhaaaaaaaaaaaaaaaaaaawwwwwaaa': 1, 'chất_liệu mỏng áo bé xíu à <emoji> smiling face with tear </emoji>': 1, 'mang hơi bị ngứa chân nha shop': 1, 'chéo liền_tay nhận ngay quà bự đi bà_con ơiiii https shp ee 8tsdt6ias3a đã được <emoji> check mark button </emoji> miêu_tả khoa_học <emoji> test tube </emoji> là sao <emoji> star </emoji> ️ lại có <emoji> thumbs up </emoji> thôi em không có <emoji> thumbs up </emoji>': 1, 'đúng với mô_tả hơi rộng chất_liệu vải nỉ màu_sắc nâu đặt áo không mũ mà gửi áo có mũ shop đóng_gói sơ_sài': 1, 'rộng lắm phải đi sửa lại': 1, 'màu_sắc trắng chất_liệu đẹp hơn vải màu đen đúng với mô_tả 70 ship hơi chậm vải đẹp hơn áo đen': 1, 'chất_liệu vải đúng với mô_tả vải không jiong hình lắm màu_sắc đúng mô_tả chất vải không giống mô_tả lắm m không rành nên không biết có phải vải đũi không quần rất dài phù_hợp với ng có chiều cao lý_tưởng giá rẻ vậy thì chất_lượng tương_ứng với tiền mọi người cứ cân_nhắc trước khi mua': 1, 'hàng một size mà kích_thước không bằng nhau shop giải_thích do gia_công shop cũng đồng_ý hoàn hàng tặng shop hai sao còn sản_phẩm thì chỉ một sao so với m 56 không m60 mặc bị cộc bạn nào nhẹ_kí mặc một mùa chắc oki m đưa vào đánh_giá để mọi người biết nha': 1, 'vải đẹp nhưng nhận được hàg có một cái bị rách ngag vai <emoji> very very happy face or smiley </emoji> trừ sao ảnh mag tínb chất minh_hoạ': 1, 'đúng với mô_tả không giống lắm màu_sắc xấu chất_liệu biết màu xấu': 1, 'đặt màu hồng giao màu be': 1, 'mình đã nhận được hàng giao hàng nhanh_chóng đóng_gói cẩn_thận nhưng vải mỗi lần đều khác nhau về chất và màu': 1, 'màu_sắc hồng phấn màu đẹp lăm nhma chất thì mỏng quá cứ sợ lộ sao ấy ạ': 1, 'màu trông hơi bẩn andvhskawgzgsiwvshdhjehedv': 1, 'tất hơi mỏng tạm được': 1, 'chất_liệu mỏng màu_sắc đúng màu chất len mỏng hơn so với mh mua lần đầu': 1, 'mỏng vcl': 1, 'ok nhưng chỉ thừa hơi nhiều': 1, 'đúng với mô_tả đúng chất_liệu mỏng không có túi màu_sắc xanh áo đc nhưng không có túi': 1, 'đúng với mô_tả tạm cùng mã nhưng sản_phẩm có màu chênh_lệch chút len bị xù cảm_thấy không hài_lòng': 1, 'shop giao hàng nhanh đóng_gói sản_phẩm tốt sẽ ủng_hộ shop thêm': 1, 'đúng với mô_tả đúng chất_liệu đẹp màu_sắc giống hình sản_phẩm rất đẹp chất_liệu tốt đóng_gói cẩn_thận shipper thân_thiện nói_chung là 10 đ': 1, 'áo chất dày_dặn săn sale được giá hời quá ạ shop đóng_gói kĩ_càng': 1, 'm63 45 không mặc sz làm vừa chiều dài nha hàng đẹp dày_dặn cầm nặng_tay với giá này quá ok nha cả nha': 1, 'áo đẹp dày rất thích giao hàng nhanh hình_ảnh và video mang tính_chất nhận xu': 1, 'đúng với mô_tả giống mẫu màu_sắc màu đen chất_liệu hơi mỏng vải khá là mỏng nhưng với giá tiền như này thì không_thể đòi_hỏi được thêm nói_chung là phù_hợp với giá tiền mọi người nên nhé giao hàng cũng khá là nhanh video chỉ mang tính_chất nhận xu': 1, 'màu_sắc trắng chất_liệu len tăm đúng với mô_tả đúng mô_tả áo về đúng hôm chỗ mk trở lạnh thấy cũng dày so với tầm giá mặc lên cũng rất đẹp sẽ ủng_hộ shop tiếp': 1, 'chất_liệu chất_liệu vải màu_sắc màu đen đúng với mô_tả đúng mô_tả ạ mình săn rẻ lém ý ship hàng nhanh cực luôn đẹp quá là ok luôn nên mua nhé mọi người': 1, 'đúng với mô_tả tốt chất_liệu tốt màu_sắc tốt lịch live tháng này của em tháng này duy_nhất chỉ có một ngày là 24 11 black friday mega live em xin_lỗi nếu để mọi người chờ ạ hơn 80 nhãn hàng lớn sẽ góp_mặt mỹ_phẩm thời_trang đồ gia_dụng tất_nhiên vẫn freeship và voucher 30 không giới_hạn giá_trị cho tất_cả đơn hàng không có chuyện voucher 30 giới_hạn bao_nhiêu không đâu ạ ngoài live của em thì không bao_giờ có zá này đâu ạ': 1, 'chất dày có lót bông cầm nặng_tay sờ mịn chín năm 10 form khá ổn mũ vừa đầu thôi chứ không rộng nhưng có hai lớp nên bù_trừ tám năm 10 giá_thành phù_hợp với chất_lượng trả_giá shop cũng đồng_ý nên rất hài_lòng về thái_độ phục_vụ 1000 10 anh shipper chúa hề lắm vậy nên mua nhé': 1, 'màu_sắc nâu đúng với mô_tả đúng chất_liệu tốt quần đẹp dày_dặn không có chỉ thừa phù_hợp với mọi người form quần xinh shop giao hàng nhanh tư_vấn nhiệt_tình đóng_gói cẩn_thận': 1, 'màu_sắc màu xám lông chuột đúng với mô_tả được chất_liệu vải nỉ mặc mùa thu hợp_lý hàng đẹp rộng_rãi tui m6 48 không mặc đang còn rộng dài qua mông mặc đi học cx rất là oke rẻ phù_hợp giá tiền quá là ưng r': 1, 'chất_liệu thun màu sắc đen phối xám áo xinh nha vải đúng êm lun cầm_chắc tay vơid giá_như vậy thì ổn chữ thiêu nên không sợ tróc': 1, 'để chuẩn_bị cho buổi báo_cáo sản_phẩm giáo_dục địa_phương thứ hai tới khuyến_khích các nhóm mang lap để hoàn_thiện trong một tiết còn lại một tiết sau sẽ báo_cáo sản_phẩm lấy điểm': 1, 'đúng với mô_tả dung chất_liệu kaki màu_sắc xanh reu mặc vô from dth chất mềm nênn mua nha mua giá rẻ vậy cx hợp_lí phối được chục bộ_đồ': 1, 'áo đẹp hơn mình nghĩ chất rất dày mình chọn màu trắng nhưng_mà dày đẹp không hề bị lộ vải siêu siêu mềm đường may tạm ổn chỉ thừa không đáng_kể lắm nói_chung xứng_đáng với số tiền đã bỏ ra': 1, 'quần đẹp lên dáng xinh lắm cảm_ơn shop': 1, 'áo ok chất được giao hơi lâu xí đúng đủ sản_phẩm sau sẽ ủng_hộ thêm nhaaa': 1, 'đúng với mô_tả vậy màu_sắc giờ chất_liệu giờ đã nhận được hàng giao hàng khá nhanh nhưng vải mỏng quá nhẹ_tênh': 1, 'áo đẹp vải cũng uki lắm lại còn rẻ nữa nhưng_mà shipper giao hàng mà như bà nội tao á <emoji> slightly smiling face </emoji>': 1, 'chất_liệu không bik đúng với mô_tả áo đẹp lên form đẹp lắm nha mọi người màu_sắc be shipper dù trời mưa vẫn đi giao lần sau sẽ ủng_hộ shop tiếp nè': 1, 'đúng với mô_tả màu_sắc không giống trong hình_ảnh chất_liệu đẹp màu_sắc không giống trong hình_ảnh': 1, 'áo đẹp áo may hai túi trong dày thấy shop này giá rẻ nhất rồi cskh nhanh nhiệt_tình cute gửi hàng nhanh': 1, 'đúng với mô_tả đẹp chất_liệu mỏng màu_sắc trắng áo lên form hơi kì và chất mỏng như giá rẻ như này cũng không đòi_hỏi gì <emoji> smiling face with tear </emoji>': 1, 'đúng với mô_tả ty chất_liệu hh màu_sắc ty 19188 không biết có ai cũng đang cảm_giác như em không mấy hôm_nay mẹ đi vay_mượn tiền cho đóng học em không dám nói là học_phí thật mà chỉ dám nói với mẹ là 10 triệu số tiền còn lại em bù là tiền em đi làm thêm vào nhịn ăn_tiêu và tiết_kiệm lại nhưng em biết rõ có xin tiền mẹ học mẹ không bao_giờ mắng đâu nhưng nỗi lo của mẹ ngày_một dày thêm khi hơn 20 ngày mẹ phải lo cho cả hai anh_em học đại_học anh mình học bk mặc_dù chương_trình thường nhưng cũng khá nặng nên khi đăng_ký nguyện_vọng đại_học dù đủ điểm đỗ neu nhưng vì biết khả_năng kinh_tế mình đã chọn nguyện_vọng sau phù_hợp với cả kinh_tế và mong_muốn của bản_thân những_tưởng học_phí này sẽ đỡ được bố_mẹ và phụ_giúp cho gia_đình nhưng thì ra không phải vậy trường khác được nợ học_phí và trả trong suốt cả một kỳ học nhưng tại_sao trường gia_hạn ngắn thông_báo chậm như_vậy <emoji> pensive face </emoji> đã sắp cận_kề ngày gia_hạn nộp học_phí nhưng em vẫn chưa gom đủ tiền nộp em cảm_giác rất sợ nếu mình đóng muộn đây chỉ là tâm_sự của em_em không có ý_kiến gì về chất_lượng đào_tạo của thầy_cô đem so_sánh với trường khác đâu vì thứ khiến em lưu_luyến với trường mình là sự nhiệt_tình của giảng_viên trường thui siu': 1, 'chất xịn nha mặc siêu đã còn rẻ nữa được tặng thêm chun buộc tóc <emoji> strawberry </emoji>': 1, 'đúng với mô_tả đúng màu_sắc xăng chất_liệu coton đẹp quá sau_này sẽ ủng_hộ tiếp ạ ok đẹp lắm nha ok so đẹp đúng rồi': 1, 'đúng với mô_tả như hình màu_sắc hồng_quần chất đẹp nhưng chỗ cạp mặt trước dạng giả khoá thì đẹp hơn với hơi bị lệch chỗ day rút chun giao hàng nhanh oki nhé': 1, 'áo đẹp form rộng thoải_mái màu lên không bị kém da giá lại rẻ nữa rất đáng để mua nha': 1, 'màu_sắc trắng áo đẹp chất dày_dặn nên mua heng ảnh và video mang tính đột_phá minh_hoạ ạ sản_phẩm thân_thiện': 1, 'shop tư_vấn rất tận_tình nhé giao hàng gói hàng chu_đáo cẩn_thận nữa nè mình rất ưng_ý nhé': 1, 'chất_liệu ok đúng với mô_tả được màu_sắc đẹp tb có 10 gb data tốc_độ cao tháng thêm thoại thả ga soạn cf120n gửi 999 mobifone gửi đến bạn 10 gb data tốc_độ cao tháng nhận thêm hai 000 phút thoại và hai 000 sms nội mạng 20 phút thoại ngoại mạng xem phim hót trên truyền_hình cliptv tại https cliptv vn phim ưu_đãi chỉ 120 000 đ tháng liên_hệ 9090 từ_chối tư_vấn cskh của mobifone soạn tc gửi 9241': 1, 'đẹp nhaaa bà_con ôi dày_dặn xinh lắm': 1, 'nhận đủ hai cái cái xám thì mang thoải_mái cái đen thì bé hơn một_tí mặc_dù cùng size <emoji> rolling on the floor laughing </emoji>': 1, 'màu_sắc nâu ui áo xinh lắm nè vừa_vặn không quá mỏng đâu sốp giao hàng cũng nhanh gọn nữa ạ nói_chung là siêu ưng recommend mọi người nên mua nhaaaa': 1, 'nhận được hàng giao nhanh canh sale để được giá tốt mình mua 60 không': 1, 'màu_sắc be đậm chất_liệu vải bông đúng với mô_tả đúng áo đẹp nha chất vải dày tôi săn được có năm không mà vải dày như này thì quá là ưng rồi lần sau sẽ ủng_hộ shop': 1, 'chất_liệu nỉ đúng với mô_tả chín 10 màu_sắc be tròi oi ta ns ưng hi chi lun form 10 đ không có nhưng ò nhưng cái màu tui hong ưng lắm với shop làm cái mũ hơi nhỏ á lần sau làm to xíu là đc ns chung 24 cá mà ntn là đc ròi mà chị shipper dth lắm lun á còn kiên_nhẫn nữa tóm_lại là khỏi bàn lun ủng_hộ mua nha mọi người hình_ảnh mang tính nhận xu': 1, 'chất_liệu len mịn màu sắc đen_trắng đúng với mô_tả đúng đẹp lắm ạ rất hài_lòng về sản_phẩm sẽ quay lại ủng_hộ <emoji> star struck </emoji>': 1, 'không ngờ áo 55 không mà đc như_vậy luôn áo đẹp lắm ạ ở trong là lớp bông cầm khá nặng_tay nói_chung là ok nhoa 凉_凉 <emoji> smiling face with smiling eyes </emoji> màu ở ngoài sẽ đậm hơn trg ảnh và video ạ': 1, 'áo xinh lắm nha phù_hợp mặc sống ảo thôi vì khi di_chuyển cái vai nó hơi bị xô lệch nhiều dươới 50 không vừa vì hơi nhỏ': 1, 'màu_sắc dbdj đúng với mô_tả nsjsj chất_liệu mỏng áo mỏng dễ rách lắm nhe mọi người cân_nhắc trước khi mua tiền_nào_của_nấy thôi': 1, 'màu_sắc xanh trắng chất_liệu len đúng với mô_tả hàng đúng mô_tả chất_lượng tốt giao hàng nhanh mặc ấm giá_cả hợp_lí đáng tiền mua': 1, 'chất_liệu vải gì đó không biết màu sắc đen đúng với mô_tả đẹp đúng với hình_mẫu đúng như đánh_giá sản_phẩm là quần mỏng nhưng_mà đẹp với màu đen cx ít lộ giá_thành rẻ nên chất_lượng như_vậy là quá ok r': 1, 'áo đẹp lắm luôn ạ áo nỉ form thoải_mái màu ghi xinh và tôn da đặt chiều t7 mà chủ_nhật nhận hàng luôn shop tư_vấn rất nhiệt_tình mua ba cái rồi chất hịn không chê vào đâu được cảm_thấy rất đáng tiền mà giá quá rẻ luôn shop giao đủ hangg có lót trong chất hịn không chê vào đâu được cảm_thấy rất đáng tiền mà giá quá rẻ luôn shop giao đủ hangg nhận hàng rất ưng cho shop 100 saolun': 1, 'giao hàng nhanh đóng_gói sản_phẩm cẩn thân shop tư_vấn nhiệt_tình thân_thiện chất_lượng sản_phẩm tốt vải khá dày_dặn nhưng không bị quá nóng lên form rất đẹp nchung là siêu ưng': 1, 'màu_sắc màu hồng chất_liệu tuyệt_vời đúng với mô_tả đúng mùa lần đâu thấy cũng ok giá rẻ đẹp <emoji> smiling face with heart eyes </emoji>': 1, 'đồ đẹp vải ok không mỏng không dày không thấy lộ bên kia mình một m6 quần bận trên mắt_cá chân với giá_như này thì nên mua nha mọi người': 1, 'đúng với mô_tả đẹp cũng tạm đc quần mỏng nhìn xuyên đc một m54 mặc oke la lắm nha mọi người nên mua ba_ba': 1, 'màu đẹp lắm nhé nhưng đt đểu nên không chụp đúng màu đc ạ <emoji> smiling face </emoji> chỉ may một lượt hơi lỏng_lẻo nhưng với giá 70 không thì đã là quá xuất_sắc <emoji> thumbs up </emoji> chất vải dày_dặn lót lưới bên trong form hơi nhỏ và ngắn nên ai cao thì mặc sẽ hơi cộc tay_áo hơi rộng': 1, 'đúng với mô_tả đúng nha chất_liệu nỉ dày đẹp màu_sắc xanh than mua lần thứ hai rồi phải nói là shop gói hàng siêuuu kỹ ngồi gỡ ra cũng mệt <emoji> smiling face with halo </emoji> sẽ ủng_hộ shop nè 10 điểm dành cho shop <emoji> kissing face with closed eyes </emoji> chúc shop mua may bán đắt nhé': 1, 'thấy đánh_giá bảo sz nhỏ chật nên bảo shop huỷ đơn nma shop vẫn giao hai ngày là nhận được rồi mọi người chê nhiều quá nhưng mình thấy đẹp nhaa mình 46 không m58 59 mặc vừa in mặc rất thoải_mái mà giặt phai ghê lắm': 1, 'quần chất ka khi rất đẹp mầu ưng_ý dáng phon rất đứng quần giá lại bình_dân sẽ mua sóp này dài_dài': 1, 'đúng với mô_tả giống như trong hình màu_sắc đẹp chất_liệu tốt hàng giao nhanh màu xanh rất đẹp mua trên live nên được miễn_phí sip gia cũng được giảm xuống rất nhiều hàng đẹp nên mua dung màu o ngoài trong rất đẹp': 1, 'chất_liệu kaki mong đúng với mô_tả ok màu_sắc black shop tư_vấn chuẩn sz quay lại lần hai ủng_hộ shop mua hộ mọi người rất ưng lại được giá đẹp \\ufaf6 <emoji> medium light skin tone </emoji>': 1, 'chất_liệu ok đúng với mô_tả đời màu_sắc đẹp mua được giá tốt áo đẹp giao hàng nhanh_chóng sẽ ủng_hộ thêm lần tới': 1, 'chất_liệu vải nỉ bông đúng với mô_tả đúng màu_sắc thắng áo đẹp giá lại giá rẻ phù_hợp với giá tiền': 1, 'màu_sắc xanh chất_liệu len mềm chất khá ok 56 không vẫn vừa nha cổ thì không xinh hơi chật quá ý vai rộng là lộ cả luôn phần bụng bị thụng trông hơi bcuoi tí săn với giá 42 không nên ok': 1, 'chất_liệu nỉ bông đúng với mô_tả đúmm màu_sắc hồng đậm có xíu ánh tím tui mua có 137 thôi mà đẹp quá_chừng luôn nma màu không giống ảnh shop đăng lắm ảnh tui chụp tui chỉnh cho màu giống ở bngoai roii màu ảnh tui chụp y_chang bên ngoài í chỉ có màu là không đúng thôi còn lại thì quas ổn luôn ạ tui cũng kbiet diễn_tả sao nên là mấy bà coi ảnh đi nha áo này mà 200 không tui thấy còn rẻ í vải siêu dày luônnn form áo không dài lắm nên là dưới m5 mặc chỉ vừa chùm mông thôii': 1, 'chất_liệu bò đúng với mô_tả 80 màu_sắc hơi khác với trên ảnh mình cao một m55 42 không mặc sao vừa nha nhưng màu_sắc bên ngoài sẽ hơi khác hình chút nên mọi người cân_nhắc trước khi mua đc mỗi cái shop giao hàng nhanh giá_cả phù_hợp': 1, 'sản_phẩm chất_lượng tốt giá_cả phù_hợp shop đi đơn nhanh tư_vấn nhiệt_tình nữa 10 đ': 1, 'đúng với mô_tả đúng màu_sắc xanh trắng chất_liệu len áo đẹp lắm nha mọi người ơi hàng đẹp cực luôn ya ưng_ý lắm nha nên mua á': 1, 'chất_liệu đũi đúng với mô_tả rất ok ạ màu_sắc be hơi mỏng tí nma so với giá này thì không phải bàn rồi chất_lượng nha mà_còn hơi chỉ thừa ạ': 1, 'đúng với mô_tả đúng màu_sắc đẹp chất_liệu cotton mình 50 không mặc size làm vừa in đẹp luôn giá này thì không_thể chê gì được rất hài_lòng': 1, 'chất_liệu lên đúng với mô_tả có màu sắc đen áo săn sale 45 không mà đẹp thế nhỉ không bị mỏng cũng không quá dày chất mịn đẹp cảm_ơn shop nhiều lắm ạ': 1, 'đúng với mô_tả ddungs màu_sắc hồng chất_liệu kaki quần đẹp quá_trời luôn ạ vừa như in không chật tí gì giá lại còn rẻ nhữa có_điều là tự_dưng bị lộ dây chỗ cạp_quần nên nhìn không ưng lắm': 1, 'chất_liệu thun lạnh màu sắc đen đúng với mô_tả đúng với mô_tả áo rẻ nhưng_mà mặc lên form xịn lắm nha mọi người ơi': 1, 'chất_liệu len siêu xinh nha ae uy_tín chất_lượng ae xem là biết shop siêu uy_tín': 1, 'sản_phẩm đẹp giao nhanh áo đẹp lắm nha mọi ngừoi nên mua với giá tiền này ạ': 1, 'áo form rộng mặc thoải_mái áo giống hình nhận được hàng mà ưng lắm mọi người ơi <emoji> face with hand over mouth </emoji> <emoji> face with hand over mouth </emoji> nên mua nha': 1, 'giao nhanh nhưng đặt size làm lại giao thành size xl mặc vào vẫn ngắn tay <emoji> very very happy face or smiley </emoji> tiền nào của đấy mặc chống cháy hoặc ở nhà thì ok chứ đi đường phải mặc thêm áo_phao mới chắn gió': 1, 'màu_sắc trắng sản_phẩm đúng với mô_tả áo chất vải mềm mịn mặc vào trời se lạnh thì ấm_áp còn không thì sẽ hơi nóng đường may đẹp tinh_tế mình một m43 40 không thì mặc vào hơi rộng bạn nào cao hơn mặc vào sẽ đẹp hơn': 1, 'chất_liệu vải kaki đúng với mô_tả ok màu sắc đen shop đóng_gói kỹ_càng giao hàng đúng sản_phẩm đã chọn chúc shop bán đắt <emoji> red heart </emoji> ️': 1, 'màu sắc đen đúng với mô_tả suất sắc luôn ạ chất_liệu lụa ưng lắm nha mọi người ơi nhưng_mà muốn chắc_chắn hơn thì đem ra tiệm may thêm đường nữa cho chắc_ăn nên mua nha anh shipper nói_chuyện dịu_dàng quá ưng lắm nha <emoji> red heart </emoji>': 1, 'chất_liệu nỉ màu sắc đen áo đẹp ấm mũ to tay bồng m m52 mặc chùm mông chủ shop cte săn live được áo giá rẻ nên mua nha mọi người': 1, 'đúng với mô_tả như trên chất_liệu vải thunn màu_sắc trắng giao hàng nhanhhhh áo đẹp lắm luôn lên from đẹp': 1, 'chất_liệu khoác nỉ đúng với mô_tả đúng với mô_tả màu_sắc nâu áo chất_liệu nỉ áo đẹp khỏi bàn nam_nữ đều mặc đc vải không quá dày cũng không quá mỏng nói_chung đẹp giá vừa rẻ lại đc áo đẹp nv xuất_sắc lun shipper thân_thiện': 1, 'vải đẹp chuẩn form giao hàng nhanh': 1, 'chất_liệu vải nỉ màu_sắc nâu đúng với mô_tả đúng nha áo mang đẹp nha chất vải mềm rất_chi_là ok luôn á m50 mang qua mông luôn nha chất áo màu siêu đẹp giá quá chi là rẻ 10 điểm nên mua nhaaaa': 1, 'đúng với mô_tả đúng màu sắc đen chất_liệu vải hàng đẹp lắm nha đúng miêu_tả giao rất nhanh hàng rẻ mà đẹp': 1, 'rẻ nên mua hai cái lunn giao hàng hơi lâu may_mà về kịp để mặc đi chơi <emoji> rolling on the floor laughing </emoji> chất đẹp không quá mỏng cũng không quá dày mỗi_tội cái cổ hơi khó thở ạ 凉_凉_凉 form thì ôm sát người đẹp lắm': 1, 'mình nhận hàng rồi nha cho shop năm sao luôn không nghĩ giá rẻ mà sản_phẩm chất_lượng vậy': 1, 'màu_sắc xanh than đúng với mô_tả đúng chất_liệu nỉ pha poly giao hàng nhanh sản_phẩm y hình chữ jump nhỏ hơn trong ảnh shop xíu thuii so với giá là quá ok nhenn sẽ mua thêmm tay_áo hơi ngắn hợp với ng thấp như mình': 1, 'vải tăm nha mặc được đẹp lắm luôn mặc đi chơi trung_thu là ok nè chốt nhé': 1, 'chất vải xấu như áo cũ mua về không mặc dk ln': 1, 'tè vải đến kiểu_dáng đẹp hú_hồn mh không nghĩ vài chục mà mua đc chiếc quần cưng như này chiều dài 104 cm mh rất ưng': 1, 'đúng với mô_tả kho xấu': 1, '24 không một đôi mẹ ơi': 1, 'đúng với mô_tả đặt áo_khoác mà giao cái qq gì vậy màu_sắc saiii chất_liệu không đúng': 1, 'giao thiếu hàng': 1, 'đúng với mô_tả đúng màu_sắc nâu chất_liệu vải vải không được đẹp lắm nhưng phù_hợp giá_cả hơi rộng nhưng bé nhà mình thích nên vẫn đánh_giá cho shop năm sao': 1, 'chất_liệu mỏng màu sắc đen đúng với mô_tả yét khá là mỏng nhưng với giá này thì cũng ok': 1, 'màu_sắc đúng đúng với mô_tả không chất_liệu mỏng áo bị lỗi': 1, 'mỏng và bự to rộng không mang được hàng về nhanh hơn dự_kiến a': 1, 'he was also an advocate and supporter in a similar position as his': 1, 'hàng đẹp giao hàng nhanh shipper vui_vẻ thân_thiện sẽ còn quay lại ủng_hộ shop': 1, 'ổn nma mình một m57 46 không thấy hơi rộng phần cánh_tay màu giống ảnh vải dày': 1, 'hàng không đúng với quảng_cáo thật tệ tôi mua sản_phẩm áo nỉ nhưng nhận được hàng không đúng tôi muốn đổi trả yêu_cầu sophie sem xét sử lý cho tôi': 1, 'mình đặt bảy đôi mang năm đôi thì năm đôi đều bị lủng không biết hai đôi kia như_thế_nào đúng là mua với giá rẻ thì ít_nhất cũng phải lành chứ sao mà lủng từ đôi này tới đôi khác': 1, 'chất_liệu oke màu sắc đen đúng với mô_tả sai kích_cỡ đặt 70 không mà 49 không không mặc vừa tay con bung chỉ': 1, 'đúng với mô_tả yes chất_liệu không bic vv màu sắc đen một m5 mặc vào là qua okela luon ak áo cũm xink lămz nha': 1, 'áo xinh mặc lên form đẹp chất vải cũng ưng màu giống với hình giá_cả phù_hợp rất ưng ạ': 1, 'sản_phẩm đẹp rẻ mua lần thứ n tại shop zui chắc tại ng m cũng nho_nhỏ nên hợp với đồ của shop <emoji> face with tears of joy </emoji> chất cũng khá ok sẽ ủng_hộ dài': 1, 'giao hàng nhanh đóng_gói hàng cẩn_thận đẹp mèo nhà mình rất thích': 1, 'chất_liệu vải cotton co_giãn màu sắc đen và trắng đúng với mô_tả sản_phẩm giống mô_tả rất vô_tri ngố': 1, 'quần đẹp quá_trời săn được giá rẻ nữa chất_liệu màu_sắc đều ưng': 1, 'màu_sắc den đúng với mô_tả không áo mỏng có mùi hình in rất xấu': 1, 'đúng với mô_tả sai mới mô_tả shop bán hàng kì_lạ đặt_hàng áo khoát giao hàng cái quần trẻ_em là sao ai đặt_hàng nhớ để_ý đánh_giá tệ nhen hông phải ganh_ghét gì mà là sự_thật <emoji> thumbs down </emoji> <emoji> thumbs down </emoji>': 1, 'áo không giống mong_đợi fom ôm phải không đẹp khô và cứng': 1, 'đẹp nhưng áo nhỏ không from rộng': 1, 'màu_sắc nâu chất mặc phù_hợp trời lạnh mặc bao nóng <emoji> very very happy face or smiley </emoji> chữ in sơn nham_nhở dễ tróc chú_ý giặt': 1, 'ship thân_thiện đóng_gói cẩn_thận đc tặng thêm lắc xinh nhưng hơit hất vọng về tất tay với thân tất không cùng màu': 1, 'giao hàng nhanh quần rất dài so với ng m55 nha chất quần ổn nhưng đường may không chắc mới mặc thử đã bục chỉ ở cạp_quần nha thêm tiền đi cắt gấu cũng phải rẻ nữa': 1, 'đúng với mô_tả <emoji> thumbs up </emoji> màu_sắc đẹp chất_liệu tốt nhưng hơn mỏng': 1, 'đúng với mô_tả yes màu_sắc vàng <emoji> happy face or smiley </emoji> chất_liệu len len mỏng lắm nha tr màu hơi vàng không phải be mặc ổn cổ cao ấm dec mỗi cái cổ áo <emoji> very happy face or smiley </emoji> giá này hợp_lí r có chỉ thừa': 1, 'đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc giao hàng nhanh nhẹ nói_chung là ổn': 1})\n","cmtid Counter({12163393239: 1, 12860404226: 1, 13284156815: 1, 11671891913: 1, 10353479733: 1, 13230909507: 1, 13293975188: 1, 13345744134: 1, 12507022926: 1, 12736590979: 1, 13080275378: 1, 13274015829: 1, 13253813454: 1, 12863431964: 1, 12479328586: 1, 13270280667: 1, 12268799974: 1, 13181950170: 1, 10878161909: 1, 12546778742: 1, 12886221522: 1, 13301745337: 1, 10375194497: 1, 12882096049: 1, 13135736549: 1, 13253931275: 1, 13008380679: 1, 13007857981: 1, 12642082708: 1, 12770070378: 1, 13011841077: 1, 10749423027: 1, 13257833589: 1, 13141909654: 1, 10537769807: 1, 13108396567: 1, 13026017547: 1, 12488721752: 1, 13249543961: 1, 13273787350: 1, 12990853401: 1, 13111062328: 1, 12760032692: 1, 12870257730: 1, 13274291503: 1, 12996799785: 1, 13340973152: 1, 13262883099: 1, 13289265334: 1, 1025695049: 1, 13164019419: 1, 10833583297: 1, 12874523003: 1, 13314054538: 1, 13026403206: 1, 12944591420: 1, 11833577193: 1, 12970412506: 1, 13054370142: 1, 13008275877: 1, 13200167512: 1, 10571370401: 1, 13132516099: 1, 13198955424: 1, 12025830907: 1, 12871690924: 1, 13191367976: 1, 12267016546: 1, 12930057041: 1, 12615634251: 1, 13022509924: 1, 12067423361: 1, 12962298180: 1, 12886215811: 1, 13183726245: 1, 13217708181: 1, 13285720669: 1, 12899246613: 1, 13296240686: 1, 12897181932: 1, 10814177612: 1, 12971792037: 1, 13044000850: 1, 11638744163: 1, 13228162541: 1, 12119184392: 1, 12135749311: 1, 13256010031: 1, 13010399907: 1, 12469793056: 1, 13302058413: 1, 12394801704: 1, 13244672161: 1, 12137185774: 1, 9716866702: 1, 12620055551: 1, 10680537778: 1, 12306569710: 1, 13323868125: 1, 11225710853: 1, 13230086706: 1, 12417356857: 1, 12891280057: 1, 13178941628: 1, 11964848499: 1, 13090801587: 1, 12848561060: 1, 13237555354: 1, 13341445417: 1, 13104103685: 1, 13149792153: 1, 10893683350: 1, 7102215502: 1, 13159756239: 1, 13170759722: 1, 13269348251: 1, 6283455819: 1, 13318626611: 1, 12358154680: 1, 13095165330: 1, 12906120442: 1, 11605138755: 1, 12727077974: 1, 13180852081: 1, 12948560132: 1, 12160661378: 1, 12973791656: 1, 13076559778: 1, 12371008994: 1, 12992989098: 1, 9958349748: 1, 13245580005: 1, 12561707427: 1, 13084057284: 1, 12807959000: 1, 13330330747: 1, 13255454365: 1, 12628639646: 1, 12855636815: 1, 12938597655: 1, 13115386435: 1, 11750537326: 1, 12437601649: 1, 13038460768: 1, 12797650862: 1, 10832847638: 1, 12990872891: 1, 12830988753: 1, 12760781935: 1, 12998265303: 1, 12256521034: 1, 13247722289: 1, 13121528771: 1, 12612223119: 1, 12234011659: 1, 12544095878: 1, 13159835416: 1, 12065864665: 1, 12585150675: 1, 12871131979: 1, 12982780896: 1, 13140042300: 1, 11498702022: 1, 13252959603: 1, 13328609265: 1, 11829631903: 1, 13260744607: 1, 13038429754: 1, 13235658301: 1, 13029163284: 1, 13244382781: 1, 6417322638: 1, 7328230113: 1, 13134894419: 1, 11948322115: 1, 13078298941: 1, 12846462987: 1, 12921012603: 1, 11480068808: 1, 10668256656: 1, 13211099713: 1, 12383838505: 1, 13245703493: 1, 11608333477: 1, 12989692394: 1, 13079504151: 1, 13097166185: 1, 13239621971: 1, 13182588775: 1, 12637499158: 1, 13186975439: 1, 13192437937: 1, 13175509542: 1, 13144472412: 1, 11320379440: 1, 12610447526: 1, 12563988690: 1, 12665590202: 1, 13070322729: 1, 12883633090: 1, 13116906729: 1, 13285823909: 1, 13232751351: 1, 12729259062: 1, 12867059435: 1, 13164969838: 1, 12795992490: 1, 13091661626: 1, 13332857221: 1, 13038307677: 1, 13171745789: 1, 12720299937: 1, 13123673714: 1, 13106235215: 1, 12622247169: 1, 13003587990: 1, 13208562772: 1, 13273575442: 1, 10674243414: 1, 13170384872: 1, 13079623867: 1, 13258244727: 1, 13277848720: 1, 10751788635: 1, 12528901917: 1, 13255835599: 1, 13260211429: 1, 10213951970: 1, 12989213961: 1, 12214022680: 1, 12645453502: 1, 12441900524: 1, 11835042567: 1, 12407390858: 1, 12805850880: 1, 12910144521: 1, 12693290903: 1, 13280071513: 1, 12853541774: 1, 13053692374: 1, 13297890522: 1, 13227307206: 1, 13200510273: 1, 12842734854: 1, 12591570701: 1, 13044032948: 1, 13160439400: 1, 12861455806: 1, 13278764661: 1, 12563669864: 1, 12537900642: 1, 12371890908: 1, 11196019962: 1, 6277181889: 1, 13188196835: 1, 13038747660: 1, 13125315357: 1, 12371215920: 1, 12662840091: 1, 13323083413: 1, 12961779171: 1, 12218145292: 1, 13307717257: 1, 11278839235: 1, 13154206315: 1, 12626247367: 1, 12967427776: 1, 12502489602: 1, 13345935353: 1, 12639849781: 1, 13281399038: 1, 12198892833: 1, 13288012286: 1, 11695680345: 1, 13032398614: 1, 10773911801: 1, 10361190868: 1, 12916112142: 1, 13171558530: 1, 13279627917: 1, 13174531792: 1, 10824538850: 1, 12411669577: 1, 13043330656: 1, 13239770552: 1, 13203451536: 1, 13026349329: 1, 13168540098: 1, 12590934663: 1, 12878774770: 1, 12968555355: 1, 13306086209: 1, 12933879441: 1, 12782597752: 1, 13186224830: 1, 12280051239: 1, 12352726771: 1, 11529783187: 1, 13274120293: 1, 12564152237: 1})\n"]},{"data":{"text/html":["\n","  <div id=\"df-9e7c077b-e020-4326-98e6-fc15cf5ba500\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uyennnp21411</th>\n","      <th>anhnhn21411</th>\n","      <th>tamta21411</th>\n","      <th>nguyennt21411</th>\n","      <th>tuanna21411</th>\n","      <th>text</th>\n","      <th>cmtid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>12163393239</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>12860404226</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Neutral</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>13284156815</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>11671891913</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Neutral</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>10353479733</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>ship thân_thiện đóng_gói cẩn_thận đc tặng thêm...</td>\n","      <td>12280051239</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>giao hàng nhanh quần rất dài so với ng m55 nha...</td>\n","      <td>12352726771</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Neutral</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả &lt;emoji&gt; thumbs up &lt;/emoji&gt; màu_...</td>\n","      <td>11529783187</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả yes màu_sắc vàng &lt;emoji&gt; happy ...</td>\n","      <td>13274120293</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc ...</td>\n","      <td>12564152237</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e7c077b-e020-4326-98e6-fc15cf5ba500')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9e7c077b-e020-4326-98e6-fc15cf5ba500 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9e7c077b-e020-4326-98e6-fc15cf5ba500');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-583a0b0b-a49b-4956-9892-4933bc9e016b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-583a0b0b-a49b-4956-9892-4933bc9e016b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-583a0b0b-a49b-4956-9892-4933bc9e016b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["    uyennnp21411 anhnhn21411 tamta21411 nguyennt21411 tuanna21411  \\\n","0       Negative    Negative   Negative      Negative    Negative   \n","1       Negative    Negative   Negative      Negative    Negative   \n","2        Neutral    Positive   Positive      Positive    Positive   \n","3       Positive    Positive   Positive      Positive    Positive   \n","4        Neutral    Negative   Negative      Negative    Negative   \n","..           ...         ...        ...           ...         ...   \n","295      Neutral     Neutral    Neutral       Neutral     Neutral   \n","296      Neutral     Neutral    Neutral       Neutral     Neutral   \n","297     Positive    Positive    Neutral      Positive    Positive   \n","298     Positive    Positive   Positive      Positive    Positive   \n","299     Positive    Positive   Positive      Positive    Positive   \n","\n","                                                  text        cmtid  \n","0                      nói_chung là xấu vải áo xấu lắm  12163393239  \n","1                                giao bé quá thất_vọng  12860404226  \n","2    màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...  13284156815  \n","3    chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...  11671891913  \n","4                                màu sắc đen chất mỏng  10353479733  \n","..                                                 ...          ...  \n","295  ship thân_thiện đóng_gói cẩn_thận đc tặng thêm...  12280051239  \n","296  giao hàng nhanh quần rất dài so với ng m55 nha...  12352726771  \n","297  đúng với mô_tả <emoji> thumbs up </emoji> màu_...  11529783187  \n","298  đúng với mô_tả yes màu_sắc vàng <emoji> happy ...  13274120293  \n","299  đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc ...  12564152237  \n","\n","[300 rows x 7 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["annotater_data_2 = {k: [] for k in annotater5id.keys()}\n","annotater_data_2.update({\n","    'text': [],\n","    'cmtid': []\n","})\n","\n","for data in datas_2:\n","\n","  temp_dict = {i: 'None' for i in annotater_data_2.keys()}\n","  temp_dict['text'] = data['content']\n","  temp_dict['cmtid'] = data['metadata']['cmtid']\n","\n","  for classification in data['classifications']:\n","    label = classification['classname']\n","\n","    for annotator in classification['classified_by']:\n","      name = annotator['annotator'].split(\"@\")[0]\n","\n","      temp_dict[name] = label\n","\n","  for k, v in temp_dict.items():\n","    annotater_data_2[k].append(v)\n","\n","drop_columns_2 = []\n","for k, v in annotater_data_2.items():\n","  if Counter(v).get('None', 0) >= len(datas) * 0.1:\n","    drop_columns_2.append(k)\n","    continue\n","\n","  print(k, Counter(v))\n","\n","annotater_df_2 = pd.DataFrame.from_dict(annotater_data_2)\n","annotater_df_2 = annotater_df_2.drop(drop_columns_2, axis = 1)\n","annotater_df_2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1701979560617,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"UFxqDRW5b2VI","outputId":"8edd80fe-c4c3-4da4-ff1b-165a0b5b218c"},"outputs":[{"data":{"text/plain":["0.8629463886881026"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["fleiss_matrix_2, categories = aggregate_raters(annotater_df_2.drop(['text', 'cmtid'], axis = 1))\n","kappa_2 = fleiss_kappa(fleiss_matrix_2)\n","kappa_2"]},{"cell_type":"markdown","metadata":{"id":"fbXMVqXIeBZH"},"source":["Sau khi gán nhãn dữ liệu lại, nhóm kiểm tra độ đồng thuận và thấy được kết quả đạt 86%, đây là mức kết quả rất tốt. Do đó nhóm tiếp tục gán 2700 comment còn lại để tiến hành huấn luyện mô hình"]},{"cell_type":"markdown","metadata":{"id":"8eglt60qeNWb"},"source":["#2. Huấn luyện mô hình"]},{"cell_type":"markdown","metadata":{"id":"SJfTf6hkf9uN"},"source":["##2.1. Chuẩn bị dữ luyện huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNhf7XGLcYWi"},"outputs":[],"source":["with open(path.join(val_path, \"val-reannotated_annotations.json\"), 'r') as f_300:\n","  data_300 = json.load(f_300)[\"examples\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUWMZDxzc_p0"},"outputs":[],"source":["with open(path.join(val_path, \"2700-annotated_annotations.json\"), \"r\") as f_2700:\n","  data_2700 = json.load(f_2700)[\"examples\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702037413485,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"D21vKZ6Qedpp","outputId":"c204beff-03e8-4a32-dce9-cd63811a859f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-29af673b-3ed9-4107-9fa1-3e1ac0c0b55c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>content</th>\n","      <th>classname</th>\n","      <th>rating_star</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12163393239</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12860404226</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13284156815</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11671891913</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10353479733</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>12280051239</td>\n","      <td>ship thân_thiện đóng_gói cẩn_thận đc tặng thêm...</td>\n","      <td>Neutral</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>12352726771</td>\n","      <td>giao hàng nhanh quần rất dài so với ng m55 nha...</td>\n","      <td>Neutral</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>11529783187</td>\n","      <td>đúng với mô_tả &lt;emoji&gt; thumbs up &lt;/emoji&gt; màu_...</td>\n","      <td>Positive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>13274120293</td>\n","      <td>đúng với mô_tả yes màu_sắc vàng &lt;emoji&gt; happy ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>12564152237</td>\n","      <td>đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29af673b-3ed9-4107-9fa1-3e1ac0c0b55c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-29af673b-3ed9-4107-9fa1-3e1ac0c0b55c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-29af673b-3ed9-4107-9fa1-3e1ac0c0b55c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-71ffc8c1-e734-47fb-be11-cbc78c1bc420\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71ffc8c1-e734-47fb-be11-cbc78c1bc420')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-71ffc8c1-e734-47fb-be11-cbc78c1bc420 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["           cmtid                                            content classname  \\\n","0    12163393239                    nói_chung là xấu vải áo xấu lắm  Negative   \n","1    12860404226                              giao bé quá thất_vọng  Negative   \n","2    13284156815  màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...  Positive   \n","3    11671891913  chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...  Positive   \n","4    10353479733                              màu sắc đen chất mỏng  Negative   \n","..           ...                                                ...       ...   \n","295  12280051239  ship thân_thiện đóng_gói cẩn_thận đc tặng thêm...   Neutral   \n","296  12352726771  giao hàng nhanh quần rất dài so với ng m55 nha...   Neutral   \n","297  11529783187  đúng với mô_tả <emoji> thumbs up </emoji> màu_...  Positive   \n","298  13274120293  đúng với mô_tả yes màu_sắc vàng <emoji> happy ...  Positive   \n","299  12564152237  đúng với mô_tả đúng màu_sắc nâu áo đẹp dễ mặc ...  Positive   \n","\n","     rating_star  \n","0              1  \n","1              1  \n","2              5  \n","3              5  \n","4              1  \n","..           ...  \n","295            3  \n","296            3  \n","297            3  \n","298            5  \n","299            5  \n","\n","[300 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["records = []\n","\n","for cmt_data in data_300:\n","  class_counts = {}\n","  for classification in cmt_data['classifications']:\n","      # Tạo một dict để đếm số lượng các class\n","      class_name = classification['classname']\n","      n_annotators = len(set([i['annotator_id'] for i in classification['classified_by']]))\n","      class_counts[class_name] = n_annotators\n","\n","  # Lấy class có số lượng lớn nhất\n","  most_common_class = max(class_counts, key=class_counts.get)\n","\n","  # Lấy thông tin cần trích xuất\n","  cmtid = cmt_data['metadata']['cmtid']\n","  content =cmt_data['content']\n","  rating_star = cmt_data['metadata']['rating_star']\n","\n","  # Thêm thông tin vào list records\n","  records.append({\n","      'cmtid': cmtid,\n","      'content': content,\n","      'classname': most_common_class,\n","      'rating_star': rating_star\n","  })\n","\n","# Tạo DataFrame từ list records\n","df = pd.DataFrame(records)\n","\n","# In ra DataFrame\n","df"]},{"cell_type":"markdown","metadata":{"id":"DkO7jKO4NU1E"},"source":["300 comment đầu tiên nhóm gán nhãn sẽ có 5 nhãn, do đó nhóm tiến hành lựa chọn nhãn có độ xuất hiện cao nhất để gán cho comment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702037413485,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"JIfSzkBWn8Os","outputId":"76c336df-3b14-46a0-bc22-3d821f8f44d3"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-dd381d24-6b38-41ef-938d-1e061dc118e0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>content</th>\n","      <th>classname</th>\n","      <th>rating_star</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12163393239</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12860404226</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13284156815</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11671891913</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10353479733</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>Negative</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2995</th>\n","      <td>13090938856</td>\n","      <td>đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...</td>\n","      <td>Neutral</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>9720766380</td>\n","      <td>mình nhận đc hàng rồi mua của shop lần thứ ba ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>13304661640</td>\n","      <td>mọi người nên suy_nghĩ trước khi mua nhé thật_...</td>\n","      <td>Negative</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>13268355664</td>\n","      <td>đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>13254595686</td>\n","      <td>quần xinh lắm luôn ạ mình m62 nặng 47 không mặ...</td>\n","      <td>Positive</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd381d24-6b38-41ef-938d-1e061dc118e0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd381d24-6b38-41ef-938d-1e061dc118e0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd381d24-6b38-41ef-938d-1e061dc118e0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bc418390-f5f9-436a-bdf8-2e207f452e20\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc418390-f5f9-436a-bdf8-2e207f452e20')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bc418390-f5f9-436a-bdf8-2e207f452e20 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["            cmtid                                            content  \\\n","0     12163393239                    nói_chung là xấu vải áo xấu lắm   \n","1     12860404226                              giao bé quá thất_vọng   \n","2     13284156815  màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...   \n","3     11671891913  chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...   \n","4     10353479733                              màu sắc đen chất mỏng   \n","...           ...                                                ...   \n","2995  13090938856  đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...   \n","2996   9720766380  mình nhận đc hàng rồi mua của shop lần thứ ba ...   \n","2997  13304661640  mọi người nên suy_nghĩ trước khi mua nhé thật_...   \n","2998  13268355664  đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...   \n","2999  13254595686  quần xinh lắm luôn ạ mình m62 nặng 47 không mặ...   \n","\n","     classname  rating_star  \n","0     Negative            1  \n","1     Negative            1  \n","2     Positive            5  \n","3     Positive            5  \n","4     Negative            1  \n","...        ...          ...  \n","2995   Neutral            5  \n","2996  Positive            5  \n","2997  Negative            5  \n","2998  Positive            5  \n","2999  Positive            5  \n","\n","[3000 rows x 4 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["for cmt_data in data_2700:\n","  # Lấy thông tin cần trích xuất\n","  cmtid = cmt_data['metadata']['cmtid']\n","  content =cmt_data['content']\n","  rating_star = cmt_data['metadata']['rating_star']\n","  class_name = cmt_data['classifications'][0]['classname']\n","\n","  # Thêm thông tin vào list records\n","  records.append({\n","      'cmtid': cmtid,\n","      'content': content,\n","      'classname': class_name,\n","      'rating_star': rating_star\n","  })\n","\n","# Tạo DataFrame từ list records\n","df = pd.DataFrame(records)\n","\n","# In ra DataFrame\n","df"]},{"cell_type":"markdown","metadata":{"id":"oFhS-os9NqET"},"source":["Tiến hành gộp 3000 comments đã gán nhãn lại để tạo ra bộ dữ liệu huấn luyện mô hình"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1702037413984,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"fMhWOMYXoh2k","outputId":"6f0232c0-5731-40f2-c28b-2e9a1b960e1f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-98a6a5ad-1f3e-4e88-aa36-4bd8ded4e870\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>itemid</th>\n","      <th>name</th>\n","      <th>comment</th>\n","      <th>rating_star</th>\n","      <th>clean_cmt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13239687733</td>\n","      <td>23886482112</td>\n","      <td>Áo len cardigan trơn dáng rộng AO26</td>\n","      <td>mặc khá mát vải này cũng ổn đẹp tuyệt với cho ...</td>\n","      <td>5</td>\n","      <td>mặc khá mát vải này cũng ổn đẹp tuyệt với cho ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13239626315</td>\n","      <td>23886482112</td>\n","      <td>Áo len cardigan trơn dáng rộng AO26</td>\n","      <td>hàng giao nhanhh chất lươngg sản phẩm tuyệt vo...</td>\n","      <td>5</td>\n","      <td>hàng giao nhanhh chất lươngg sản_phẩm tuyệt vo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13239565011</td>\n","      <td>23886482112</td>\n","      <td>Áo len cardigan trơn dáng rộng AO26</td>\n","      <td>Sp rất đẹp ,thơm, shop giao siêu nhanh, chất v...</td>\n","      <td>5</td>\n","      <td>sản_phẩm rất đẹp thơm shop giao siêu nhanh chấ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13175587025</td>\n","      <td>18894188708</td>\n","      <td>Áo Khoác Thom , Áo Khoác Lông Cừu 4 Sọc Cánh T...</td>\n","      <td>Màu sắc:ko\\nChất liệu:ko cos\\nĐúng với mô tả:k...</td>\n","      <td>1</td>\n","      <td>màu_sắc không chất_liệu không cos đúng với mô_...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13253091864</td>\n","      <td>18894188708</td>\n","      <td>Áo Khoác Thom , Áo Khoác Lông Cừu 4 Sọc Cánh T...</td>\n","      <td>Màu sắc:đen\\nĐúng với mô tả:cũng OK\\nChất liệu...</td>\n","      <td>1</td>\n","      <td>màu sắc đen đúng với mô_tả cũng ok chất_liệu c...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14298</th>\n","      <td>12768980268</td>\n","      <td>22648063543</td>\n","      <td>Quần kaki túi hộp nữ form suông rộng MIAA lưng...</td>\n","      <td>Trời ơi quần đẹp xỉu tụi bây ơi, thề mua được ...</td>\n","      <td>5</td>\n","      <td>trời_ơi quần đẹp xỉu tụi bây ơi thề mua được c...</td>\n","    </tr>\n","    <tr>\n","      <th>14299</th>\n","      <td>13249750307</td>\n","      <td>22648063543</td>\n","      <td>Quần kaki túi hộp nữ form suông rộng MIAA lưng...</td>\n","      <td>Quần vải đẹp, màu xinh lắm, form quần ưng nha,...</td>\n","      <td>5</td>\n","      <td>quần vải đẹp màu xinh lắm form quần ưng nha gi...</td>\n","    </tr>\n","    <tr>\n","      <th>14300</th>\n","      <td>13239621971</td>\n","      <td>22386234995</td>\n","      <td>N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...</td>\n","      <td>M63 45kg mặc sz L vừa chiều dài nha. Hàng đẹp ...</td>\n","      <td>5</td>\n","      <td>m 63 45 kilogram mặc size làm vừa chiều dài nh...</td>\n","    </tr>\n","    <tr>\n","      <th>14301</th>\n","      <td>13240092618</td>\n","      <td>22386234995</td>\n","      <td>N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...</td>\n","      <td>\"Chất liệu như mô tả\\nNhìn đẹp, sang nên mua đ...</td>\n","      <td>5</td>\n","      <td>chất_liệu như mô_tả nhìn đẹp sang nên mua để m...</td>\n","    </tr>\n","    <tr>\n","      <th>14302</th>\n","      <td>13339211202</td>\n","      <td>22386234995</td>\n","      <td>N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...</td>\n","      <td>Màu sắc:đen\\nĐúng với mô tả:đúng\\nChất liệu:nh...</td>\n","      <td>5</td>\n","      <td>màu sắc đen đúng với mô_tả đúng chất_liệu nhun...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14303 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98a6a5ad-1f3e-4e88-aa36-4bd8ded4e870')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-98a6a5ad-1f3e-4e88-aa36-4bd8ded4e870 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-98a6a5ad-1f3e-4e88-aa36-4bd8ded4e870');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-660e15ec-51cd-418f-8548-9ecfebd46119\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-660e15ec-51cd-418f-8548-9ecfebd46119')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-660e15ec-51cd-418f-8548-9ecfebd46119 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["             cmtid       itemid  \\\n","0      13239687733  23886482112   \n","1      13239626315  23886482112   \n","2      13239565011  23886482112   \n","3      13175587025  18894188708   \n","4      13253091864  18894188708   \n","...            ...          ...   \n","14298  12768980268  22648063543   \n","14299  13249750307  22648063543   \n","14300  13239621971  22386234995   \n","14301  13240092618  22386234995   \n","14302  13339211202  22386234995   \n","\n","                                                    name  \\\n","0                    Áo len cardigan trơn dáng rộng AO26   \n","1                    Áo len cardigan trơn dáng rộng AO26   \n","2                    Áo len cardigan trơn dáng rộng AO26   \n","3      Áo Khoác Thom , Áo Khoác Lông Cừu 4 Sọc Cánh T...   \n","4      Áo Khoác Thom , Áo Khoác Lông Cừu 4 Sọc Cánh T...   \n","...                                                  ...   \n","14298  Quần kaki túi hộp nữ form suông rộng MIAA lưng...   \n","14299  Quần kaki túi hộp nữ form suông rộng MIAA lưng...   \n","14300  N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...   \n","14301  N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...   \n","14302  N07 Sét Nhung QC Phối Viền, Sét Bộ Ngủ Cho Nữ ...   \n","\n","                                                 comment  rating_star  \\\n","0      mặc khá mát vải này cũng ổn đẹp tuyệt với cho ...            5   \n","1      hàng giao nhanhh chất lươngg sản phẩm tuyệt vo...            5   \n","2      Sp rất đẹp ,thơm, shop giao siêu nhanh, chất v...            5   \n","3      Màu sắc:ko\\nChất liệu:ko cos\\nĐúng với mô tả:k...            1   \n","4      Màu sắc:đen\\nĐúng với mô tả:cũng OK\\nChất liệu...            1   \n","...                                                  ...          ...   \n","14298  Trời ơi quần đẹp xỉu tụi bây ơi, thề mua được ...            5   \n","14299  Quần vải đẹp, màu xinh lắm, form quần ưng nha,...            5   \n","14300  M63 45kg mặc sz L vừa chiều dài nha. Hàng đẹp ...            5   \n","14301  \"Chất liệu như mô tả\\nNhìn đẹp, sang nên mua đ...            5   \n","14302  Màu sắc:đen\\nĐúng với mô tả:đúng\\nChất liệu:nh...            5   \n","\n","                                               clean_cmt  \n","0      mặc khá mát vải này cũng ổn đẹp tuyệt với cho ...  \n","1      hàng giao nhanhh chất lươngg sản_phẩm tuyệt vo...  \n","2      sản_phẩm rất đẹp thơm shop giao siêu nhanh chấ...  \n","3      màu_sắc không chất_liệu không cos đúng với mô_...  \n","4      màu sắc đen đúng với mô_tả cũng ok chất_liệu c...  \n","...                                                  ...  \n","14298  trời_ơi quần đẹp xỉu tụi bây ơi thề mua được c...  \n","14299  quần vải đẹp màu xinh lắm form quần ưng nha gi...  \n","14300  m 63 45 kilogram mặc size làm vừa chiều dài nh...  \n","14301  chất_liệu như mô_tả nhìn đẹp sang nên mua để m...  \n","14302  màu sắc đen đúng với mô_tả đúng chất_liệu nhun...  \n","\n","[14303 rows x 6 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import csv\n","\n","data_v2 = pd.read_csv(path.join(preprocessing_path, 'fashion_v2.csv'))\n","\n","data_v2"]},{"cell_type":"markdown","metadata":{"id":"61Qop2S-gRn3"},"source":["###Thay thế comment pre-processing cũ bằng comment pre-processing mới"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1702037413985,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"xXdgDv-wsAeE","outputId":"ac424609-03be-4cc6-86df-ebdca1e6c9a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-23d185bb16b1>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data.rename(columns={'rating_star_x': 'rating_star'}, inplace=True)\n"]},{"data":{"text/html":["\n","  <div id=\"df-11551c68-75c2-4c11-bae7-1122a7135c24\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>content</th>\n","      <th>classname</th>\n","      <th>clean_cmt</th>\n","      <th>rating_star</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12163393239</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>Negative</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12860404226</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>Negative</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13284156815</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>Positive</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11671891913</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>Positive</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10353479733</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>Negative</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2995</th>\n","      <td>13090938856</td>\n","      <td>đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...</td>\n","      <td>Neutral</td>\n","      <td>đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>9720766380</td>\n","      <td>mình nhận đc hàng rồi mua của shop lần thứ ba ...</td>\n","      <td>Positive</td>\n","      <td>mình nhận được hàng rồi mua của shop lần thứ b...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>13304661640</td>\n","      <td>mọi người nên suy_nghĩ trước khi mua nhé thật_...</td>\n","      <td>Negative</td>\n","      <td>mọi người nên suy_nghĩ trước khi mua nhé thật_...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>13268355664</td>\n","      <td>đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>13254595686</td>\n","      <td>quần xinh lắm luôn ạ mình m62 nặng 47 không mặ...</td>\n","      <td>Positive</td>\n","      <td>quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11551c68-75c2-4c11-bae7-1122a7135c24')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-11551c68-75c2-4c11-bae7-1122a7135c24 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-11551c68-75c2-4c11-bae7-1122a7135c24');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-70b02b14-e133-4261-9955-7ee331b2d585\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70b02b14-e133-4261-9955-7ee331b2d585')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-70b02b14-e133-4261-9955-7ee331b2d585 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["            cmtid                                            content  \\\n","0     12163393239                    nói_chung là xấu vải áo xấu lắm   \n","1     12860404226                              giao bé quá thất_vọng   \n","2     13284156815  màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...   \n","3     11671891913  chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...   \n","4     10353479733                              màu sắc đen chất mỏng   \n","...           ...                                                ...   \n","2995  13090938856  đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...   \n","2996   9720766380  mình nhận đc hàng rồi mua của shop lần thứ ba ...   \n","2997  13304661640  mọi người nên suy_nghĩ trước khi mua nhé thật_...   \n","2998  13268355664  đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...   \n","2999  13254595686  quần xinh lắm luôn ạ mình m62 nặng 47 không mặ...   \n","\n","     classname                                          clean_cmt  rating_star  \n","0     Negative                    nói_chung là xấu vải áo xấu lắm            1  \n","1     Negative                              giao bé quá thất_vọng            1  \n","2     Positive  màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...            5  \n","3     Positive  chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...            5  \n","4     Negative                              màu sắc đen chất mỏng            1  \n","...        ...                                                ...          ...  \n","2995   Neutral  đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...            5  \n","2996  Positive  mình nhận được hàng rồi mua của shop lần thứ b...            5  \n","2997  Negative  mọi người nên suy_nghĩ trước khi mua nhé thật_...            5  \n","2998  Positive  đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...            5  \n","2999  Positive  quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...            5  \n","\n","[3000 rows x 5 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_new = pd.merge(df, data_v2, how = \"left\", on = \"cmtid\")\n","train_data = df_new[['cmtid','content','classname','clean_cmt','rating_star_x']]\n","train_data.rename(columns={'rating_star_x': 'rating_star'}, inplace=True)\n","train_data"]},{"cell_type":"markdown","metadata":{"id":"AXeDwsMTNwAG"},"source":["Trong quá trình gán nhãn, nhóm có bổ sung các từ viết tắt cũng như teencode, do đó các clean_cmt cần được cập nhật lại để đảm bảo độ chính xác"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":548},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1702037413985,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"OgJohqsZ3ZYa","outputId":"574691ec-6f0d-4ae3-d16a-8656a46505bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-11-5101c5f451fe>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['content'] = train_data['clean_cmt'].apply(lambda x: x.replace(\"_\", \" \"))\n"]},{"data":{"text/html":["\n","  <div id=\"df-391a2e37-d442-4606-a7b0-8f92e5e7816a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cmtid</th>\n","      <th>content</th>\n","      <th>classname</th>\n","      <th>clean_cmt</th>\n","      <th>rating_star</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12163393239</td>\n","      <td>nói chung là xấu vải áo xấu lắm</td>\n","      <td>Negative</td>\n","      <td>nói_chung là xấu vải áo xấu lắm</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12860404226</td>\n","      <td>giao bé quá thất vọng</td>\n","      <td>Negative</td>\n","      <td>giao bé quá thất_vọng</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13284156815</td>\n","      <td>màu sắc nâu đúng với mô tả 10 10 chất liệu nỉ ...</td>\n","      <td>Positive</td>\n","      <td>màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11671891913</td>\n","      <td>chất liệu đẹp màu sắc đúng màu đúng với mô tả ...</td>\n","      <td>Positive</td>\n","      <td>chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10353479733</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>Negative</td>\n","      <td>màu sắc đen chất mỏng</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2995</th>\n","      <td>13090938856</td>\n","      <td>đúng với mô tả đúng với mô tả màu sắc be nâu c...</td>\n","      <td>Neutral</td>\n","      <td>đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>9720766380</td>\n","      <td>mình nhận được hàng rồi mua của shop lần thứ b...</td>\n","      <td>Positive</td>\n","      <td>mình nhận được hàng rồi mua của shop lần thứ b...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>13304661640</td>\n","      <td>mọi người nên suy nghĩ trước khi mua nhé thật ...</td>\n","      <td>Negative</td>\n","      <td>mọi người nên suy_nghĩ trước khi mua nhé thật_...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>13268355664</td>\n","      <td>đúng với mô tả gửi đúng màu đúng mẫu màu sắc m...</td>\n","      <td>Positive</td>\n","      <td>đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>13254595686</td>\n","      <td>quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...</td>\n","      <td>Positive</td>\n","      <td>quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-391a2e37-d442-4606-a7b0-8f92e5e7816a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-391a2e37-d442-4606-a7b0-8f92e5e7816a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-391a2e37-d442-4606-a7b0-8f92e5e7816a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-147a44a7-eae9-4a09-9daa-b6e921605785\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-147a44a7-eae9-4a09-9daa-b6e921605785')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-147a44a7-eae9-4a09-9daa-b6e921605785 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["            cmtid                                            content  \\\n","0     12163393239                    nói chung là xấu vải áo xấu lắm   \n","1     12860404226                              giao bé quá thất vọng   \n","2     13284156815  màu sắc nâu đúng với mô tả 10 10 chất liệu nỉ ...   \n","3     11671891913  chất liệu đẹp màu sắc đúng màu đúng với mô tả ...   \n","4     10353479733                              màu sắc đen chất mỏng   \n","...           ...                                                ...   \n","2995  13090938856  đúng với mô tả đúng với mô tả màu sắc be nâu c...   \n","2996   9720766380  mình nhận được hàng rồi mua của shop lần thứ b...   \n","2997  13304661640  mọi người nên suy nghĩ trước khi mua nhé thật ...   \n","2998  13268355664  đúng với mô tả gửi đúng màu đúng mẫu màu sắc m...   \n","2999  13254595686  quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...   \n","\n","     classname                                          clean_cmt  rating_star  \n","0     Negative                    nói_chung là xấu vải áo xấu lắm            1  \n","1     Negative                              giao bé quá thất_vọng            1  \n","2     Positive  màu_sắc nâu đúng với mô_tả 10 10 chất_liệu nỉ ...            5  \n","3     Positive  chất_liệu đẹp màu_sắc đúng màu đúng với mô_tả ...            5  \n","4     Negative                              màu sắc đen chất mỏng            1  \n","...        ...                                                ...          ...  \n","2995   Neutral  đúng với mô_tả đúng với mô_tả màu_sắc be nâu c...            5  \n","2996  Positive  mình nhận được hàng rồi mua của shop lần thứ b...            5  \n","2997  Negative  mọi người nên suy_nghĩ trước khi mua nhé thật_...            5  \n","2998  Positive  đúng với mô_tả gửi đúng màu đúng mẫu màu_sắc m...            5  \n","2999  Positive  quần xinh lắm luôn ạ mình m62 nặng 47 kilogram...            5  \n","\n","[3000 rows x 5 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_data['content'] = train_data['clean_cmt'].apply(lambda x: x.replace(\"_\", \" \"))\n","train_data"]},{"cell_type":"markdown","metadata":{"id":"RU8TkVRvN_6S"},"source":["Khác với tiếng Anh, đặc trưng của ngôn ngữ tiếng Việt là từ ghép, do đó nhóm tiến hành huấn luyện mô hình trên 2 tập dữ liệu là tập dữ liệu có tách từ (word_segment) và không có tách từ để đo độ hiệu quả của mô hình.\n","\n","* Cột content là cột chứa các comment không được tách từ\n","* Cột clean_cmt là cột chứa các comment được tách từ"]},{"cell_type":"markdown","metadata":{"id":"EdZ1PPXCgcht"},"source":["##2.2. Machine Learning"]},{"cell_type":"markdown","metadata":{"id":"p2q1w-2iQjrX"},"source":["Để thực hiện huấn luyện mô hình bằng Máy học, trước tiên nhóm tiến hành import các thư viện liên quan để sử dụng, trong đó bao gồm:\n","*   sklearn -  thư viện Machine Learning của Python, cung cấp nhiều mô hình và thuật toán Machine Learning khác nhau\n","*   numpy - thư viện cung cấp các hàm và cấu trúc dữ liệu để xử lý dữ liệu số\n","*   transformers - thư viện cung cấp các mô hình Transformer bao gồm BERT, RoBERTa, v.v.\n","*   more_itertools - thư viện cung cấp các hàm mở rộng cho các đối tượng iterable.\n","*   torch - thư viện Machine Learning dựa trên GPU của Python, cung cấp các mô hình và thuật toán Machine Learning được tối ưu hóa cho GPU.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-DzlfNuvTKT"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","metadata":{"id":"lIUWZj6-gtp-"},"source":["###Tạo hàm chuyển văn bản thành vector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232,"referenced_widgets":["9718027d5ce740aa9cf2a7b41a7df10a","f238c8244a544fdf9860337e2cfb5a92","92021d0ef2a14005b98440cd74543430","3f700128d3ec44899e4e392185a7f15f","e0412659fb3e4dca95b0d37d858516af","a57720487bc849bba8a1977c51898b1e","0bf13a0e9e67491fb679e2c037bc1882","dfa4273ff7ef452fb3cb656447b81f09","87d08bdf660a431cae8c0aeecb28431f","a7deb85baccf455fadb827f3ea3bae57","e2f7da7554144067b68b46ed54b3657c","41017bad4a4f46eb9cf500a8923b6390","6d6da3ff18bb449788b8b4fccc1d9eb2","96d257683413425ba74b06f5d74feb3f","f037cb8cb26344f5a1c2d2696421790f","3e9135ffc5164eefbdf11d6ddf018d44","09fdfe5f453e4859a238cfb4f4a5edfd","eb44200b7620466ca617683e7d78424d","9b14ba0d74414f49b008136aca6f6bfa","bda8f2f902264654be38f901113a249b","7f57328f2f9f426c80c4c8e540633e67","de6a57daa3514e25920923209978398a","27c5cdf31fdf48f6814c2f65f9d378a5","28d1b7564de544b6acf25d84a111b706","1f9d021091aa4d29b6ab322f9a3d5bd9","e30ab18aeda64c61912ae489373c7ef0","8cf134e5f9d54a10acc61fb8f4388834","b66726e54cfb4f318fda28f15c2c46a4","f94c990a39d64ccf9fece7a1918a8267","3d638a7603d04eb9ae4146eb86ecc29c","f5f7b43689964366a0e72e59804521ab","0782dfb1bfc54f418697622dafb1c768","e1b468cc6145455dbb5ee34846e54843","93142e0c997448e59d1a76683bdb8bcc","e545ebf59d1f4351bb610d9679e85b99","1981a4f700714dd6931ec0d93cdf4276","867f18c730744351b68d66363353b8cf","ce4f20264afc407c89e0abf6af544cab","7860ee7c888849268f9a81c53d8be429","6fbf5dde3feb42dda729a197fe60d459","c69861e632e64be5ae165b0e4a61b36c","53d364bafec24598b5e5640c7f2dd192","605596f4978a4fd6956c116855e50dfc","7390dbb648f945c88a27f544eb0779e7","86931bb632f24853b3054d8c9bb34979","7cfb965ede3e4e66bfb068f757a019be","c18213f4e45148858a559f9cb7049a32","068ba042ef264bcdb723383e3a0c336d","5025c5d9be0342e98ce11258b5d89f84","218bb1c8a34743feac9fe300d34302b5","3f4834aa78ab4290b03f689c94650dcd","5f4bb6f5e2a44efd9db05e5bd11becb1","734eac47600f4de0979d8937c9e77506","caa7f4a046f343909710cdde14d1d75e","27dd5f5bd0c64f328da8d04152bc001b"]},"executionInfo":{"elapsed":19889,"status":"ok","timestamp":1702037434259,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"obEKJ_Qs9kdZ","outputId":"f20e2859-a5ee-463b-b343-0dfd5a075823"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9718027d5ce740aa9cf2a7b41a7df10a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41017bad4a4f46eb9cf500a8923b6390","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27c5cdf31fdf48f6814c2f65f9d378a5","version_major":2,"version_minor":0},"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93142e0c997448e59d1a76683bdb8bcc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86931bb632f24853b3054d8c9bb34979","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import numpy as np\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from transformers import AutoTokenizer, AutoModel\n","from more_itertools import chunked\n","import torch\n","\n","class TransformerEmbedding(TransformerMixin, BaseEstimator):\n","\n","    def __init__(self, model_name='bert-base-uncased', batch_size=1, layer=-1):\n","        self.model_name = model_name\n","        self.layer = layer\n","        self.batch_size = batch_size\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","        self.model = AutoModel.from_pretrained(self.model_name).to(self.device)\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        res = []\n","        total = 0\n","        for batch in chunked(X, self.batch_size):\n","            encoded_input = self.tokenizer(\n","                batch,\n","                max_length = 256,\n","                return_tensors='pt',\n","                padding = 'max_length',\n","                truncation = True,\n","                pad_to_max_length = True,\n","                add_special_tokens = True,\n","            ).to(self.device)\n","\n","            with torch.no_grad():\n","              output = self.model(**encoded_input)\n","              embed = output.last_hidden_state[:,-1].cpu().detach().numpy()\n","              res.append(embed)\n","        return np.concatenate(res)\n","\n","\n","model_name = 'vinai/phobert-base-v2'\n","\n","bert_embed = TransformerEmbedding(model_name, batch_size = 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbHwhHgiwZq0"},"outputs":[],"source":["X = bert_embed.transform(train_data['clean_cmt'])\n","X_no_word_segment = bert_embed.transform(train_data['content'])\n","\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(train_data['classname'])"]},{"cell_type":"markdown","metadata":{"id":"I2FPg1VITMPh"},"source":["###Cài đặt K-Fold"]},{"cell_type":"markdown","metadata":{"id":"CugNs-avSLsJ"},"source":["\n","\n","Khi có một lượng dữ liệu đủ lớn, tập dữ liệu thường sẽ được chia theo tỉ lệ 80/20 để tiến hành huấn luyện và kiểm thử mô hình. Tuy nhiên, với bộ huấn luyện 3000 dòng dữ liệu thì việc chia như vậy có thể dẫn đến model hoạt động kém. Do đó, nhóm chọn **K-Fold Cross Validation** để lấy mẫu đánh giá mô hình."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkjV--Eefo5k"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Define k-fold cross-validation\n","num_folds = 5\n","skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n","scoring = {'accuracy', 'f1_weighted'}\n","\n","X = scaler.fit_transform(X)\n","X_no_word_segment = scaler.fit_transform(X_no_word_segment)"]},{"cell_type":"markdown","metadata":{"id":"aB0lpOVlTS-b"},"source":["**Thông số đo lường**\n","\n","*   Accuracy - độ chính xác\n","*   F1 score - giá trị trung bình của độ chính xác và khả năng thu hồi\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RwxLhbJEV0Ld"},"source":["###Huấn luyện mô hình Máy học Naive Bayes, Logistic Regression, và Linear Support Vector Machine"]},{"cell_type":"markdown","metadata":{"id":"-niZOfrlWF5N"},"source":["\n","\n","1.   Naive Bayes\n","\n","\n","> Có rất nhiều thuật toán học máy được sử dụng để giải quyết cho bài toán phân lớp văn bản (Text Classification). Tuy nhiên, Naïve Bayes là thuật toán có thời gian chạy nhanh và độ chính xác cao nên thường được sử dụng cho các bài toán phân lớp văn bản. Trong một nghiên cứu của tác giả Đặng Văn Nam (2020) trình bày cụ thể việc xây dựng một mô hình học máy với thuật toán Naïve Bayes sử dụng đặc trưng TF-IDF (Term Frequency – Inverse DocumentFrequency) trong phân lớp văn bản đã cho thấy hiệu quả của thuật toán Naive Bayes so với các thuật toán học máy khác với thời gian huấn luyện, kiểm thử mô hình rất nhanh và độ chính\n","xác cao.\n","\n","\n","2.   Logistic Regression\n","\n","\n","> Hồi quy Logistic (Logistic Regression) là thuật toán Supervised Learning (học máy có giám sát), là một kỹ thuật phân tích dữ liệu sử dụng toán học để tìm ra mối quan hệ giữa hai yếu tố dữ liệu. Sau đó, kỹ thuật này sử dụng mối quan hệ đã tìm được để dự đoán giá trị của một yếu tố dựa trên yếu tố còn lại. Trong nghiên cứu của nhóm tác giả Priyanshi Kathuria, Parth Sethi, Rithwick Negi (2022) về bình luận và rating trên các sàn thương mại điện tử, kết quả dự đoán cho thấy với mô hình Logistic Regression cho kết quả có độ chính xác cao nhất ở cả hai nhóm phân tích là bình luận (88,18%) và đánh giá (80,68%)\n","\n","\n","3.   Linear Support Vector Machine\n","\n","\n","> Mô hình SVM là một mô hình có thể sử dụng cho bài toán phân lớp (classification) cũng như bài toán hồi quy (regression). Đây là thuật toán\n","hỗ trợ phân loại rất phổ biến và hiệu quả, có thể áp dụng trong học có giám sát hoặc bán giám sát. Trong nghiên cứu của tác giả Đặng Quang Vinh (2023) đã xem xét bài toán định giá quyền chọn sử dụng công thức Black-Scholes bằng một số thuật toán máy học có giám sát (supervised machine learning). Kết quả thực nghiệm cho thấy mô hình SVM có nhiều khả năng ước lượng giá quyền chọn với độ chính xác cao so với các mô hình truyền thống khác\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":96169,"status":"ok","timestamp":1702037699665,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"-8FEuphSv9Hr","outputId":"465c48a8-4960-41e2-e27b-28dd616c16e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'fit_time': array([0.02172709, 0.01031828, 0.00990748, 0.00944304, 0.0157845 ]), 'score_time': array([0.00792313, 0.00620461, 0.0067296 , 0.00369859, 0.0058043 ]), 'test_accuracy': array([0.48333333, 0.48833333, 0.48166667, 0.47      , 0.48      ]), 'test_f1_weighted': array([0.41713045, 0.41994243, 0.42025307, 0.41625397, 0.41494876])}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"name":"stdout","output_type":"stream","text":["{'fit_time': array([1.27673912, 1.5200038 , 1.56248832, 1.63424158, 2.2686758 ]), 'score_time': array([0.01312828, 0.00656676, 0.00926089, 0.00823379, 0.01321769]), 'test_accuracy': array([0.75      , 0.73833333, 0.735     , 0.745     , 0.74333333]), 'test_f1_weighted': array([0.74789354, 0.73253624, 0.73141872, 0.74490288, 0.73729776])}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'fit_time': array([9.25089502, 7.32827353, 8.87322879, 8.60858464, 8.11272144]), 'score_time': array([0.01170349, 0.00464034, 0.00826836, 0.00480747, 0.00550103]), 'test_accuracy': array([0.73166667, 0.73166667, 0.70666667, 0.71666667, 0.725     ]), 'test_f1_weighted': array([0.73210208, 0.72509479, 0.70463256, 0.7131655 , 0.71772441])}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","  <div id=\"df-bb763ce9-89be-4a0c-9e08-e98261501758\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Mean accuracy</th>\n","      <th>Mean f1</th>\n","      <th>Mean accuracy without word segment</th>\n","      <th>Mean f1 without word segment</th>\n","    </tr>\n","    <tr>\n","      <th>Model Name</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>MultinomialNB</th>\n","      <td>0.480667</td>\n","      <td>0.417706</td>\n","      <td>0.469333</td>\n","      <td>0.434393</td>\n","    </tr>\n","    <tr>\n","      <th>LogisticRegression</th>\n","      <td>0.742333</td>\n","      <td>0.738810</td>\n","      <td>0.751333</td>\n","      <td>0.747949</td>\n","    </tr>\n","    <tr>\n","      <th>LinearSVC</th>\n","      <td>0.722333</td>\n","      <td>0.718544</td>\n","      <td>0.718000</td>\n","      <td>0.716193</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb763ce9-89be-4a0c-9e08-e98261501758')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bb763ce9-89be-4a0c-9e08-e98261501758 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bb763ce9-89be-4a0c-9e08-e98261501758');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-512382ff-12c9-458d-bdc6-9b3694ff147e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-512382ff-12c9-458d-bdc6-9b3694ff147e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-512382ff-12c9-458d-bdc6-9b3694ff147e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                    Mean accuracy   Mean f1  \\\n","Model Name                                    \n","MultinomialNB            0.480667  0.417706   \n","LogisticRegression       0.742333  0.738810   \n","LinearSVC                0.722333  0.718544   \n","\n","                    Mean accuracy without word segment  \\\n","Model Name                                               \n","MultinomialNB                                 0.469333   \n","LogisticRegression                            0.751333   \n","LinearSVC                                     0.718000   \n","\n","                    Mean f1 without word segment  \n","Model Name                                        \n","MultinomialNB                           0.434393  \n","LogisticRegression                      0.747949  \n","LinearSVC                               0.716193  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize Naive Bayes, Logistic Regression, LinearSVC\n","model = [MultinomialNB(), LogisticRegression(), LinearSVC()]\n","table_ml = []\n","\n","for i in model:\n","  cross_val_scores = cross_validate(i, X, y, cv=skf, scoring=scoring)\n","  cross_val_scores_2 = cross_validate(i, X_no_word_segment, y, cv=skf, scoring=scoring)\n","  print(cross_val_scores)\n","  table_ml.append({\n","      \"Model Name\": type(i).__name__,\n","      \"Mean accuracy\": cross_val_scores['test_accuracy'].mean(),\n","      \"Mean f1\": cross_val_scores['test_f1_weighted'].mean(),\n","      \"Mean accuracy without word segment\": cross_val_scores_2['test_accuracy'].mean(),\n","      \"Mean f1 without word segment\": cross_val_scores_2['test_f1_weighted'].mean()\n","\n","})\n","result_df = pd.DataFrame(table_ml)\n","result_df.set_index(\"Model Name\", inplace=True)\n","\n","result_df"]},{"cell_type":"markdown","metadata":{"id":"3RvLJEwAhUOh"},"source":["##2.3. Deep Learning"]},{"cell_type":"markdown","metadata":{"id":"qBF5996qXUgv"},"source":["Để thực hiện huấn luyện mô hình bằng Học sâu, trước tiên nhóm tiến hành import các thư viện liên quan để sử dụng, trong đó bao gồm:\n","*   tensorflow - cung cấp nhiều mô hình và thuật toán học sâu khác nhau, cũng như các công cụ để xây dựng và huấn luyện các mô hình học sâu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7AvL0SHg9Ii"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import f1_score, accuracy_score\n","import tensorflow as tf\n","import tensorflow_addons as tfa"]},{"cell_type":"markdown","metadata":{"id":"zpa7d7lph4Zx"},"source":["###Huấn luyện mô hình Học sâu CNN\n","\n","Mô hình CNN: CNN có khả năng tự động học và phát hiện các đặc trưng không gian trong dữ liệu, điều này rất hữu ích khi xử lý các vấn đề liên quan đến ngôn ngữ tự nhiên như phân tích cảm xúc trong bình luận. Đồng thời, bình luận thường được biểu diễn dưới dạng chuỗi từ và câu. CNN có thể được sử dụng để xử lý chuỗi dữ liệu thông qua việc sử dụng các tầng convolutional để nhận diện các đặc trưng trong không gian từ. Trong một nghiên cứu của nhóm tác giả Trần Quốc Khánh, Nguyễn Trọng Ân, Hoàng Gia Phú, Lưu Đức Cảnh (2022) đã ứng dụng đề xuất phương pháp mới và hiệu quả để giải quyết bài toán phát hiện ngôn ngữ xúc phạm tiếng Việt dựa trên mô hình PhoBERT-CNN, kết quả nghiên cứu cho thấy mô hình PhoBERT-CNN có thể đạt được độ chính xác lên tới 93,2% trong bài toán phát hiện ngôn ngữ xúc phạm tiếng Việt."]},{"cell_type":"markdown","metadata":{"id":"LiYsYpJUZSwg"},"source":["#### Huấn luyện mô hình với tập dữ liệu có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50139,"status":"ok","timestamp":1702038691292,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"19S_gHEY3B95","outputId":"12e14179-19c4-4caf-ddde-3ffd89abe23f"},"outputs":[{"name":"stdout","output_type":"stream","text":["19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.6087441917707186\n","Accuracy: 0.6533333333333333\n","\n","19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.5335629896849107\n","Accuracy: 0.61\n","\n","19/19 [==============================] - 0s 6ms/step\n","F1 Score: 0.5750205539815464\n","Accuracy: 0.6016666666666667\n","\n","19/19 [==============================] - 0s 3ms/step\n","F1 Score: 0.5991278134681975\n","Accuracy: 0.6166666666666667\n","\n","19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.5819791106741686\n","Accuracy: 0.62\n","\n","ACC 0.6203333333333333\n","F1 0.5796869319159084\n"]}],"source":["accuracys = []\n","f1s = []\n","for train_index, test_index in skf.split(X, y):\n","    y_train_one_hot = to_categorical(y, num_classes=3)\n","\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y_train_one_hot[train_index], y_train_one_hot[test_index]\n","\n","    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","    # Xây dựng mô hình CNN\n","    model = Sequential()\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 2, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 3, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 4, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(3, activation='sigmoid'))\n","\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  )\n","\n","    # # Huấn luyện mô hình\n","    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)\n","\n","    # Đánh giá mô hình\n","    y_pred = model.predict(X_test)\n","\n","    y_pred = np.argmax(y_pred, axis = 1)\n","    y_test = np.argmax(y_test, axis = 1)\n","\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    print(\"F1 Score:\", f1)\n","    print(\"Accuracy:\", accuracy)\n","    print()\n","\n","    accuracys.append(accuracy)\n","    f1s.append(f1)\n","\n","print(\"ACC\", sum(accuracys)/len(accuracys))\n","print(\"F1\", sum(f1s)/len(f1s))"]},{"cell_type":"markdown","metadata":{"id":"zqKKwcaSiFSx"},"source":["####Huấn luyện mô hình với tập dữ liệu không có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38336,"status":"ok","timestamp":1702038729616,"user":{"displayName":"Snake Game","userId":"15149353055136077620"},"user_tz":-420},"id":"X5K4FJimZUHB","outputId":"0cd9c41b-88e5-438f-d482-5a9ee24bbf1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.5518050431615232\n","Accuracy: 0.6066666666666667\n","\n","19/19 [==============================] - 0s 3ms/step\n","F1 Score: 0.6087532659481361\n","Accuracy: 0.635\n","\n","19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.5281345094577569\n","Accuracy: 0.5883333333333334\n","\n","19/19 [==============================] - 0s 3ms/step\n","F1 Score: 0.5899463487567707\n","Accuracy: 0.6333333333333333\n","\n","19/19 [==============================] - 0s 4ms/step\n","F1 Score: 0.568117713341757\n","Accuracy: 0.6166666666666667\n","\n","ACC 0.616\n","F1 0.5693513761331888\n"]}],"source":["accuracys = []\n","f1s = []\n","for train_index, test_index in skf.split(X_no_word_segment, y):\n","    y_train_one_hot = to_categorical(y, num_classes=3)\n","\n","    X_train, X_test = X_no_word_segment[train_index], X_no_word_segment[test_index]\n","    y_train, y_test = y_train_one_hot[train_index], y_train_one_hot[test_index]\n","\n","    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n","    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","    # Xây dựng mô hình CNN\n","    model = Sequential()\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 2, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 3, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(128, 4, activation='relu'))\n","    model.add(MaxPooling1D())\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(3, activation='sigmoid'))\n","\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  )\n","\n","    # # Huấn luyện mô hình\n","    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)\n","\n","    # Đánh giá mô hình\n","    # evaluates = model.evaluate(X_test, y_test, verbose=0)\n","    y_pred = model.predict(X_test)\n","\n","    y_pred = np.argmax(y_pred, axis = 1)\n","    y_test = np.argmax(y_test, axis = 1)\n","\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    print(\"F1 Score:\", f1)\n","    print(\"Accuracy:\", accuracy)\n","    print()\n","\n","    accuracys.append(accuracy)\n","    f1s.append(f1)\n","    # print(f'Loss: {loss}, Accuracy: {accuracy}')\n","\n","    # print(loss)\n","\n","print(\"ACC\", sum(accuracys)/len(accuracys))\n","print(\"F1\", sum(f1s)/len(f1s))"]},{"cell_type":"markdown","metadata":{"id":"5L24G0nMiIos"},"source":["##2.4. Transformer Model"]},{"cell_type":"markdown","metadata":{"id":"JVl-BvWBb58C"},"source":["Để thực hiện huấn luyện mô hình bằng Transformer Model, trước tiên nhóm tiến hành import các thư viện liên quan để sử dụng, trong đó bao gồm:\n","*   tensorflow - cung cấp nhiều mô hình và thuật toán học sâu khác nhau, cũng như các công cụ để xây dựng và huấn luyện các mô hình học sâu.\n","*   torch -  được sử dụng để tối ưu hóa quá trình huấn luyện mô hình Transformer trên GPU\n","*   transformers -  được sử dụng để tối ưu hóa quá trình huấn luyện mô hình Transformer trên GPU\n","*   statistics - cung cấp các hàm và cấu trúc dữ liệu để thực hiện các phép tính thống kê, được sử dụng để tính toán các chỉ số đánh giá mô hình, chẳng hạn như độ chính xác, độ nhạy, độ đặc hiệu, v.v.\n","*   math - cung cấp các hàm và cấu trúc dữ liệu để thực hiện các phép tính toán học để thực hiện các phép tính toán học cần thiết cho quá trình huấn luyện, chẳng hạn như tính toán gradient và tối ưu hóa hàm mất mát\n","*   load_metric - được sử dụng để tải các chỉ số đánh giá mô hình đã được cài đặt sẵn\n"]},{"cell_type":"markdown","metadata":{"id":"tb_DOBbfdsmm"},"source":["###Huấn luyện mô hình Transformer PhoBERT, XLM-RoBERTa\n","1.   PhoBERT\n","\n","PhoBERT là một mô hình transformer, một loại mô hình học máy có thể học được mối quan hệ giữa các từ trong văn bản. Mô hình này có thể được sử dụng cho nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP). Trong nghiên cứu của nhóm tác giả Ngô Văn Sơn, Nguyễn Thị Minh Nghĩa, Hoàng Thị Huế, Nguyễn Hữu Liêm, Võ Viết Minh Nhật (2022) về cải tiến của PhoBERT nhằm tăng khả năng hiểu tiếng Việt của Chatbot thông tin khách sạn, mô hình PhoBERT sau khi thực hiện điều chỉnh cho kết quả tốt nhất trong việc phân loại ý định. Chỉ số đánh giá cho thấy mô hình PhoBERT hoạt động tốt hơn nhiều so với BERT và FastText.\n","2.   XLM-RoBERTa\n","\n","XLM-RoBERTa là một mô hình ngôn ngữ mạng nơ-ron tiên tiến được phát triển bởi Facebook AI Research (FAIR). Đây là một biến thể của mô hình Roberta, được thiết kế đặc biệt để xử lý ngôn ngữ tự nhiên và chia sẻ thông tin giữa các ngôn ngữ khác nhau. Nhóm tác giả Nguyễn Ngọc Toàn, Lê Xuân Tấn, Lương Thế Dũng, Trần Nghi Phú (2022) đã dùng mô hình XLM-RoBERTa để nghiên cứu về \"nhận dạng thực thể được đặt tên trong văn bản Tiếng Việt sử dụng học máy và ứng dụng trong an ninh mạng\". Kết quả cho thấy mô hình XLM-RoBERTa nhận dạng rất tốt với chỉ số của các nhãn trong nghiên cứu đều đạt trên 90%.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YHfAAeTeekam"},"source":["####Giải phóng bộ nhớ GPU trong quá trình train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqSRfeqbiLxk"},"outputs":[],"source":["import gc\n","\n","def free_gpu():\n","  torch.cuda.empty_cache()\n","  gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qq802cBVikfE"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","import os, pickle, re, keras, sklearn, string, io, gensim, warnings, io\n","import random as rn\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"JhwahVDWgg1V"},"source":["#### Chuẩn hóa dữ liệu để đưa vào mô hình"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYHhtxWc1Zmg"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","import torch.nn.functional as F\n","\n","def get_train_test(label, word = True):\n","\n","    if word:\n","        X = train_data['clean_cmt'].values.tolist()\n","    else:\n","        X = train_data['content'].values.tolist()\n","\n","    label_encoder = LabelEncoder()\n","    y = label_encoder.fit_transform(train_data['classname'])\n","    y = F.one_hot(torch.tensor(y), num_classes=3).numpy()\n","\n","    X = np.array(X)\n","    y = np.array(y)\n","\n","    test_size = 0.2\n","\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(X,\n","                                                        y, test_size=test_size,\n","                                                        stratify = y,\n","                                                        random_state=seed)\n","\n","    print(X_train[0])\n","    print(y_train[0])\n","    print(X_test[0])\n","    print(y_test[0])\n","    print(X_train[0])\n","    print(y_train[0])\n","    print(X_test[0])\n","\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"markdown","metadata":{"id":"HjoEqtnYi2XY"},"source":["#### Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6H5V5hoi0ZE"},"outputs":[],"source":["!pip install sentencepiece\n","!pip install transformers[torch]\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FmL52yJi4Zw"},"outputs":[],"source":["from torch.nn import *\n","from transformers import *\n","import torch\n","import random,operator\n","import pickle, statistics\n","from sklearn.metrics import *\n","import math\n","from torch.utils.data import DataLoader\n","from datasets import load_metric\n","metric = load_metric('accuracy') # Acccuracy\n","from transformers import logging\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"kMsXzVFBgrNt"},"source":["#### In cấu hình mô trường"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702096709379,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"ZC8ZD5mGRZaf","outputId":"98d93ae9-7797-4194-a493-c20ceb54ca5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Dec  9 04:38:27 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   66C    P0    31W /  70W |    315MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from torch import cuda\n","device = 'cuda'if cuda.is_available() else 'cpu'\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"Ugg_ptKHt1to"},"source":["#### Cài đặt môi trường để tránh sự random về số"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HneamaWNjBmw"},"outputs":[],"source":["seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","random.seed(seed)\n","np.random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"8kknSZ1mt9Y8"},"source":["#### Các hàm bổ trợ"]},{"cell_type":"markdown","metadata":{"id":"sjs2wcang67F"},"source":["##### Hàm chuyển đổi label qua id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3eTqcp6jEv6"},"outputs":[],"source":["def convert_lb2id(label):\n","  label2id = {}\n","  for idx, i in enumerate(label):\n","    label2id[i] = idx\n","\n","  return label2id\n","\n","def convert_id2lb(label):\n","  id2label = {}\n","  for idx, i in enumerate(label):\n","    id2label[idx] = i\n","\n","  return id2label"]},{"cell_type":"markdown","metadata":{"id":"gPHxrvaVhHnv"},"source":["##### Tạo cấu trúc bộ dữ liệu cho máy học"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvL8c72MjHoc"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class CustomDataset(Dataset):\n","    def __init__ (self, tokenizer, label_list, X_data, y_data = None):\n","        self.tokenizer = tokenizer\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        self.label_list = label_list\n","\n","    def __len__ (self):\n","        return len(self.X_data)\n","\n","    def __getitem__(self, idx):\n","        inputs = self.tokenizer.encode_plus(\n","            self.X_data[idx],\n","            max_length=256,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","\n","        return_data = {\n","            'input_ids' : inputs.input_ids.squeeze(),\n","            'attention_mask': inputs.attention_mask.squeeze(),\n","        }\n","\n","        if self.y_data is not None:\n","          return_data['labels'] = torch.FloatTensor(self.y_data[idx])\n","\n","\n","        return return_data"]},{"cell_type":"markdown","metadata":{"id":"yHZPA8jsiH4I"},"source":["##### Tạo thực thể huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w81iSjK7jJ4u"},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","class CustomTrainer(Trainer):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.class_weights = None  # Initialize class_weights\n","        self.compute_class_weights()\n","\n","    def compute_class_weights(self):\n","        # Assuming labels are integers representing class indices\n","        unique_classes = np.unique(np.argmax(y, axis = 1))\n","        class_weights = compute_class_weight('balanced', classes=unique_classes, y=np.argmax(y, axis = 1))\n","        self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","\n","        if \"labels\" in inputs:\n","          labels = inputs.pop(\"labels\")\n","\n","        # Forward\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","        #  Compute loss\n","        loss_function = CrossEntropyLoss(weight = self.class_weights)       # MCC\n","        # loss_function = BCEWithLogitsLoss()    # MLC\n","\n","        if self.args.past_index >= 0:\n","            self._past = outputs[self.args.past_index]\n","\n","        if labels is not None:\n","            loss = loss_function(logits, labels)\n","        else:\n","            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n","            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n","\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"markdown","metadata":{"id":"F7eLnc4ZiPyo"},"source":["##### Tạo hàm lấy dữ liệu để huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8v9a4ZQjOq2"},"outputs":[],"source":["def get_dataset(tokenizer, label_model, X_train, X_test, y_train, y_test):\n","  train_dataset = CustomDataset(tokenizer, label_model, X_train, y_train)\n","  if type_job == \"train\":\n","    test_dataset = CustomDataset(tokenizer, label_model, X_test, y_test)\n","  else:\n","    test_dataset = CustomDataset(tokenizer, label_model, X_test)\n","\n","\n","  test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","  del test_dataset\n","\n","  return train_dataset, test_dataloader"]},{"cell_type":"markdown","metadata":{"id":"lcl6trsPiXK5"},"source":["##### Tạo hàm lấy model để huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWl6kJvvjQcG"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, AutoModelForSequenceClassification, AutoModel\n","def get_model(name_model):\n","  tokenizer = AutoTokenizer.from_pretrained(name_model)\n","  model = AutoModelForSequenceClassification.from_pretrained(\n","            name_model,\n","            num_labels = len(label_model),\n","            label2id = convert_lb2id(label_model),\n","            id2label = convert_id2lb(label_model),\n","            problem_type = problem_type,\n","            ignore_mismatched_sizes=True\n","          ).to(device)\n","\n","  return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"y2C7rTBZibXX"},"source":["##### Tạo hàm áp dụng mô hình để huấn luyện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slWVYibwjRwe"},"outputs":[],"source":["def train_model(model, training_args, train_dataset):\n","  model.train()\n","  trainer = CustomTrainer(\n","      model = model,\n","      args = training_args,\n","      train_dataset = train_dataset,\n","      # eval_dataset = test_dataset,\n","      data_collator = lambda data : {\n","          'input_ids' : torch.stack([item['input_ids'] for item in data]),\n","          'attention_mask' : torch.stack([item['attention_mask'] for item in data]),\n","          'labels' : torch.stack([item['labels'] for item in data]),\n","      }\n","  )\n","\n","  trainer.train()\n","\n","  del trainer\n","\n","  free_gpu()"]},{"cell_type":"markdown","metadata":{"id":"BKVUsrO4ihU3"},"source":["##### Tạo hàm để chuyển về dạng one-hot-vector (index to num)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbiZ42yjjTMP"},"outputs":[],"source":["def get_ohv(label, name_labels):\n","  ohv_label = []\n","  for i in range(len(name_labels)):\n","    ohv_label.append(0)\n","\n","  label_list = [i.strip() for i in label.split(\",\")]\n","\n","  for i in label_list:\n","    if i in name_labels:\n","      ohv_label[name_labels.index(i)] = 1\n","\n","  return ohv_label"]},{"cell_type":"markdown","metadata":{"id":"siYsksKZjLWP"},"source":["##### Hàm in ra kết quả"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxgwoC9pjUTp"},"outputs":[],"source":["def print_predict_result(model, test_dataloader):\n","  y_pred = []\n","  y_true = []\n","\n","  model.eval()\n","  with torch.no_grad():\n","      for batch in test_dataloader:\n","          input_ids = batch['input_ids'].to(device)\n","          attention_mask = batch['attention_mask'].to(device)\n","\n","          output = model(input_ids, attention_mask=attention_mask)\n","\n","          logits = output.logits.detach().cpu().numpy()\n","          logits = np.array([np.argmax(i).flatten().item() for i in logits])\n","\n","          y_pred.extend(logits)\n","\n","          if type_job == \"train\":\n","            labels = batch['labels'].cpu().numpy()\n","            labels = [np.argmax(i) for i in labels]\n","            y_true.extend(labels)\n","\n","  y_pred = [get_ohv(label_model[i], label_model) for i in y_pred]\n","  y_true = [get_ohv(label_model[i], label_model) for i in y_true]\n","\n","  micro_test = f1_score(y_true, y_pred, average='micro')\n","  macro_test = f1_score(y_true, y_pred, average='macro')\n","  weighted_test = f1_score(y_true, y_pred, average='weighted')\n","  accuracy_test = accuracy_score(y_true,y_pred)\n","  report = classification_report(y_true, y_pred, target_names = label_model)\n","  print()\n","  print(\"Accuracy: \", round(accuracy_test*100,2))\n","  print(\"F1 weighted: \", round(weighted_test*100,2))\n","  print(\"f1 macro: \", round(macro_test*100,2))\n","  print(\"f1 micro: \", round(micro_test*100,2))\n","\n","  print(\"-\"*100)\n","  print(report)\n","  print()\n","  print()\n","  print()\n","  print(\"=\" * 100 + \"\\n\")\n","\n","  return accuracy_test, weighted_test"]},{"cell_type":"markdown","metadata":{"id":"_cmzbr6AjN9h"},"source":["##### Chuẩn bị mô hình"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POpPEOKHjWIB"},"outputs":[],"source":["name_models = [\"xlm-roberta-base\"\n","            , \"vinai/phobert-base-v2\"]\n","\n","\n","problem_type = \"single_label_classification\"\n","\n","category_list = [\"negative\", \"neutral\", \"positive\"]\n","\n","label_model = category_list\n","\n","max_len = 256 #Độ dài tối đa mô hình có thể nhận vào\n","epochs = 5 #Số lần huấn luyện\n","batch_size = 32\n","learning_rate = 1e-4 #Tốc độ học\n","weight_decay = 0.01 #Phần trăm bỏ để tránh overfitting\n","\n","log_strategy = \"steps\"\n","log_step = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZPMCsxijYh4"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir = '/content',\n","    # evaluation_strategy= 'epoch',\n","    learning_rate = learning_rate,\n","    # save_strategy = 'epoch',\n","    per_device_train_batch_size = batch_size,\n","    num_train_epochs = epochs,\n","    weight_decay = weight_decay,\n","    fp16=True,\n","    fp16_full_eval=True,\n","    jit_mode_eval=True,\n","    logging_strategy=log_strategy,\n","    logging_steps = log_step,\n","    seed = seed,\n","    # load_best_model_at_end=True,\n",")\n","\n","type_job = \"train\""]},{"cell_type":"markdown","metadata":{"id":"eNywfM0Djtsa"},"source":["#### Cài đặt KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzsmlljvkCPa"},"outputs":[],"source":["# Define k-fold cross-validation\n","num_folds = 5\n","skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"xUpuXNYSkCzb"},"source":["#### Huấn luyện mô hình với tập dữ liệu có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3884d04cc0ea430e9a2efc41a81121b6","89b7e1dba47b4c948ca72de9bd60cefd","09bf9f7143a943489da576a5bab94251","3c9b64c514b84e46a62c838f1c065ea0","51e1ce545925491986f60418f0a10967","e572155204d74b058fa5ecf720ab2b7e","ab525333527f4cd58aaf793d6d65311f","262f2b7596454e778c6fa96a480379e5","086fd60f5c7b490388ea92d9095c8ee0","f11ac565d4b546a3bbf0d4d73a1bbc88","5695110e437f4abc842f746e48dc9fd0","283f123d72264aa8afa6ade7f3de3ea7","9b984549e55a41f1a6d5e75247ed0ecc","2b90430095f14f9fb3aa918e9598a302","80fa2f3f0bfa4c2d9b9a7cb96c5b489e","85146fb92ed346cd8ac2da2743d56281","a64f5a34c5594dadb9dbb500259d5832","fc70a7ad031f4f8b89c6e2c23ecec3df","fa936c6340084a52b83bf4dd1b44ef7f","f5325d05a6674c72bfb123115f1e1830","c71e21112fa84680b3e61edb316746ae","6842b1668b714e65a8ce8d56a5b45a3f","88247e37022345e7ac487cd2cfcc94dd","e1d3bbd8ce514202af30898efa1ddcda","fe331362b4ec4739811711bf17d8e81f","79d81c60a00747758e068aa664aec0c8","1c4362e1cea84190a34f0c009ed64832","9d4f9f69feef482c974e55886602ac1e","291ac95f62574deaaee9f001ed0483a4","32c5eb50cd3b4339b7ec473fa6b317cd","51b4f8393d914ca289fd666497b5fc40","489cbb3a38a744079c38fa269e3756ad","54b87fa822484af9b73260ce0e8a5bbc","0041e669a3a84374900cb25eb45f8dc9","7c363660b35345418e9c44b2f6808163","39f4f6725a83419d83febc740c10347f","86b001bde0d14ed883081459e3c6f38a","13fa5bc7d63b416298e1f05d05a40dac","30a6506f5f72488a8e620303d41daa69","bc3b8014fe764297a40fcab6c4d94acf","9c759ee1ae76406383809e3e270966d4","e5980c68948141b7bf0edf44d1f91f8f","fdba005e73dc4b07a0d882ce8159ab6d","e372081e33444d41b3d705da89e3a2da","645e6e4bb439482babdbb9d8f6bdf36f","f24c5f27a90841779c55991e676d5ec2","d4ed2369f8d7479f9e06c94a0facaee3","58e77fc3d72e432c8d3b8757a2dffff6","35f053cd9db743bfa8dc4bda978943ca","50a84ba4a5cf499186daae562b33232e","331d71b2927c48fc939a33cd3f39bb92","085028ef309148bfa82557a3f7a80157","e2b87aeb42104ec3ac84a8bb8a337d69","e0d0e7d97c8e4127870ffa6c093ca6e5","b67385b6339b4520aae50b474c9e76dc"]},"executionInfo":{"elapsed":1872845,"status":"ok","timestamp":1702095794998,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"ir3MdrSQ_EGl","outputId":"26ff82da-e70a-4adf-a6cc-c4b3e6b40df7"},"outputs":[{"name":"stdout","output_type":"stream","text":["màu_sắc ghi sữa chất_liệu không biết đúng với mô_tả đúng giá hạt_dẻ mà áo lại xịn lắm khá dày_dặn form croptop siêu xinh ạ\n","[0 0 1]\n","đúng với mô_tả cũng không giống lắm chất_liệu hơi mỏng màu_sắc nâu hình_ảnh chỉ mang tính_chất nhận xu\n","[0 1 0]\n","màu_sắc ghi sữa chất_liệu không biết đúng với mô_tả đúng giá hạt_dẻ mà áo lại xịn lắm khá dày_dặn form croptop siêu xinh ạ\n","[0 0 1]\n","đúng với mô_tả cũng không giống lắm chất_liệu hơi mỏng màu_sắc nâu hình_ảnh chỉ mang tính_chất nhận xu\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.075300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.59_0.5149936476617732/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  59.0\n","F1 weighted:  51.5\n","f1 macro:  45.82\n","f1 micro:  59.0\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.49      0.91      0.63       210\n","     neutral       1.00      0.01      0.01       151\n","    positive       0.79      0.67      0.73       239\n","\n","   micro avg       0.59      0.59      0.59       600\n","   macro avg       0.76      0.53      0.46       600\n","weighted avg       0.74      0.59      0.51       600\n"," samples avg       0.59      0.59      0.59       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.59_0.5149936476617732/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3884d04cc0ea430e9a2efc41a81121b6","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"283f123d72264aa8afa6ade7f3de3ea7","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88247e37022345e7ac487cd2cfcc94dd","version_major":2,"version_minor":0},"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0041e669a3a84374900cb25eb45f8dc9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"645e6e4bb439482babdbb9d8f6bdf36f","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:39, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.545900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.815_0.8162543877318738/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  81.5\n","F1 weighted:  81.63\n","f1 macro:  79.71\n","f1 micro:  81.5\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.83      0.85      0.84       210\n","     neutral       0.64      0.66      0.65       151\n","    positive       0.92      0.88      0.90       239\n","\n","   micro avg       0.81      0.81      0.81       600\n","   macro avg       0.80      0.80      0.80       600\n","weighted avg       0.82      0.81      0.82       600\n"," samples avg       0.81      0.81      0.81       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.815_0.8162543877318738/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.769000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.78_0.7832663001150312/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  78.0\n","F1 weighted:  78.33\n","f1 macro:  76.23\n","f1 micro:  78.0\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.85      0.74      0.79       210\n","     neutral       0.57      0.66      0.61       151\n","    positive       0.88      0.89      0.89       239\n","\n","   micro avg       0.78      0.78      0.78       600\n","   macro avg       0.77      0.76      0.76       600\n","weighted avg       0.79      0.78      0.78       600\n"," samples avg       0.78      0.78      0.78       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.78_0.7832663001150312/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.532400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7983333333333333_0.7973833595650964/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  79.83\n","F1 weighted:  79.74\n","f1 macro:  77.48\n","f1 micro:  79.83\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.84      0.77      0.80       210\n","     neutral       0.61      0.62      0.61       151\n","    positive       0.89      0.94      0.91       239\n","\n","   micro avg       0.80      0.80      0.80       600\n","   macro avg       0.78      0.77      0.77       600\n","weighted avg       0.80      0.80      0.80       600\n"," samples avg       0.80      0.80      0.80       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7983333333333333_0.7973833595650964/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.909500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7266666666666667_0.7268739044617716/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  72.67\n","F1 weighted:  72.69\n","f1 macro:  69.76\n","f1 micro:  72.67\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.73      0.77      0.75       211\n","     neutral       0.49      0.48      0.48       150\n","    positive       0.88      0.85      0.86       239\n","\n","   micro avg       0.73      0.73      0.73       600\n","   macro avg       0.70      0.70      0.70       600\n","weighted avg       0.73      0.73      0.73       600\n"," samples avg       0.73      0.73      0.73       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7266666666666667_0.7268739044617716/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.532500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.825_0.8268434214683358/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  82.5\n","F1 weighted:  82.68\n","f1 macro:  80.85\n","f1 micro:  82.5\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.86      0.85      0.85       211\n","     neutral       0.65      0.69      0.67       150\n","    positive       0.92      0.89      0.90       239\n","\n","   micro avg       0.82      0.82      0.82       600\n","   macro avg       0.81      0.81      0.81       600\n","weighted avg       0.83      0.82      0.83       600\n"," samples avg       0.82      0.82      0.82       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.825_0.8268434214683358/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.103800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  35.17\n","F1 weighted:  18.3\n","f1 macro:  17.34\n","f1 micro:  35.17\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.35      1.00      0.52       211\n","     neutral       0.00      0.00      0.00       150\n","    positive       0.00      0.00      0.00       239\n","\n","   micro avg       0.35      0.35      0.35       600\n","   macro avg       0.12      0.33      0.17       600\n","weighted avg       0.12      0.35      0.18       600\n"," samples avg       0.35      0.35      0.35       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.3516666666666667_0.18298808055898072/config.json\n","Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.3516666666666667_0.18298808055898072/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.665100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.835_0.8374656534009067/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  83.5\n","F1 weighted:  83.75\n","f1 macro:  82.15\n","f1 micro:  83.5\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.89      0.84      0.86       211\n","     neutral       0.66      0.74      0.70       150\n","    positive       0.91      0.89      0.90       239\n","\n","   micro avg       0.83      0.83      0.83       600\n","   macro avg       0.82      0.82      0.82       600\n","weighted avg       0.84      0.83      0.84       600\n"," samples avg       0.83      0.83      0.83       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.835_0.8374656534009067/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.714600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7766666666666666_0.7780473867969921/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  77.67\n","F1 weighted:  77.8\n","f1 macro:  75.51\n","f1 micro:  77.67\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.81      0.79      0.80       211\n","     neutral       0.57      0.60      0.59       150\n","    positive       0.88      0.87      0.88       239\n","\n","   micro avg       0.78      0.78      0.78       600\n","   macro avg       0.76      0.76      0.76       600\n","weighted avg       0.78      0.78      0.78       600\n"," samples avg       0.78      0.78      0.78       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7766666666666666_0.7780473867969921/pytorch_model.bin\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 190\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [190/190 02:41, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.604000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7983333333333333_0.8013730862328813/config.json\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  79.83\n","F1 weighted:  80.14\n","f1 macro:  78.17\n","f1 micro:  79.83\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.84      0.80      0.82       211\n","     neutral       0.60      0.67      0.64       150\n","    positive       0.90      0.87      0.89       239\n","\n","   micro avg       0.80      0.80      0.80       600\n","   macro avg       0.78      0.78      0.78       600\n","weighted avg       0.81      0.80      0.80       600\n"," samples avg       0.80      0.80      0.80       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /content/gdrive/MyDrive/DFS/temp/Code_Crawl_Data_Shoppe/model/0.7983333333333333_0.8013730862328813/pytorch_model.bin\n"]}],"source":["from sklearn.model_selection import StratifiedKFold\n","import torch.nn.functional as F\n","\n","X_train, X_test, y_train, y_test = get_train_test(label_model, word = True)\n","\n","X = np.concatenate((X_train, X_test), axis=0)\n","y = np.concatenate((y_train, y_test), axis=0)\n","\n","eval_data = {}\n","for train_index, test_index in skf.split(X, np.argmax(y, axis = 1)):\n","    X_train_fold, X_test_fold = X[train_index], X[test_index]\n","    y_train_fold, y_test_fold = y[train_index], y[test_index]\n","\n","    for name_model in name_models:\n","      free_gpu()\n","      model, tokenizer = get_model(name_model)\n","      train_dataset, test_dataloader = get_dataset(tokenizer, label_model, X_train_fold, X_test_fold, y_train_fold, y_test_fold)\n","\n","      train_model(model, training_args, train_dataset)\n","      accuracy_test, weighted_test = print_predict_result(model, test_dataloader)\n","      print()\n","\n","      if name_model not in eval_data:\n","          eval_data[name_model] = []\n","\n","      eval_data[name_model].append([accuracy_test, weighted_test])\n","\n","      model.save_pretrained(path.join(model_path, str(accuracy_test) + \"_\" + str(weighted_test)))\n","\n","      del model"]},{"cell_type":"markdown","metadata":{"id":"52zLWA3CkOs7"},"source":["#### Kết quả từng fold của 2 mô hình có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702095794999,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"HhUETiW--K_C","outputId":"5a0e21c1-d19c-43f5-bf2a-066f9d17efe9"},"outputs":[{"data":{"text/plain":["{'xlm-roberta-base': [[0.59, 0.5149936476617732],\n","  [0.78, 0.7832663001150312],\n","  [0.7266666666666667, 0.7268739044617716],\n","  [0.3516666666666667, 0.18298808055898072],\n","  [0.7766666666666666, 0.7780473867969921]],\n"," 'vinai/phobert-base-v2': [[0.815, 0.8162543877318738],\n","  [0.7983333333333333, 0.7973833595650964],\n","  [0.825, 0.8268434214683358],\n","  [0.835, 0.8374656534009067],\n","  [0.7983333333333333, 0.8013730862328813]]}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["eval_data"]},{"cell_type":"markdown","metadata":{"id":"MqOU6kZSkSyU"},"source":["#### Điểm trung bình của 2 mô hình có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1702095794999,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"ON5Ml4quj2Qz","outputId":"731d673f-2bb8-4788-f2f6-3c6b7016489e"},"outputs":[{"name":"stdout","output_type":"stream","text":["xlm-roberta-base\n","ACC 0.6449999999999999\n","F1 0.5972338639189098\n","vinai/phobert-base-v2\n","ACC 0.8143333333333335\n","F1 0.8158639816798188\n"]}],"source":["for k, values in eval_data.items():\n","    print(k)\n","    accs = [i[0] for i in values]\n","    f1ss = [i[1] for i in values]\n","\n","    print(\"ACC\", sum(accs)/len(accs))\n","    print(\"F1\", sum(f1ss)/len(f1ss))"]},{"cell_type":"markdown","metadata":{"id":"G186omokjxEZ"},"source":["#### Huấn luyện mô hình với tập dữ liệu không có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1984761,"status":"ok","timestamp":1702098698683,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"JkTQiYE2CAwC","outputId":"418afa74-96ea-4a9d-b342-727dffdbba93"},"outputs":[{"name":"stdout","output_type":"stream","text":["màu sắc ghi sữa chất liệu không biết đúng với mô tả đúng giá hạt dẻ mà áo lại xịn lắm khá dày dặn form croptop siêu xinh ạ\n","[0 0 1]\n","đúng với mô tả cũng không giống lắm chất liệu hơi mỏng màu sắc nâu hình ảnh chỉ mang tính chất nhận xu\n","[0 1 0]\n","màu sắc ghi sữa chất liệu không biết đúng với mô tả đúng giá hạt dẻ mà áo lại xịn lắm khá dày dặn form croptop siêu xinh ạ\n","[0 0 1]\n","đúng với mô tả cũng không giống lắm chất liệu hơi mỏng màu sắc nâu hình ảnh chỉ mang tính chất nhận xu\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 03:23, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.107300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.107200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.104300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  35.0\n","F1 weighted:  18.15\n","f1 macro:  17.28\n","f1 micro:  35.0\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.35      1.00      0.52       210\n","     neutral       0.00      0.00      0.00       151\n","    positive       0.00      0.00      0.00       239\n","\n","   micro avg       0.35      0.35      0.35       600\n","   macro avg       0.12      0.33      0.17       600\n","weighted avg       0.12      0.35      0.18       600\n"," samples avg       0.35      0.35      0.35       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 02:56, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.634600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.406600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.256800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  83.17\n","F1 weighted:  83.3\n","f1 macro:  81.66\n","f1 micro:  83.17\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.85      0.90      0.87       210\n","     neutral       0.67      0.70      0.69       151\n","    positive       0.93      0.86      0.89       239\n","\n","   micro avg       0.83      0.83      0.83       600\n","   macro avg       0.82      0.82      0.82       600\n","weighted avg       0.84      0.83      0.83       600\n"," samples avg       0.83      0.83      0.83       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 03:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.017400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.939300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.805600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  72.67\n","F1 weighted:  72.53\n","f1 macro:  69.85\n","f1 micro:  72.67\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.77      0.71      0.74       210\n","     neutral       0.50      0.50      0.50       151\n","    positive       0.83      0.88      0.85       239\n","\n","   micro avg       0.73      0.73      0.73       600\n","   macro avg       0.70      0.70      0.70       600\n","weighted avg       0.73      0.73      0.73       600\n"," samples avg       0.73      0.73      0.73       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 02:56, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.666700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.415600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.254500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  78.17\n","F1 weighted:  78.45\n","f1 macro:  76.26\n","f1 micro:  78.17\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.83      0.77      0.80       210\n","     neutral       0.57      0.64      0.60       151\n","    positive       0.89      0.89      0.89       239\n","\n","   micro avg       0.78      0.78      0.78       600\n","   macro avg       0.76      0.76      0.76       600\n","weighted avg       0.79      0.78      0.78       600\n"," samples avg       0.78      0.78      0.78       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 03:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.930000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.924700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.716600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  76.5\n","F1 weighted:  76.73\n","f1 macro:  74.2\n","f1 micro:  76.5\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.82      0.72      0.76       211\n","     neutral       0.53      0.60      0.56       150\n","    positive       0.89      0.91      0.90       239\n","\n","   micro avg       0.77      0.77      0.77       600\n","   macro avg       0.74      0.74      0.74       600\n","weighted avg       0.77      0.77      0.77       600\n"," samples avg       0.77      0.77      0.77       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.694900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.453500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.285000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  81.83\n","F1 weighted:  81.92\n","f1 macro:  79.91\n","f1 micro:  81.83\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.84      0.86      0.85       211\n","     neutral       0.64      0.65      0.65       150\n","    positive       0.91      0.88      0.90       239\n","\n","   micro avg       0.82      0.82      0.82       600\n","   macro avg       0.80      0.80      0.80       600\n","weighted avg       0.82      0.82      0.82       600\n"," samples avg       0.82      0.82      0.82       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 03:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.106500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.129400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.105900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  39.83\n","F1 weighted:  22.69\n","f1 macro:  18.99\n","f1 micro:  39.83\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.00      0.00      0.00       211\n","     neutral       0.00      0.00      0.00       150\n","    positive       0.40      1.00      0.57       239\n","\n","   micro avg       0.40      0.40      0.40       600\n","   macro avg       0.13      0.33      0.19       600\n","weighted avg       0.16      0.40      0.23       600\n"," samples avg       0.40      0.40      0.40       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.732600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.471400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.314800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  83.0\n","F1 weighted:  83.23\n","f1 macro:  81.49\n","f1 micro:  83.0\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.88      0.82      0.85       211\n","     neutral       0.65      0.73      0.69       150\n","    positive       0.91      0.91      0.91       239\n","\n","   micro avg       0.83      0.83      0.83       600\n","   macro avg       0.82      0.82      0.81       600\n","weighted avg       0.84      0.83      0.83       600\n"," samples avg       0.83      0.83      0.83       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n","Model config XLMRobertaConfig {\n","  \"_name_or_path\": \"xlm-roberta-base\",\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 278,045,955\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 03:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.971600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.881600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.779100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  75.0\n","F1 weighted:  74.28\n","f1 macro:  71.25\n","f1 micro:  75.0\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.75      0.83      0.79       211\n","     neutral       0.54      0.44      0.49       150\n","    positive       0.86      0.87      0.86       239\n","\n","   micro avg       0.75      0.75      0.75       600\n","   macro avg       0.72      0.71      0.71       600\n","weighted avg       0.74      0.75      0.74       600\n"," samples avg       0.75      0.75      0.75       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/vocab.txt\n","loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/bpe.codes\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"vinai/phobert-base-v2\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"negative\",\n","    \"1\": \"neutral\",\n","    \"2\": \"positive\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"negative\": 0,\n","    \"neutral\": 1,\n","    \"positive\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-base-v2/snapshots/2b51e367d92093c9688112098510e6a58bab67cd/pytorch_model.bin\n","Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using auto half precision backend\n","***** Running training *****\n","  Num examples = 2,400\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 375\n","  Number of trainable parameters = 135,000,579\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [375/375 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.689700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.400800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.257500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy:  77.83\n","F1 weighted:  78.09\n","f1 macro:  75.91\n","f1 micro:  77.83\n","----------------------------------------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","    negative       0.82      0.78      0.80       211\n","     neutral       0.57      0.63      0.60       150\n","    positive       0.89      0.87      0.88       239\n","\n","   micro avg       0.78      0.78      0.78       600\n","   macro avg       0.76      0.76      0.76       600\n","weighted avg       0.78      0.78      0.78       600\n"," samples avg       0.78      0.78      0.78       600\n","\n","\n","\n","\n","====================================================================================================\n","\n","\n"]},{"data":{"text/plain":["{'xlm-roberta-base': [[0.35, 0.18148148148148147],\n","  [0.7266666666666667, 0.7253342110363576],\n","  [0.765, 0.7673454134902766],\n","  [0.3983333333333333, 0.22694080254270954],\n","  [0.75, 0.7427556998372237]],\n"," 'vinai/phobert-base-v2': [[0.8316666666666667, 0.8330371679675747],\n","  [0.7816666666666666, 0.7845078243456529],\n","  [0.8183333333333334, 0.8191500746516925],\n","  [0.83, 0.8323130431339713],\n","  [0.7783333333333333, 0.7809484097133127]]}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import StratifiedKFold\n","import torch.nn.functional as F\n","\n","# Define k-fold cross-validation\n","num_folds = 5\n","skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n","X_train, X_test, y_train, y_test = get_train_test(label_model, word = False)\n","\n","X = np.concatenate((X_train, X_test), axis=0)\n","y = np.concatenate((y_train, y_test), axis=0)\n","\n","eval_data_2 = {}\n","for train_index, test_index in skf.split(X, np.argmax(y, axis = 1)):\n","    X_train_fold, X_test_fold = X[train_index], X[test_index]\n","    y_train_fold, y_test_fold = y[train_index], y[test_index]\n","\n","    for name_model in name_models:\n","        free_gpu()\n","        model, tokenizer = get_model(name_model)\n","        train_dataset, test_dataloader = get_dataset(tokenizer, label_model, X_train_fold, X_test_fold, y_train_fold, y_test_fold)\n","\n","        train_model(model, training_args, train_dataset)\n","        accuracy_test, weighted_test = print_predict_result(model, test_dataloader)\n","        print()\n","\n","        if name_model not in eval_data_2:\n","            eval_data_2[name_model] = []\n","\n","        eval_data_2[name_model].append([accuracy_test, weighted_test])\n","\n","        del model\n","\n","eval_data_2"]},{"cell_type":"markdown","metadata":{"id":"2nrw7J01keX6"},"source":["#### Kết quả từng fold của 2 mô hình không có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702098698683,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"a6fkWUOU-hRR","outputId":"116cd786-9b99-4fc4-e197-f4e6d28c3206"},"outputs":[{"data":{"text/plain":["{'xlm-roberta-base': [[0.35, 0.18148148148148147],\n","  [0.7266666666666667, 0.7253342110363576],\n","  [0.765, 0.7673454134902766],\n","  [0.3983333333333333, 0.22694080254270954],\n","  [0.75, 0.7427556998372237]],\n"," 'vinai/phobert-base-v2': [[0.8316666666666667, 0.8330371679675747],\n","  [0.7816666666666666, 0.7845078243456529],\n","  [0.8183333333333334, 0.8191500746516925],\n","  [0.83, 0.8323130431339713],\n","  [0.7783333333333333, 0.7809484097133127]]}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["eval_data_2"]},{"cell_type":"markdown","metadata":{"id":"06BH2XO5kizZ"},"source":["#### Điểm trung bình của 2 mô hình không có tách từ (word_segment)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1702098698683,"user":{"displayName":"Đại Nguyễn Bá","userId":"11161078056318279435"},"user_tz":-420},"id":"ByZmijYCfOyY","outputId":"48581574-8813-4170-8e4b-9067de00eef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["xlm-roberta-base\n","ACC 0.5980000000000001\n","F1 0.5287715216776098\n","vinai/phobert-base-v2\n","ACC 0.808\n","F1 0.8099913039624408\n"]}],"source":["for k, values in eval_data_2.items():\n","    print(k)\n","    accs = [i[0] for i in values]\n","    f1ss = [i[1] for i in values]\n","\n","    print(\"ACC\", sum(accs)/len(accs))\n","    print(\"F1\", sum(f1ss)/len(f1ss))"]},{"cell_type":"markdown","metadata":{"id":"NNfqxUPjkHw5"},"source":["#3. Tổng kết"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"algALkOakfTV"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1702109131611,"user":{"displayName":"Uyên Nguyễn Ngọc Phương","userId":"06000761974539573354"},"user_tz":-420},"id":"22_bcINWkKvB","outputId":"866ce5b8-234a-4fcb-d414-9dd25c1a9e37"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d2d7d97c-be41-4b15-ba92-50e8f2677dc7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model name</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Accuracy without word segment</th>\n","      <th>F1 without word segment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Naive Bayes</td>\n","      <td>0.480667</td>\n","      <td>0.417706</td>\n","      <td>0.469333</td>\n","      <td>0.434393</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Logistic Regession</td>\n","      <td>0.742333</td>\n","      <td>0.738810</td>\n","      <td>0.751333</td>\n","      <td>0.747949</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Support vector machine</td>\n","      <td>0.722333</td>\n","      <td>0.718544</td>\n","      <td>0.718000</td>\n","      <td>0.716193</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CNN</td>\n","      <td>0.620333</td>\n","      <td>0.579687</td>\n","      <td>0.616000</td>\n","      <td>0.569351</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>XLM-R</td>\n","      <td>0.644999</td>\n","      <td>0.597234</td>\n","      <td>0.598000</td>\n","      <td>0.528772</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Bert (PhoBert)</td>\n","      <td>0.814333</td>\n","      <td>0.815864</td>\n","      <td>0.808000</td>\n","      <td>0.809991</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2d7d97c-be41-4b15-ba92-50e8f2677dc7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d2d7d97c-be41-4b15-ba92-50e8f2677dc7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d2d7d97c-be41-4b15-ba92-50e8f2677dc7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5b937666-4abe-4f28-b74c-398753070a02\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b937666-4abe-4f28-b74c-398753070a02')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5b937666-4abe-4f28-b74c-398753070a02 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["               Model name  Accuracy        F1  Accuracy without word segment  \\\n","0             Naive Bayes  0.480667  0.417706                       0.469333   \n","1      Logistic Regession  0.742333  0.738810                       0.751333   \n","2  Support vector machine  0.722333  0.718544                       0.718000   \n","3                     CNN  0.620333  0.579687                       0.616000   \n","4                   XLM-R  0.644999  0.597234                       0.598000   \n","5          Bert (PhoBert)  0.814333  0.815864                       0.808000   \n","\n","   F1 without word segment  \n","0                 0.434393  \n","1                 0.747949  \n","2                 0.716193  \n","3                 0.569351  \n","4                 0.528772  \n","5                 0.809991  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["result = {'Model name': ['Naive Bayes','Logistic Regession', 'Support vector machine', 'CNN', 'XLM-R', 'Bert (PhoBert)'],\n","          'Accuracy': [0.480667,0.742333, 0.722333, 0.620333, 0.644999, 0.814333],\n","          'F1': [0.417706, 0.738810, 0.718544, 0.579687, 0.597234, 0.815864],\n","          'Accuracy without word segment': [0.469333, 0.751333, 0.718000, 0.616, 0.598, 0.808],\n","          'F1 without word segment': [0.434393, 0.747949, 0.716193,  0.569351, 0.528772, 0.809991]}\n","result_df = pd.DataFrame(data = result)\n","result_df"]},{"cell_type":"markdown","metadata":{"id":"Z9B4wanfnG7b"},"source":["**Đánh giá và lựa chọn mô hình**\n","\n","Thống kê thấy được mô hình PhoBert và tách từ đem lại giá trị tốt nhất, do vậy nhóm lấy mô hình PhoBert có hệ số điểm F1, Accuracy cao nhất trong 5 fold là 0.835, 0.8374656534009067 để thực hiện dự đoán bộ dữ liệu có sẵn"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
